---
description: Epic 31 Architecture - Current Event Flow Pattern
globs:
  - "services/websocket-ingestion/**"
  - "services/enrichment-pipeline/**"
  - "services/weather-api/**"
  - "services/sports-data/**"
  - "implementation/analysis/*CALL_TREE*"
  - "docs/architecture/**"
alwaysApply: true
---

# Epic 31 Architecture Pattern

**Last Updated:** January 8, 2026  
**Status:** Current Production Architecture

## Critical Architecture Facts

### ❌ DEPRECATED Services (Do NOT Reference)

**enrichment-pipeline (Port 8002):**
- **Status**: DEPRECATED in Epic 31 (Story 31.4)
- **Why**: Simplified architecture, reduced latency, fewer failure points
- **Replacement**: Inline normalization in websocket-ingestion
- **Code Evidence**: See `services/websocket-ingestion/src/main.py`:
  - Lines 136-137, 206-207: Comments about Epic 31 standalone pattern
  - Lines 237-250: InfluxDBBatchWriter initialization (direct writes)
  - Lines 512-521: `_write_event_to_influxdb()` method (direct writes)

**DO NOT:**
- ❌ Reference enrichment-pipeline in new documentation
- ❌ Suggest HTTP POST to enrichment-pipeline
- ❌ Mention "dual write paths" (obsolete concept)
- ❌ Suggest enrichment-pipeline for normalization

### ✅ CURRENT Architecture (Epic 31)

**Event Flow:**
```
Home Assistant WebSocket (192.168.1.86:8123)
        ↓
websocket-ingestion (Port 8001)
  - Event validation
  - Inline normalization
  - Device/area lookups (Epic 23.2)
  - Duration calculation (Epic 23.3)
  - DIRECT InfluxDB writes
        ↓
InfluxDB (Port 8086)
  bucket: home_assistant_events
        ↓
data-api (Port 8006)
  - Query endpoint for events
        ↓
health-dashboard (Port 3000)
```

**Key Points:**
- Single write path (websocket-ingestion → InfluxDB)
- No intermediate services
- All normalization inline
- External services are standalone

## External Services Pattern

**ALL external services follow this pattern:**

1. **Fetch** from external API (ESPN, OpenWeatherMap, etc.)
2. **Write** directly to InfluxDB
3. **Query** via data-api
4. **Display** on dashboard

**Examples:**
- `weather-api` (Port 8009) - Standalone, writes weather data to InfluxDB
- `sports-api` (Port 8005) - Polls HA Team Tracker sensors, writes scores to InfluxDB
- `carbon-intensity` (Port 8010) - Writes carbon data to InfluxDB

**Note:** `sports-api` is not in docker-compose.yml by default (standalone service).

**DO NOT:**
- ❌ Make services HTTP POST to websocket-ingestion
- ❌ Create service-to-service dependencies
- ✅ Write directly to InfluxDB
- ✅ Query via data-api

## Database Architecture (Epic 22)

**Hybrid Pattern:**
- **InfluxDB**: Time-series data (events, metrics, sports scores)
- **SQLite**: Relational metadata (devices, entities, webhooks)

**Query Patterns:**
- Events: Query InfluxDB via data-api
- Devices/Entities: Query SQLite via data-api
- Sports: Query InfluxDB via data-api

## Code Patterns to Follow

### When Writing Event Processing Code

```python
# ✅ CORRECT (Epic 31)
async def process_batch(self, batch):
    # Process events
    for event in batch:
        await self.async_event_processor.process_event(event)
    
    # Events are already in InfluxDB (via batch processor)
    logger.debug("Batch processed - events stored in InfluxDB")

# ❌ INCORRECT (Pre-Epic 31)
async def process_batch(self, batch):
    # Send to enrichment-pipeline
    if self.http_client:
        for event in batch:
            await self.http_client.send_event(event)
```

### When Writing Documentation

```markdown
# ✅ CORRECT (Epic 31)
Events flow: HA → websocket-ingestion → InfluxDB (direct)

# ❌ INCORRECT (Pre-Epic 31)
Events flow: HA → websocket-ingestion → enrichment-pipeline → InfluxDB
```

### When Analyzing Performance

**Current Bottlenecks (Epic 31):**
- Batch timeout: 5.0 seconds (configurable via BATCH_TIMEOUT)
- InfluxDB write latency: 10-30ms per batch
- Device lookup: 2-5ms (in-memory dictionary)

**NOT Bottlenecks:**
- ~~HTTP POST to enrichment~~ (removed)
- ~~Enrichment processing time~~ (service deprecated)

## Automation Execution Architecture (January 2026)

**Service:** api-automation-edge (Port 8025)

**Task Queue Pattern:**
```
HTTP Request → Validate → Queue Task (Huey SQLite) → Return Task ID (fast)
                     ↓
              Huey Queue (SQLite)
                     ↓
              Worker Process → Execute → Store Result
                     ↓
              Result Queryable via API
```

**Key Components:**
- **Huey SQLite Backend**: Task queue with persistence (survives restarts)
- **Asynchronous Execution**: Non-blocking HTTP responses, tasks execute in background
- **Task Prioritization**: Based on automation risk level (high=10, medium=5, low=1)
- **Persistent Retry**: Retries survive service restarts (high: 10 retries/60s, medium: 5/30s, low: 3/15s)
- **Delayed Execution**: Support for `delay` (seconds) and `eta` (ISO datetime) parameters
- **Cron Scheduling**: Periodic task scheduling for automation specs with `trigger.type: "schedule"`

**Execution Modes:**
1. **Synchronous** (`USE_TASK_QUEUE=false`): Original blocking execution (backward compatible)
2. **Asynchronous** (`USE_TASK_QUEUE=true`, default): Tasks queued, execution in background

**New API Endpoints:**
- `POST /api/execute/{spec_id}?delay=300` - Queue task with delay
- `POST /api/execute/{spec_id}?eta=2026-01-20T14:30:00Z` - Queue task for specific time
- `GET /api/tasks/{task_id}` - Get task status and result
- `GET /api/tasks` - List tasks (with filters)
- `POST /api/tasks/{task_id}/cancel` - Cancel pending task
- `GET /api/schedules` - List scheduled automations
- `POST /api/schedules/{spec_id}/enable` - Enable cron schedule
- `POST /api/schedules/{spec_id}/disable` - Disable cron schedule

**Integration Points:**
- **Kill Switch**: Revokes queued tasks when kill switch activated (global/home/spec level)
- **Metrics**: Queue metrics (depth, execution time, success rate) sent to InfluxDB
- **Health Check**: `/health` endpoint includes queue status (pending, scheduled, consumer status)

**Configuration:**
- `USE_TASK_QUEUE`: Enable task queue (default: "true")
- `HUEY_DATABASE_PATH`: SQLite database path (default: "./data/automation_queue.db")
- `HUEY_WORKERS`: Number of worker threads (default: 4)
- `HUEY_RESULT_TTL`: Result storage TTL in seconds (default: 604800 = 7 days)

**Code Pattern:**
```python
# ✅ CORRECT (Task Queue - Asynchronous)
@router.post("/{spec_id}")
async def execute_spec(spec_id: str, delay: Optional[int] = None):
    # Validate and check kill switch (before queuing)
    spec = spec_registry.get_spec(spec_id, home_id)
    is_allowed, reason = kill_switch.is_allowed(spec, home_id)
    
    # Queue task instead of executing directly
    task = queue_automation_task(
        spec_id=spec_id,
        trigger_data=trigger_data,
        home_id=home_id,
        delay=delay
    )
    
    return {"task_id": task.id, "status": "queued"}

# ❌ INCORRECT (Blocking - Pre-Task Queue)
@router.post("/{spec_id}")
async def execute_spec(spec_id: str):
    # Execute synchronously (blocks HTTP request)
    execution_result = await executor.execute(...)
    return execution_result
```

## Epic Timeline Reference

**Epic 22** (January 2025):
- Hybrid database architecture (InfluxDB + SQLite)
- 5-10x faster device/entity queries

**Epic 23** (March 2025):
- Context tracking (context_id, context_parent_id)
- Spatial analytics (device_id, area_id)
- Duration tracking (duration_in_state)
- Device metadata (manufacturer, model)

**Epic 31** (October 2025):
- Deprecated enrichment-pipeline
- Direct InfluxDB writes
- Standalone external services
- Simplified architecture

**Epic 31+** (January 2026):
- Asynchronous automation execution with Huey SQLite task queue
- Task prioritization and persistent retry
- Delayed execution and cron-based scheduling
- Non-blocking HTTP responses for automation execution

## When to Update This Rule

Update when:
- Major architecture changes
- Services deprecated/added
- Data flow patterns change
- Execution patterns change (e.g., task queue, scheduling)
- Epic milestones reached

**Current as of:** Epic 31+ (January 2026)

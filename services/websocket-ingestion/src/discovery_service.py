"""
Home Assistant Device & Entity Discovery Service

Queries Home Assistant registries to discover connected devices, entities, and integrations.
"""

import asyncio
import logging
import time
from typing import Any

from aiohttp import ClientWebSocketResponse

from .message_id_manager import get_message_id_manager
from .models import Device, Entity

logger = logging.getLogger(__name__)


class DiscoveryService:
    """Service for discovering devices and entities from Home Assistant registries"""

    def __init__(self, influxdb_manager=None):
        self.message_id_manager = get_message_id_manager()  # Use centralized manager
        self.pending_responses: dict[int, asyncio.Future] = {}
        self.influxdb_manager = influxdb_manager

        # Epic 23.2: Device and area mapping caches for event enrichment
        self.entity_to_device: dict[str, str] = {}  # entity_id â†’ device_id
        self.device_to_area: dict[str, str] = {}    # device_id â†’ area_id
        self.entity_to_area: dict[str, str] = {}    # entity_id â†’ area_id (direct assignment)
        self.device_metadata: dict[str, dict[str, Any]] = {}  # device_id â†’ {manufacturer, model, sw_version}

        # Cache expiration tracking (refresh every 30 minutes to handle stale data)
        self._cache_timestamp: float | None = None
        self._cache_ttl_seconds = 1800  # 30 minutes - devices/areas don't change often
        self._last_stale_warning_timestamp: float | None = None  # Track when we last warned about stale cache
        self._stale_warning_interval = 600  # Only warn every 10 minutes to avoid log spam

        logger.info("Discovery service initialized with device/area mapping caches")

    async def _get_next_id(self) -> int:
        """Get next message ID from centralized manager"""
        return await self.message_id_manager.get_next_id()

    async def _discover_devices_websocket(self, websocket: ClientWebSocketResponse) -> list[dict[str, Any]]:
        """
        Discover devices via WebSocket (original implementation)

        Args:
            websocket: Connected WebSocket client

        Returns:
            List of device dictionaries
        """
        try:
            message_id = await self._get_next_id()
            logger.info("ðŸ“± Discovering devices via WebSocket...")

            # Send device registry list command
            await websocket.send_json({
                "id": message_id,
                "type": "config/device_registry/list",
            })

            # Wait for response
            response = await self._wait_for_response(websocket, message_id, timeout=10.0)

            if not response or not response.get("success"):
                error_msg = response.get("error", {}).get("message", "Unknown error") if response else "No response"
                logger.error(f"âŒ Device registry command failed: {error_msg}")
                return []

            return response.get("result", [])

        except Exception as e:
            logger.exception(f"âŒ Error discovering devices via WebSocket: {e}")
            return []

    async def discover_devices(self, websocket: ClientWebSocketResponse | None = None) -> list[dict[str, Any]]:
        """
        Discover all devices from Home Assistant device registry

        Note: Home Assistant doesn't have HTTP API for device registry.
        Uses WebSocket if provided, otherwise returns empty list.
        Device info can be extracted from entities instead.

        Args:
            websocket: Optional WebSocket client (required for device discovery)

        Returns:
            List of device dictionaries
        """
        try:
            logger.info("=" * 80)
            logger.info("ðŸ“± DISCOVERING DEVICES")
            logger.info("=" * 80)

            # Home Assistant doesn't have HTTP API for device registry
            # Use WebSocket if available, otherwise skip (devices can be inferred from entities)
            if websocket:
                logger.info("Using WebSocket for device discovery (HTTP API not available)")
                devices = await self._discover_devices_websocket(websocket)
            else:
                logger.warning("âš ï¸  No WebSocket provided - skipping device discovery")
                logger.info("ðŸ’¡ Device info will be available from entity registry (device_id references)")
                return []

            device_count = len(devices)
            logger.info(f"âœ… Discovered {device_count} devices")

            # Epic 23.2: Build device â†’ area mapping cache
            # Epic 23.5: Build device metadata cache
            for device in devices:
                device_id = device.get("id")
                if device_id:
                    # Store device â†’ area mapping
                    area_id = device.get("area_id")
                    if area_id:
                        self.device_to_area[device_id] = area_id

                    # Epic 23.5: Store device metadata (manufacturer, model, version)
                    self.device_metadata[device_id] = {
                        "manufacturer": device.get("manufacturer"),
                        "model": device.get("model"),
                        "sw_version": device.get("sw_version"),
                        "name": device.get("name"),
                        "name_by_user": device.get("name_by_user"),
                    }

            logger.info(f"ðŸ“ Cached {len(self.device_to_area)} device â†’ area mappings")
            logger.info(f"ðŸ·ï¸  Cached {len(self.device_metadata)} device metadata entries")

            # Update cache timestamp
            self._cache_timestamp = time.time()

            # Log sample device if available
            if devices:
                sample = devices[0]
                logger.info(f"ðŸ“± Sample device: {sample.get('name', 'Unknown')} "
                          f"(manufacturer: {sample.get('manufacturer', 'Unknown')}, "
                          f"model: {sample.get('model', 'Unknown')})")

            return devices

        except Exception as e:
            logger.exception(f"âŒ Error discovering devices: {e}")
            import traceback
            logger.exception(traceback.format_exc())
            return []

    async def discover_entities(self, websocket: ClientWebSocketResponse | None = None) -> list[dict[str, Any]]:
        """
        Discover all entities from Home Assistant entity registry

        Uses HTTP API to avoid WebSocket concurrency issues.

        Args:
            websocket: Optional WebSocket client (deprecated, kept for backward compatibility)

        Returns:
            List of entity dictionaries

        Raises:
            Exception: If command fails or response is invalid
        """
        try:
            import os

            import aiohttp

            logger.info("=" * 80)
            logger.info("ðŸ”Œ DISCOVERING ENTITIES (via HTTP API)")
            logger.info("=" * 80)

            # Use HTTP API to fetch entity registry (avoids WebSocket concurrency issues)
            ha_url = os.getenv("HA_HTTP_URL") or os.getenv("HOME_ASSISTANT_URL", "http://192.168.1.86:8123")
            ha_token = os.getenv("HA_TOKEN") or os.getenv("HOME_ASSISTANT_TOKEN")

            if not ha_token:
                logger.error("âŒ No HA token available for entity discovery")
                return []

            # Normalize URL (ensure http:// not ws://)
            ha_url = ha_url.replace("ws://", "http://").replace("wss://", "https://").rstrip("/")

            logger.info(f"ðŸ”— Connecting to Home Assistant at: {ha_url}")
            logger.info(f"ðŸ”‘ Using token: {ha_token[:20]}..." if ha_token else "âŒ No token!")

            headers = {
                "Authorization": f"Bearer {ha_token}",
                "Content-Type": "application/json",
            }

            # Create session with connector to avoid SSL issues
            connector = aiohttp.TCPConnector(ssl=False)
            async with aiohttp.ClientSession(connector=connector) as session:
                logger.info(f"ðŸ“¡ Fetching entity registry from: {ha_url}/api/config/entity_registry/list")
                async with session.get(
                    f"{ha_url}/api/config/entity_registry/list",
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30),
                ) as response:
                    logger.info(f"ðŸ“¥ Response status: {response.status}")
                    if response.status != 200:
                        error_text = await response.text()
                        logger.warning(f"âš ï¸  HTTP entity registry endpoint failed: HTTP {response.status} - {error_text}")
                        # Fallback to WebSocket if available
                        if websocket:
                            logger.info("ðŸ”„ Falling back to WebSocket for entity discovery...")
                            try:
                                entities = await self._discover_entities_websocket(websocket)
                                if entities:
                                    logger.info(f"âœ… Entity discovery succeeded via WebSocket fallback: {len(entities)} entities")
                                else:
                                    logger.error("âŒ WebSocket fallback returned empty result - entity discovery failed")
                                return entities
                            except Exception as ws_error:
                                logger.exception(f"âŒ WebSocket fallback failed: {ws_error}")
                                logger.exception("Entity discovery completely failed - both HTTP and WebSocket methods failed")
                                return []
                        else:
                            logger.error("âŒ No WebSocket available for fallback - entity discovery failed")
                            logger.error("This indicates a configuration issue - check HA_HTTP_URL and HA_TOKEN, or ensure WebSocket is available")
                            return []

                    entities = await response.json()
                    logger.info(f"ðŸ“¦ Response type: {type(entities)}, length: {len(entities) if isinstance(entities, (list, dict)) else 'N/A'}")

                    # Handle both list and dict responses
                    if isinstance(entities, dict):
                        entities = entities.get("entities", entities.get("result", []))

                    entity_count = len(entities)
                    logger.info(f"âœ… Discovered {entity_count} entities")

                    # Epic 23.2: Build entity â†’ device and entity â†’ area mapping caches
                    for entity in entities:
                        entity_id = entity.get("entity_id")
                        if entity_id:
                            # Store entity â†’ device mapping
                            device_id = entity.get("device_id")
                            if device_id:
                                self.entity_to_device[entity_id] = device_id

                            # Store entity â†’ area mapping (direct assignment)
                            area_id = entity.get("area_id")
                            if area_id:
                                self.entity_to_area[entity_id] = area_id

                    logger.info(f"ðŸ”— Cached {len(self.entity_to_device)} entity â†’ device mappings")
                    logger.info(f"ðŸ“ Cached {len(self.entity_to_area)} entity â†’ area mappings (direct)")

                    # Update cache timestamp
                    self._cache_timestamp = time.time()

                    # Log sample entity if available
                    if entities:
                        sample = entities[0]
                        entity_id = sample.get("entity_id", "Unknown")
                        domain = entity_id.split(".")[0] if "." in entity_id else "Unknown"
                        logger.info(f"ðŸ”Œ Sample entity: {entity_id} "
                                  f"(platform: {sample.get('platform', 'Unknown')}, "
                                  f"domain: {domain})")
                        # Log name fields to verify they're present
                        logger.info(f"   name: {sample.get('name')}, "
                                  f"name_by_user: {sample.get('name_by_user')}, "
                                  f"original_name: {sample.get('original_name')}")

                    return entities

        except Exception as e:
            logger.exception(f"âŒ HTTP entity discovery failed with exception: {e}")
            import traceback
            logger.exception(f"Exception traceback: {traceback.format_exc()}")
            # Fallback to WebSocket if available
            if websocket:
                logger.info("ðŸ”„ Attempting WebSocket fallback for entity discovery...")
                try:
                    entities = await self._discover_entities_websocket(websocket)
                    if entities:
                        logger.info(f"âœ… Entity discovery succeeded via WebSocket fallback: {len(entities)} entities")
                    else:
                        logger.exception("âŒ WebSocket fallback returned empty result - entity discovery failed")
                    return entities
                except Exception as ws_error:
                    logger.exception(f"âŒ WebSocket fallback also failed: {ws_error}")
                    logger.exception("Entity discovery completely failed - both HTTP and WebSocket methods failed")
                    logger.exception(f"WebSocket error traceback: {traceback.format_exc()}")
                    return []
            else:
                logger.exception(f"âŒ Error discovering entities and no WebSocket available: {e}")
                logger.exception("This indicates a configuration issue - check HA_HTTP_URL and HA_TOKEN, or ensure WebSocket is available")
                return []

    async def _discover_entities_websocket(self, websocket: ClientWebSocketResponse) -> list[dict[str, Any]]:
        """
        Discover entities via WebSocket (fallback method)

        Args:
            websocket: Connected WebSocket client

        Returns:
            List of entity dictionaries
        """
        try:
            message_id = await self._get_next_id()
            logger.info("ðŸ”Œ Discovering entities via WebSocket (fallback)...")

            # Send entity registry list command
            await websocket.send_json({
                "id": message_id,
                "type": "config/entity_registry/list",
            })

            # Wait for response
            response = await self._wait_for_response(websocket, message_id, timeout=10.0)

            if not response or not response.get("success"):
                error_msg = response.get("error", {}).get("message", "Unknown error") if response else "No response"
                logger.error(f"âŒ Entity registry WebSocket command failed: {error_msg}")
                return []

            entities = response.get("result", [])
            entity_count = len(entities)
            logger.info(f"âœ… Discovered {entity_count} entities via WebSocket")

            # Epic 23.2: Build entity â†’ device and entity â†’ area mapping caches
            for entity in entities:
                entity_id = entity.get("entity_id")
                if entity_id:
                    # Store entity â†’ device mapping
                    device_id = entity.get("device_id")
                    if device_id:
                        self.entity_to_device[entity_id] = device_id

                    # Store entity â†’ area mapping (direct assignment)
                    area_id = entity.get("area_id")
                    if area_id:
                        self.entity_to_area[entity_id] = area_id

            logger.info(f"ðŸ”— Cached {len(self.entity_to_device)} entity â†’ device mappings")
            logger.info(f"ðŸ“ Cached {len(self.entity_to_area)} entity â†’ area mappings (direct)")

            # Update cache timestamp
            self._cache_timestamp = time.time()

            return entities

        except Exception as e:
            logger.exception(f"âŒ Error discovering entities via WebSocket: {e}")
            import traceback
            logger.exception(traceback.format_exc())
            return []

    async def discover_config_entries(self, websocket: ClientWebSocketResponse) -> list[dict[str, Any]]:
        """
        Discover all config entries (integrations) from Home Assistant

        Args:
            websocket: Connected WebSocket client

        Returns:
            List of config entry dictionaries

        Raises:
            Exception: If command fails or response is invalid
        """
        try:
            message_id = await self._get_next_id()
            logger.info("=" * 80)
            logger.info(f"ðŸ”§ DISCOVERING CONFIG ENTRIES (message_id: {message_id})")
            logger.info("=" * 80)

            # Send config entries list command
            await websocket.send_json({
                "id": message_id,
                "type": "config_entries/list",
            })

            logger.info("âœ… Config entries command sent, waiting for response...")

            # Wait for response
            response = await self._wait_for_response(websocket, message_id, timeout=10.0)

            if not response:
                logger.error("âŒ No response received for config entries command")
                return []

            if not response.get("success"):
                error_msg = response.get("error", {}).get("message", "Unknown error")
                logger.error(f"âŒ Config entries command failed: {error_msg}")
                return []

            config_entries = response.get("result", [])
            entry_count = len(config_entries)

            logger.info(f"âœ… Discovered {entry_count} config entries")

            # Log sample config entry if available
            if config_entries:
                sample = config_entries[0]
                logger.info(f"ðŸ”§ Sample config entry: {sample.get('title', 'Unknown')} "
                          f"(domain: {sample.get('domain', 'Unknown')}, "
                          f"state: {sample.get('state', 'Unknown')})")

            return config_entries

        except asyncio.TimeoutError:
            logger.exception("âŒ Timeout waiting for config entries response")
            return []
        except Exception as e:
            logger.exception(f"âŒ Error discovering config entries: {e}")
            import traceback
            logger.exception(traceback.format_exc())
            return []

    async def _wait_for_response(
        self,
        websocket: ClientWebSocketResponse,
        message_id: int,
        timeout: float = 10.0,
    ) -> dict[str, Any] | None:
        """
        Wait for response with specific message ID

        Args:
            websocket: WebSocket connection
            message_id: Message ID to wait for
            timeout: Timeout in seconds

        Returns:
            Response dictionary or None if timeout/error
        """
        try:
            start_time = asyncio.get_event_loop().time()

            while True:
                # Check timeout
                elapsed = asyncio.get_event_loop().time() - start_time
                if elapsed > timeout:
                    msg = f"Timeout waiting for message {message_id}"
                    raise asyncio.TimeoutError(msg)

                # Wait for message with remaining timeout
                remaining_timeout = timeout - elapsed
                msg = await asyncio.wait_for(
                    websocket.receive(),
                    timeout=remaining_timeout,
                )

                if msg.type == 1:  # TEXT message
                    data = msg.json()

                    # Check if this is our response
                    if data.get("id") == message_id:
                        return data
                    # Log and continue waiting for our message
                    logger.debug(f"Received message for different ID: {data.get('id')}, waiting for {message_id}")
                    continue
                logger.warning(f"Received non-text message type: {msg.type}")
                continue

        except asyncio.TimeoutError:
            raise
        except Exception as e:
            logger.exception(f"Error waiting for response: {e}")
            return None

    async def discover_all(self, websocket: ClientWebSocketResponse | None = None, store: bool = True) -> dict[str, Any]:
        """
        Discover all devices, entities, config entries, and services

        Uses HTTP API for devices and entities to avoid WebSocket concurrency issues.

        Args:
            websocket: Optional WebSocket client (deprecated, kept for backward compatibility)
            store: Whether to store results in SQLite via data-api (default: True)

        Returns:
            Dictionary with 'devices', 'entities', 'config_entries', and 'services' keys
        """
        logger.info("=" * 80)
        logger.info("ðŸš€ STARTING COMPLETE HOME ASSISTANT DISCOVERY")
        logger.info("=" * 80)

        # Use HTTP API for devices and entities (avoids WebSocket concurrency issues)
        devices_data = await self.discover_devices(websocket)
        entities_data = await self.discover_entities(websocket)
        # TEMPORARY: Skip config entries - command not supported in this HA version
        config_entries_data = []  # await self.discover_config_entries(websocket)

        # Discover services from HA Services API (Epic 2025) - already uses HTTP API
        services_data = await self.discover_services(websocket)

        logger.info("=" * 80)
        logger.info("âœ… DISCOVERY COMPLETE")
        logger.info(f"   Devices: {len(devices_data)}")
        logger.info(f"   Entities: {len(entities_data)}")
        logger.info(f"   Config Entries: {len(config_entries_data)}")
        logger.info(f"   Services: {len(services_data)} domains")
        logger.info("=" * 80)

        # Convert to models and store if requested
        # CRITICAL FIX: Always store to SQLite via data-api when store=True, regardless of influxdb_manager
        if store:
            logger.info("ðŸ’¾ Storing discovered data to SQLite via data-api...")
            logger.info(f"   Devices: {len(devices_data)}, Entities: {len(entities_data)}, Services: {len(services_data)}")
            await self.store_discovery_results(devices_data, entities_data, config_entries_data, services_data)
        else:
            logger.info("â„¹ï¸  Storage disabled - skipping store_discovery_results")

        return {
            "devices": devices_data,
            "entities": entities_data,
            "config_entries": config_entries_data,
            "services": services_data,
        }

    async def discover_services(self, websocket: ClientWebSocketResponse) -> dict[str, dict[str, Any]]:
        """
        Discover available services from Home Assistant Services API.

        Epic 2025: Fetch all available services per domain for service validation.

        Args:
            websocket: Connected WebSocket client

        Returns:
            Dictionary mapping domain -> {service_name -> service_data}
        """
        try:
            logger.info("ðŸ” Discovering services from HA Services API...")

            # Use HTTP API to fetch services (Services API doesn't have WebSocket command)
            import os

            import aiohttp

            ha_url = os.getenv("HA_HTTP_URL") or os.getenv("HOME_ASSISTANT_URL", "http://192.168.1.86:8123")
            ha_token = os.getenv("HA_TOKEN") or os.getenv("HOME_ASSISTANT_TOKEN")

            if not ha_token:
                logger.warning("âš ï¸  No HA token available for services discovery")
                return {}

            headers = {
                "Authorization": f"Bearer {ha_token}",
                "Content-Type": "application/json",
            }

            async with aiohttp.ClientSession() as session:
                async with session.get(f"{ha_url}/api/services", headers=headers) as response:
                    if response.status == 200:
                        services_data = await response.json()
                        logger.info(f"âœ… Retrieved {len(services_data)} service domains from HA")
                        return services_data
                    logger.warning(f"Failed to get services from HA: {response.status}")
                    return {}
        except Exception as e:
            logger.error(f"Error discovering services: {e}", exc_info=True)
            return {}

    async def store_discovery_results(
        self,
        devices_data: list[dict[str, Any]],
        entities_data: list[dict[str, Any]],
        config_entries_data: list[dict[str, Any]],
        services_data: dict[str, dict[str, Any]] | None = None,
    ) -> bool:
        """
        Store discovery results to SQLite (via data-api) and optionally to InfluxDB

        Args:
            devices_data: List of device dictionaries from HA
            entities_data: List of entity dictionaries from HA
            config_entries_data: List of config entry dictionaries from HA

        Returns:
            True if storage successful
        """
        import os

        import aiohttp

        try:
            # Primary storage: SQLite via data-api (simple HTTP POST)
            # Use service name from docker-compose (data-api) as default
            data_api_url = os.getenv("DATA_API_URL", "http://data-api:8006")
            api_key = os.getenv("DATA_API_API_KEY") or os.getenv("DATA_API_KEY") or os.getenv("API_KEY")

            # Create session with proper connector (disable SSL for internal HTTP)
            # Use connector_kwargs to ensure SSL is completely disabled
            connector = aiohttp.TCPConnector(
                ssl=False,
                limit=100,
                limit_per_host=30,
            )
            timeout = aiohttp.ClientTimeout(total=30)

            async with aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                connector_owner=True,
            ) as session:
                # Store devices to SQLite
                if devices_data:
                    try:
                        async with session.post(
                            f"{data_api_url}/internal/devices/bulk_upsert",
                            json=devices_data,
                            headers={"Authorization": f"Bearer {api_key}"} if api_key else None,
                            timeout=aiohttp.ClientTimeout(total=30),
                        ) as response:
                            if response.status == 200:
                                result = await response.json()
                                logger.info(f"âœ… Stored {result.get('upserted', 0)} devices to SQLite")
                            else:
                                error_text = await response.text()
                                logger.error(f"âŒ Failed to store devices to SQLite: {response.status} - {error_text}")
                    except Exception as e:
                        logger.exception(f"âŒ Error posting devices to data-api: {e}")

                # Store entities to SQLite
                if entities_data:
                    try:
                        headers = {}
                        if api_key:
                            headers["Authorization"] = f"Bearer {api_key}"
                        headers["Content-Type"] = "application/json"

                        async with session.post(
                            f"{data_api_url}/internal/entities/bulk_upsert",
                            json=entities_data,
                            headers=headers,
                            timeout=aiohttp.ClientTimeout(total=30),
                        ) as response:
                            if response.status == 200:
                                result = await response.json()
                                logger.info(f"âœ… Stored {result.get('upserted', 0)} entities to SQLite")
                            else:
                                error_text = await response.text()
                                logger.error(f"âŒ Failed to store entities to SQLite: {response.status} - {error_text}")
                    except Exception as e:
                        logger.exception(f"âŒ Error posting entities to data-api: {e}")

                # Store services to SQLite (Epic 2025) - with graceful degradation
                if services_data:
                    try:
                        headers = {}
                        if api_key:
                            headers["Authorization"] = f"Bearer {api_key}"
                        headers["Content-Type"] = "application/json"

                        # First, check if endpoint exists (optional - graceful degradation)
                        endpoint_url = f"{data_api_url}/internal/services/bulk_upsert"

                        async with session.post(
                            endpoint_url,
                            json=services_data,
                            headers=headers,
                            timeout=aiohttp.ClientTimeout(total=30),
                        ) as response:
                            if response.status == 200:
                                result = await response.json()
                                logger.info(f"âœ… Stored {result.get('upserted', 0)} services to SQLite")
                            elif response.status == 404:
                                # Endpoint doesn't exist - check if this is expected
                                # Log as warning but note it might indicate missing endpoint implementation
                                logger.warning("âš ï¸  Services bulk_upsert endpoint returned 404 (Not Found)")
                                logger.warning(f"   Endpoint: {endpoint_url}")
                                logger.warning("   This may indicate:")
                                logger.warning("   1. Endpoint not yet implemented in data-api (expected)")
                                logger.warning("   2. Incorrect endpoint URL (configuration issue)")
                                logger.warning("   Discovery will continue, but services will not be stored")
                            elif response.status in {401, 403}:
                                error_text = await response.text()
                                logger.error(f"âŒ Services storage failed: Authentication/Authorization error ({response.status})")
                                logger.error(f"   Error: {error_text}")
                                logger.error("   Check DATA_API_API_KEY or DATA_API_KEY environment variable")
                            else:
                                error_text = await response.text()
                                logger.warning(f"âš ï¸  Failed to store services to SQLite: HTTP {response.status}")
                                logger.warning(f"   Error: {error_text}")
                                logger.warning("   Discovery will continue, but services will not be stored")
                    except Exception as e:
                        # Don't fail entire operation if services storage fails
                        logger.warning(f"âš ï¸  Error posting services to data-api: {e}")
                        logger.info("ðŸ’¡ Services storage error is non-critical - discovery will continue")

            # Optional: Store snapshot to InfluxDB for historical tracking
            store_influx_history = os.getenv("STORE_DEVICE_HISTORY_IN_INFLUXDB", "false").lower() == "true"

            if store_influx_history and self.influxdb_manager:
                logger.info("ðŸ“Š Storing device history snapshot to InfluxDB...")

                # Convert devices to models for InfluxDB
                devices = []
                for device_data in devices_data:
                    try:
                        device = Device.from_ha_device(device_data)
                        device.validate()
                        devices.append(device)
                    except Exception as e:
                        logger.warning(f"âš ï¸  Skipping invalid device for InfluxDB: {e}")

                # Convert entities to models for InfluxDB
                entities = []
                for entity_data in entities_data:
                    try:
                        entity = Entity.from_ha_entity(entity_data)
                        entity.validate()
                        entities.append(entity)
                    except Exception as e:
                        logger.warning(f"âš ï¸  Skipping invalid entity for InfluxDB: {e}")

                # Batch write to InfluxDB
                if devices:
                    device_points = [d.to_influx_point() for d in devices]
                    success = await self.influxdb_manager.batch_write_devices(device_points, bucket="home_assistant_events")
                    if success:
                        logger.info(f"âœ… Stored {len(devices)} devices history to InfluxDB")

                if entities:
                    entity_points = [e.to_influx_point() for e in entities]
                    success = await self.influxdb_manager.batch_write_entities(entity_points, bucket="home_assistant_events")
                    if success:
                        logger.info(f"âœ… Stored {len(entities)} entities history to InfluxDB")

            logger.info("=" * 80)
            logger.info("âœ… STORAGE COMPLETE")
            if services_data:
                # Fix: Handle both dict and list formats
                if isinstance(services_data, dict):
                    total_services = sum(len(domain_services) for domain_services in services_data.values())
                    logger.info(f"   Services: {total_services} total services across {len(services_data)} domains")
                elif isinstance(services_data, list):
                    logger.info(f"   Services: {len(services_data)} services")
            logger.info("=" * 80)

            return True

        except Exception as e:
            logger.exception(f"âŒ Error storing discovery results: {e}")
            import traceback
            logger.exception(traceback.format_exc())
            return False

    async def subscribe_to_device_registry_events(self, websocket: ClientWebSocketResponse) -> bool:
        """
        Subscribe to device registry update events

        Args:
            websocket: Connected WebSocket client

        Returns:
            True if subscription successful
        """
        try:
            message_id = await self._get_next_id()
            logger.info("ðŸ“± Subscribing to device registry update events...")

            await websocket.send_json({
                "id": message_id,
                "type": "subscribe_events",
                "event_type": "device_registry_updated",
            })

            # Wait for subscription confirmation
            response = await self._wait_for_response(websocket, message_id, timeout=5.0)

            if response and response.get("success"):
                logger.info("âœ… Subscribed to device registry events")
                return True
            logger.error("âŒ Failed to subscribe to device registry events")
            return False

        except Exception as e:
            logger.exception(f"âŒ Error subscribing to device registry events: {e}")
            return False

    async def subscribe_to_entity_registry_events(self, websocket: ClientWebSocketResponse) -> bool:
        """
        Subscribe to entity registry update events

        Args:
            websocket: Connected WebSocket client

        Returns:
            True if subscription successful
        """
        try:
            message_id = await self._get_next_id()
            logger.info("ðŸ”Œ Subscribing to entity registry update events...")

            await websocket.send_json({
                "id": message_id,
                "type": "subscribe_events",
                "event_type": "entity_registry_updated",
            })

            # Wait for subscription confirmation
            response = await self._wait_for_response(websocket, message_id, timeout=5.0)

            if response and response.get("success"):
                logger.info("âœ… Subscribed to entity registry events")
                return True
            logger.error("âŒ Failed to subscribe to entity registry events")
            return False

        except Exception as e:
            logger.exception(f"âŒ Error subscribing to entity registry events: {e}")
            return False

    async def handle_device_registry_event(self, event: dict[str, Any]) -> bool:
        """
        Handle device registry update event

        Args:
            event: Event data from Home Assistant

        Returns:
            True if handled successfully
        """
        try:
            data = event.get("data", {})
            action = data.get("action", "unknown")
            device_data = data.get("device", {})
            device_id = data.get("device_id", "unknown")

            logger.info("=" * 80)
            logger.info(f"ðŸ“± DEVICE REGISTRY EVENT: {action.upper()}")
            logger.info(f"   Device ID: {device_id}")
            if device_data:
                logger.info(f"   Name: {device_data.get('name', 'Unknown')}")
                logger.info(f"   Manufacturer: {device_data.get('manufacturer', 'Unknown')}")
            logger.info("=" * 80)

            # Store update if we have InfluxDB and device data
            if self.influxdb_manager and device_data:
                try:
                    device = Device.from_ha_device(device_data)
                    device.validate()
                    point = device.to_influx_point()
                    await self.influxdb_manager.write_device(point, bucket="home_assistant_events")
                    logger.info("âœ… Stored device update in InfluxDB")
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to store device update: {e}")

            return True

        except Exception as e:
            logger.exception(f"âŒ Error handling device registry event: {e}")
            return False

    async def handle_entity_registry_event(self, event: dict[str, Any]) -> bool:
        """
        Handle entity registry update event

        Args:
            event: Event data from Home Assistant

        Returns:
            True if handled successfully
        """
        try:
            data = event.get("data", {})
            action = data.get("action", "unknown")
            entity_data = data.get("entity", {})
            entity_id = data.get("entity_id", "unknown")

            logger.info("=" * 80)
            logger.info(f"ðŸ”Œ ENTITY REGISTRY EVENT: {action.upper()}")
            logger.info(f"   Entity ID: {entity_id}")
            if entity_data:
                logger.info(f"   Platform: {entity_data.get('platform', 'Unknown')}")
            logger.info("=" * 80)

            # Store update if we have InfluxDB and entity data
            if self.influxdb_manager and entity_data:
                try:
                    entity = Entity.from_ha_entity(entity_data)
                    entity.validate()
                    point = entity.to_influx_point()
                    await self.influxdb_manager.write_entity(point, bucket="home_assistant_events")
                    logger.info("âœ… Stored entity update in InfluxDB")
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to store entity update: {e}")

            # Epic 23.2: Update mapping caches on entity registry events
            if entity_id and entity_data:
                device_id = entity_data.get("device_id")
                if device_id:
                    self.entity_to_device[entity_id] = device_id

                area_id = entity_data.get("area_id")
                if area_id:
                    self.entity_to_area[entity_id] = area_id

                logger.debug(f"Updated mapping cache for entity {entity_id}")

            return True

        except Exception as e:
            logger.exception(f"âŒ Error handling entity registry event: {e}")
            return False

    # Epic 23.2: Helper methods for device/area lookup
    def get_device_id(self, entity_id: str) -> str | None:
        """
        Get device_id for an entity

        Args:
            entity_id: The entity ID to look up

        Returns:
            device_id if found, None otherwise
        """
        # Check if cache is stale and log warning
        self._check_cache_freshness()
        return self.entity_to_device.get(entity_id)

    def get_area_id(self, entity_id: str, device_id: str | None = None) -> str | None:
        """
        Get area_id for an entity or device

        Checks in this order:
        1. Entity direct area assignment
        2. Device area assignment (if device_id provided or looked up)

        Args:
            entity_id: The entity ID to look up
            device_id: Optional device ID (will be looked up if not provided)

        Returns:
            area_id if found, None otherwise
        """
        # Check entity-level area first (direct assignment)
        entity_area = self.entity_to_area.get(entity_id)
        if entity_area:
            return entity_area

        # Fallback to device-level area
        if not device_id:
            device_id = self.get_device_id(entity_id)

        if device_id:
            return self.device_to_area.get(device_id)

        return None

    # Epic 23.5: Helper method for device metadata lookup
    def get_device_metadata(self, device_id: str) -> dict[str, Any] | None:
        """
        Get device metadata (manufacturer, model, sw_version)

        Args:
            device_id: The device ID to look up

        Returns:
            Device metadata dict if found, None otherwise
        """
        return self.device_metadata.get(device_id)

    def _check_cache_freshness(self):
        """
        Check if cache is stale and log warning if needed.

        Cache is considered stale if it's older than TTL and has entries.
        This helps identify when discovery hasn't run recently.

        Only logs warning once per interval to avoid log spam.
        """
        if self._cache_timestamp and len(self.entity_to_device) > 0:
            cache_age = time.time() - self._cache_timestamp
            if cache_age > self._cache_ttl_seconds:
                # Only log warning if we haven't warned recently
                current_time = time.time()
                should_warn = (
                    self._last_stale_warning_timestamp is None or
                    (current_time - self._last_stale_warning_timestamp) > self._stale_warning_interval
                )

                if should_warn:
                    logger.warning(
                        f"âš ï¸ Discovery cache is stale ({cache_age/60:.1f} minutes old, "
                        f"TTL: {self._cache_ttl_seconds/60:.1f} minutes). "
                        f"Consider triggering discovery to refresh device/area mappings.",
                    )
                    self._last_stale_warning_timestamp = current_time

    def is_cache_stale(self) -> bool:
        """
        Check if cache is stale.

        Returns:
            True if cache is older than TTL, False otherwise
        """
        if not self._cache_timestamp or len(self.entity_to_device) == 0:
            return True  # Empty cache is considered stale
        cache_age = time.time() - self._cache_timestamp
        return cache_age > self._cache_ttl_seconds

    def clear_caches(self):
        """
        Clear all mapping caches.

        Useful when discovery fails or needs to be reset.
        """
        self.entity_to_device.clear()
        self.device_to_area.clear()
        self.entity_to_area.clear()
        self.device_metadata.clear()
        self._cache_timestamp = None
        logger.info("ðŸ§¹ Discovery caches cleared")

    def get_cache_statistics(self) -> dict[str, Any]:
        """
        Get statistics about mapping caches

        Returns:
            Dictionary with cache statistics
        """
        cache_age_minutes = None
        if self._cache_timestamp:
            cache_age_minutes = (time.time() - self._cache_timestamp) / 60

        return {
            "entity_to_device_mappings": len(self.entity_to_device),
            "device_to_area_mappings": len(self.device_to_area),
            "entity_to_area_mappings": len(self.entity_to_area),
            "device_metadata_entries": len(self.device_metadata),
            "cache_age_minutes": round(cache_age_minutes, 1) if cache_age_minutes else None,
            "cache_ttl_minutes": self._cache_ttl_seconds / 60,
            "is_stale": self.is_cache_stale(),
        }


"""
Device Intelligence Service - Discovery Service

Main discovery service that orchestrates device discovery from multiple sources.
"""

import asyncio
import logging
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Any

from sqlalchemy.ext.asyncio import AsyncSession

from ..clients.ha_client import HAArea, HADevice, HAEntity
from ..clients.mqtt_client import MQTTClient, ZigbeeDevice, ZigbeeGroup
from ..config import Settings
from ..core.database import get_db_session
from ..services.device_service import DeviceService
from ..services.hygiene_analyzer import DeviceHygieneAnalyzer
from ..services.name_enhancement import DeviceNameGenerator, NameUniquenessValidator
from .cache import get_device_cache
from .device_parser import DeviceParser, UnifiedDevice

logger = logging.getLogger(__name__)


@dataclass
class DiscoveryStatus:
    """Discovery service status."""
    service_running: bool
    ha_connected: bool
    mqtt_connected: bool
    last_discovery: datetime | None
    devices_count: int
    areas_count: int
    errors: list[str]


class DiscoveryService:
    """Main discovery service orchestrating device discovery from multiple sources."""

    def __init__(self, settings: Settings):
        self.settings = settings

        # Clients - HA client will be initialized with unified connection manager
        self.ha_client = None  # Will be initialized in start() method
        self.mqtt_client = MQTTClient(
            settings.MQTT_BROKER,
            settings.MQTT_USERNAME,
            settings.MQTT_PASSWORD,
            settings.ZIGBEE2MQTT_BASE_TOPIC
        )

        # Parser
        self.device_parser = DeviceParser()

        # Name enhancement components (optional, can be disabled)
        self.auto_generate_name_suggestions = getattr(settings, 'AUTO_GENERATE_NAME_SUGGESTIONS', False)
        self.name_generator = None
        self.name_validator = None
        self.batch_processor = None
        if self.auto_generate_name_suggestions:
            from ..services.name_enhancement import PreferenceLearner
            from ..services.name_enhancement.batch_processor import NameEnhancementBatchProcessor
            
            self.name_generator = DeviceNameGenerator(settings)
            self.name_validator = NameUniquenessValidator()
            self.preference_learner = PreferenceLearner()
            self.batch_processor = NameEnhancementBatchProcessor(self.name_generator, settings)

        # State
        self.running = False
        self.discovery_task: asyncio.Task | None = None
        self.last_discovery: datetime | None = None
        self.errors: list[str] = []

        # Data
        self.unified_devices: dict[str, UnifiedDevice] = {}
        self.ha_devices: list[HADevice] = []
        self.ha_entities: list[HAEntity] = []
        self.ha_areas: list[HAArea] = []
        self.ha_config_entries: dict[str, str] = {}  # Maps config_entry_id -> domain/integration
        self.zigbee_devices: dict[str, ZigbeeDevice] = {}
        self.zigbee_groups: dict[int, ZigbeeGroup] = {}

    async def start(self) -> bool:
        """Start the discovery service."""
        try:
            logger.info("üöÄ Starting Device Intelligence Discovery Service")

            # Initialize HA client with configured settings
            from ..clients.ha_client import HomeAssistantClient
            self.ha_client = HomeAssistantClient(
                self.settings.HA_URL,
                None,  # No fallback URL for now
                self.settings.HA_TOKEN
            )

            # Connect to Home Assistant
            if not await self.ha_client.connect():
                logger.error("‚ùå Failed to connect to Home Assistant")
                return False

            # Start HA message handler
            await self.ha_client.start_message_handler()

            # Subscribe to registry update events for real-time cache updates
            await self._subscribe_to_registry_updates()

            # Connect to MQTT broker (optional - can discover HA devices without Zigbee)
            if await self.mqtt_client.connect():
                logger.info("‚úÖ Connected to MQTT broker")
                # Register MQTT message handlers
                self.mqtt_client.register_message_handler("devices", self._on_zigbee_devices_update)
                self.mqtt_client.register_message_handler("groups", self._on_zigbee_groups_update)
            else:
                logger.warning("‚ö†Ô∏è  MQTT broker connection failed - will continue without Zigbee devices")

            # Start discovery task
            self.running = True
            self.discovery_task = asyncio.create_task(self._discovery_loop())

            # Start batch processor if enabled
            if self.batch_processor:
                try:
                    self.batch_processor.start()
                    logger.info("‚úÖ Name enhancement batch processor started")
                except Exception as e:
                    logger.warning(f"Failed to start batch processor: {e}")

            logger.info("‚úÖ Discovery service started successfully")
            return True

        except Exception as e:
            logger.error(f"‚ùå Failed to start discovery service: {e}")
            self.errors.append(f"Startup error: {str(e)}")
            return False

    async def stop(self):
        """Stop the discovery service."""
        logger.info("üõë Stopping Discovery Service")

        self.running = False

        # Cancel discovery task
        if self.discovery_task:
            self.discovery_task.cancel()
            try:
                await self.discovery_task
            except asyncio.CancelledError:
                pass

        # Stop batch processor
        if self.batch_processor:
            self.batch_processor.stop()

        # Disconnect clients
        if self.ha_client:
            await self.ha_client.disconnect()
        await self.mqtt_client.disconnect()

        logger.info("‚úÖ Discovery service stopped")

    async def _discovery_loop(self):
        """Main discovery loop."""
        logger.info("üîÑ Starting discovery loop")

        # Initial discovery
        await self._perform_discovery()

        # Periodic discovery
        while self.running:
            try:
                await asyncio.sleep(300)  # 5 minutes
                if self.running:
                    await self._perform_discovery()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"‚ùå Error in discovery loop: {e}")
                self.errors.append(f"Discovery loop error: {str(e)}")
                await asyncio.sleep(60)  # Wait before retry

    async def _perform_discovery(self):
        """Perform full device discovery."""
        try:
            logger.info("üîç Performing device discovery")

            # Discover Home Assistant data
            await self._discover_home_assistant()

            # Discover Zigbee2MQTT data (already handled by MQTT callbacks)
            # But we can trigger a refresh if needed
            await self._refresh_zigbee_data()

            # Parse and unify device data
            await self._unify_device_data()
            await self._run_hygiene_analysis()

            # Update last discovery timestamp
            self.last_discovery = datetime.now(timezone.utc)
            logger.info(f"‚úÖ Discovery completed at {self.last_discovery.isoformat()}: {len(self.unified_devices)} devices")

        except Exception as e:
            logger.error(f"‚ùå Error during discovery: {e}")
            self.errors.append(f"Discovery error: {str(e)}")

    async def _run_hygiene_analysis(self):
        """Analyze device hygiene and persist findings."""
        try:
            async for session in get_db_session():
                analyzer = DeviceHygieneAnalyzer(session)
                await analyzer.analyze(self.ha_devices, self.ha_entities, self.ha_areas)
                break
        except Exception as e:
            logger.error(f"‚ùå Error during hygiene analysis: {e}")
            self.errors.append(f"Hygiene analysis error: {str(e)}")

    async def _discover_home_assistant(self):
        """Discover devices, entities, and areas from Home Assistant."""
        try:
            logger.info("üè† Discovering Home Assistant data")

            # Get config entries first (needed to resolve integrations)
            self.ha_config_entries = await self.ha_client.get_config_entries()

            # Get device registry
            self.ha_devices = await self.ha_client.get_device_registry()

            # Get entity registry
            self.ha_entities = await self.ha_client.get_entity_registry()

            # Get area registry
            self.ha_areas = await self.ha_client.get_area_registry()

            # Update parser with areas and config entries
            self.device_parser.update_areas(self.ha_areas)
            self.device_parser.update_config_entries(self.ha_config_entries)

            logger.info(f"üì± HA Discovery: {len(self.ha_devices)} devices, {len(self.ha_entities)} entities, {len(self.ha_areas)} areas, {len(self.ha_config_entries)} config entries")

        except Exception as e:
            logger.error(f"‚ùå Error discovering Home Assistant data: {e}")
            raise

    async def _subscribe_to_registry_updates(self):
        """
        Subscribe to entity and device registry update events.
        
        This keeps the cache fresh by triggering discovery when entities/devices
        are added, removed, or modified in Home Assistant.
        """
        try:
            async def handle_entity_registry_update(event_data: dict[str, Any]):
                """Handle entity registry update event."""
                action = event_data.get("event", {}).get("action", "unknown")
                entity_id = event_data.get("event", {}).get("entity_id", "unknown")
                logger.info(f"üìã Entity registry updated: {action} - {entity_id}")

                # Trigger incremental update for entity changes
                if action in ["create", "update", "remove"]:
                    logger.info(f"üîÑ Triggering incremental discovery due to entity {action}")
                    # Perform a lightweight discovery update (just HA entities)
                    await self._discover_home_assistant()
                    await self._unify_device_data()

            async def handle_device_registry_update(event_data: dict[str, Any]):
                """Handle device registry update event."""
                action = event_data.get("event", {}).get("action", "unknown")
                device_id = event_data.get("event", {}).get("device_id", "unknown")
                logger.info(f"üì± Device registry updated: {action} - {device_id}")

                # Trigger incremental update for device changes
                if action in ["create", "update", "remove"]:
                    logger.info(f"üîÑ Triggering incremental discovery due to device {action}")
                    # Perform a lightweight discovery update (just HA devices/entities)
                    await self._discover_home_assistant()
                    await self._unify_device_data()

            await self.ha_client.subscribe_to_registry_updates(
                entity_callback=handle_entity_registry_update,
                device_callback=handle_device_registry_update
            )

            logger.info("‚úÖ Subscribed to registry update events")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to subscribe to registry updates: {e}")
            # Don't fail startup if subscriptions fail - we still have periodic discovery

    async def _refresh_zigbee_data(self):
        """Refresh Zigbee2MQTT data by requesting bridge info."""
        try:
            # Request bridge devices (this will trigger MQTT callback)
            if self.mqtt_client.is_connected():
                base_topic = self.mqtt_client.base_topic
                # Publish request for bridge devices
                request_topic = f"{base_topic}/bridge/request/device/list"
                self.mqtt_client.client.publish(request_topic, "{}")  # Empty JSON payload
                logger.debug(f"üì° Requested Zigbee2MQTT device list refresh via {request_topic}")

                # Also request groups
                group_request_topic = f"{base_topic}/bridge/request/group/list"
                self.mqtt_client.client.publish(group_request_topic, "{}")
                logger.debug(f"üì° Requested Zigbee2MQTT group list refresh via {group_request_topic}")

        except Exception as e:
            logger.error(f"‚ùå Error refreshing Zigbee data: {e}")

    async def _unify_device_data(self):
        """Unify device data from all sources."""
        try:
            logger.info("üîÑ Unifying device data from all sources")

            # Parse devices
            unified_devices = self.device_parser.parse_devices(
                self.ha_devices,
                self.ha_entities,
                self.zigbee_devices
            )

            # Update unified devices in memory
            self.unified_devices = {device.id: device for device in unified_devices}

            # Store devices in database
            await self._store_devices_in_database(unified_devices)

            # Invalidate cache for all updated devices (device-level invalidation)
            cache = get_device_cache()
            for device in unified_devices:
                await cache.delete(device.id)

            if unified_devices:
                logger.info(f"‚úÖ Unified {len(self.unified_devices)} devices and invalidated cache")

        except Exception as e:
            logger.error(f"‚ùå Error unifying device data: {e}")
            raise

    async def _store_devices_in_database(self, unified_devices: list[UnifiedDevice]):
        """Store unified devices and their capabilities in the database."""
        try:
            logger.info(f"üíæ Storing {len(unified_devices)} devices in database")

            # Convert UnifiedDevice objects to database format
            devices_data = []
            capabilities_data = []
            missing_integrations = []

            for device in unified_devices:
                integration_value = (device.integration or "").strip()
                if not integration_value:
                    missing_integrations.append(device.id)
                    integration_value = "unknown"

                device_data = {
                    "id": device.id,
                    "name": device.name,
                    "manufacturer": device.manufacturer,
                    "model": device.model,
                    "area_id": device.area_id,
                    "area_name": device.area_name,  # Include area_name
                    "integration": integration_value,
                    "device_class": device.device_class,
                    "sw_version": device.sw_version,
                    "hw_version": device.hw_version,
                    "power_source": device.power_source,
                    "via_device_id": device.via_device_id,
                    "disabled_by": device.disabled_by,
                    "last_seen": device.last_seen,
                    "health_score": device.health_score,
                    "is_battery_powered": device.power_source == "Battery" if device.power_source else False,
                    "created_at": device.created_at,
                    "updated_at": device.updated_at,
                    # Initialize all optional fields with None to ensure consistency
                    "config_entry_id": None,
                    "connections_json": None,
                    "identifiers_json": None,
                    "zigbee_ieee": None,
                    "name_by_user": None,
                    "suggested_area": None,
                    "entry_type": None,
                    "configuration_url": None,
                    # Initialize Zigbee2MQTT fields
                    "lqi": None,
                    "lqi_updated_at": None,
                    "availability_status": None,
                    "availability_updated_at": None,
                    "battery_level": None,
                    "battery_low": None,
                    "battery_updated_at": None,
                    "device_type": None,
                    "source": None
                }

                # Override with actual values if available
                if device.ha_device:
                    if device.ha_device.config_entries:
                        device_data["config_entry_id"] = device.ha_device.config_entries[0] if device.ha_device.config_entries else None
                    # SKIP JSON fields for now due to SQLAlchemy insert issues
                    # if device.ha_device.connections:
                    #     device_data["connections_json"] = json.dumps(device.ha_device.connections)
                    # if device.ha_device.identifiers:
                    #     device_data["identifiers_json"] = json.dumps(device.ha_device.identifiers)
                    # Extract zigbee IEEE address if present
                    if device.ha_device.identifiers:
                        for identifier in device.ha_device.identifiers:
                            if len(identifier) >= 2 and identifier[0] == "zha":
                                device_data["zigbee_ieee"] = identifier[1]
                                break
                    # Add new HA device attributes
                    device_data["name_by_user"] = device.ha_device.name_by_user
                    device_data["suggested_area"] = device.ha_device.suggested_area
                    device_data["entry_type"] = device.ha_device.entry_type
                    device_data["configuration_url"] = device.ha_device.configuration_url
                    
                    # Set source based on HA device integration if Zigbee2MQTT
                    # This allows Zigbee devices to be identified even without MQTT data
                    # Note: Zigbee2MQTT devices in HA may use 'mqtt' as integration name
                    integration_lower = integration_value.lower()
                    if ('zigbee' in integration_lower or 
                        integration_lower == 'zigbee2mqtt' or
                        integration_lower == 'mqtt'):
                        # For MQTT integration, check if it's a Zigbee device by checking identifiers
                        # Zigbee devices typically have identifiers with 'ieee' or 'zigbee' patterns
                        is_zigbee = False
                        if integration_lower == 'mqtt':
                            # Check if device has Zigbee-like identifiers
                            identifiers = device.ha_device.identifiers or []
                            for identifier in identifiers:
                                identifier_str = str(identifier).lower()
                                if 'zigbee' in identifier_str or 'ieee' in identifier_str:
                                    is_zigbee = True
                                    break
                            # Only set source to zigbee2mqtt if we confirm it's a Zigbee device
                            if not is_zigbee:
                                continue
                        
                        device_data["source"] = "zigbee2mqtt"
                        # Ensure integration field is set correctly
                        if device.ha_device.integration:
                            device_data["integration"] = device.ha_device.integration

                # Add Zigbee2MQTT data if available (from MQTT - this will override source if MQTT data exists)
                if device.zigbee_device:
                    device_data["zigbee_ieee"] = device.zigbee_device.ieee_address
                    device_data["source"] = "zigbee2mqtt"
                    
                    # Zigbee2MQTT-specific fields
                    if device.zigbee_device.lqi is not None:
                        device_data["lqi"] = device.zigbee_device.lqi
                        device_data["lqi_updated_at"] = datetime.now(timezone.utc)
                    
                    if device.zigbee_device.availability:
                        device_data["availability_status"] = device.zigbee_device.availability
                        device_data["availability_updated_at"] = datetime.now(timezone.utc)
                    
                    if device.zigbee_device.battery is not None:
                        device_data["battery_level"] = device.zigbee_device.battery
                        device_data["battery_updated_at"] = datetime.now(timezone.utc)
                    
                    if device.zigbee_device.battery_low is not None:
                        device_data["battery_low"] = device.zigbee_device.battery_low
                    
                    if device.zigbee_device.device_type:
                        device_data["device_type"] = device.zigbee_device.device_type
                    
                    # Update last_seen from Zigbee2MQTT if available
                    if device.zigbee_device.last_seen:
                        device_data["last_seen"] = device.zigbee_device.last_seen

                # Remove the JSON fields that were initialized to None to avoid SQLAlchemy issues
                device_data.pop("connections_json", None)
                device_data.pop("identifiers_json", None)

                devices_data.append(device_data)

                # Store capabilities for this device
                if device.capabilities:
                    for capability in device.capabilities:
                        capability_data = {
                            "device_id": device.id,
                            "capability_name": capability.get("name", ""),
                            "capability_type": capability.get("type", ""),
                            "properties": capability.get("properties", {}),
                            "exposed": capability.get("exposed", True),
                            "configured": capability.get("configured", True),
                            "source": capability.get("source", "unknown"),
                            "last_updated": datetime.now(timezone.utc)
                        }
                        capabilities_data.append(capability_data)

            if missing_integrations:
                logger.warning(
                    "‚ö†Ô∏è %d devices missing integration metadata (showing up to 5 IDs): %s",
                    len(missing_integrations),
                    missing_integrations[:5],
                )

            # Store in database using DeviceService
            async for session in get_db_session():
                device_service = DeviceService(session)
                await device_service.bulk_upsert_devices(devices_data)

                # Store capabilities if any
                if capabilities_data:
                    await device_service.bulk_upsert_capabilities(capabilities_data)
                
                # Store Zigbee2MQTT metadata if available
                await self._store_zigbee_metadata(session, unified_devices)

                # NEW: Generate name suggestions (optional, non-blocking)
                if self.auto_generate_name_suggestions and self.name_generator:
                    # Load validator cache if needed
                    if self.name_validator and not self.name_validator._cache_loaded:
                        await self.name_validator.load_cache(session)
                    
                    # Generate suggestions in background (don't block discovery)
                    asyncio.create_task(
                        self._generate_name_suggestions_async(unified_devices, session)
                    )

                break  # Only need one session

            logger.info(f"‚úÖ Stored {len(devices_data)} devices and {len(capabilities_data)} capabilities in database")

        except Exception as e:
            logger.error(f"‚ùå Error storing devices in database: {e}")
            raise

    async def _on_zigbee_devices_update(self, data: list[dict[str, Any]]):
        """Handle Zigbee2MQTT devices update."""
        try:
            logger.info(f"üì± Zigbee2MQTT devices updated: {len(data)} devices")

            # Update Zigbee devices
            for device_data in data:
                # Parse last_seen with timezone handling
                last_seen = None
                if device_data.get("last_seen"):
                    try:
                        last_seen_str = device_data["last_seen"].replace('Z', '+00:00')
                        last_seen = datetime.fromisoformat(last_seen_str)
                    except Exception as e:
                        logger.debug(f"Could not parse last_seen for {device_data.get('ieee_address')}: {e}")
                
                # Extract Zigbee2MQTT-specific fields
                definition = device_data.get("definition", {})
                
                zigbee_device = ZigbeeDevice(
                    ieee_address=device_data["ieee_address"],
                    friendly_name=device_data["friendly_name"],
                    model=device_data.get("model", ""),
                    description=device_data.get("description", ""),
                    manufacturer=device_data.get("manufacturer", ""),
                    manufacturer_code=device_data.get("manufacturer_code"),
                    power_source=device_data.get("power_source"),
                    model_id=device_data.get("model_id"),
                    hardware_version=device_data.get("hardware_version"),
                    software_build_id=device_data.get("software_build_id"),
                    date_code=device_data.get("date_code"),
                    last_seen=last_seen,
                    definition=definition,
                    exposes=definition.get("exposes", []),
                    capabilities={},
                    # Zigbee2MQTT-specific fields
                    lqi=device_data.get("lqi"),
                    availability=device_data.get("availability"),
                    battery=device_data.get("battery"),
                    battery_low=device_data.get("battery_low"),
                    device_type=device_data.get("type"),
                    network_address=device_data.get("network_address"),
                    supported=device_data.get("supported"),
                    interview_completed=device_data.get("interview_completed"),
                    settings=device_data.get("settings")
                )

                self.zigbee_devices[zigbee_device.ieee_address] = zigbee_device

            # Trigger device unification
            await self._unify_device_data()

        except Exception as e:
            logger.error(f"‚ùå Error handling Zigbee devices update: {e}")

    async def _on_zigbee_groups_update(self, data: list[dict[str, Any]]):
        """Handle Zigbee2MQTT groups update."""
        try:
            logger.info(f"üë• Zigbee2MQTT groups updated: {len(data)} groups")

            # Update Zigbee groups
            for group_data in data:
                group = ZigbeeGroup(
                    id=group_data["id"],
                    friendly_name=group_data["friendly_name"],
                    members=group_data.get("members", []),
                    scenes=group_data.get("scenes", [])
                )

                self.zigbee_groups[group.id] = group

        except Exception as e:
            logger.error(f"‚ùå Error handling Zigbee groups update: {e}")

    async def force_refresh(self) -> bool:
        """Force a complete discovery refresh."""
        try:
            logger.info("üîÑ Forcing discovery refresh")
            await self._perform_discovery()
            return True
        except Exception as e:
            logger.error(f"‚ùå Error during forced refresh: {e}")
            return False

    def get_status(self) -> DiscoveryStatus:
        """Get discovery service status."""
        return DiscoveryStatus(
            service_running=self.running,
            ha_connected=self.ha_client.is_connected() if self.ha_client else False,
            mqtt_connected=self.mqtt_client.is_connected(),
            last_discovery=self.last_discovery,
            devices_count=len(self.unified_devices),
            areas_count=len(self.ha_areas),
            errors=self.errors[-10:]  # Last 10 errors
        )

    def get_devices(self) -> list[UnifiedDevice]:
        """Get all discovered devices."""
        return list(self.unified_devices.values())

    def get_device(self, device_id: str) -> UnifiedDevice | None:
        """Get specific device by ID."""
        return self.unified_devices.get(device_id)

    def get_devices_by_area(self, area_id: str) -> list[UnifiedDevice]:
        """Get devices by area ID."""
        return [d for d in self.unified_devices.values() if d.area_id == area_id]

    def get_devices_by_integration(self, integration: str) -> list[UnifiedDevice]:
        """Get devices by integration type."""
        return [d for d in self.unified_devices.values() if d.integration == integration]

    def get_areas(self) -> list[HAArea]:
        """Get all discovered areas."""
        return self.ha_areas.copy()

    def get_zigbee_groups(self) -> list[ZigbeeGroup]:
        """Get all discovered Zigbee groups."""
        return list(self.zigbee_groups.values())

    async def _generate_name_suggestions_async(
        self,
        unified_devices: list[UnifiedDevice],
        db_session: AsyncSession
    ):
        """Generate name suggestions asynchronously (non-blocking)"""
        if not self.name_generator or not self.name_validator:
            return

        try:
            from ..models.database import Device, DeviceEntity
            from ..models.name_enhancement import NameSuggestion
            from sqlalchemy import select

            suggestions_created = 0
            
            for unified_device in unified_devices:
                try:
                    # Get device from database
                    result = await db_session.execute(
                        select(Device).where(Device.id == unified_device.id)
                    )
                    device = result.scalar_one_or_none()
                    
                    if not device:
                        continue

                    # Skip if device already has name_by_user (user customized)
                    if device.name_by_user:
                        continue

                    # Get primary entity for this device
                    entity_result = await db_session.execute(
                        select(DeviceEntity).where(
                            DeviceEntity.device_id == device.id
                        ).limit(1)
                    )
                    entity = entity_result.scalar_one_or_none()

                    # Generate suggestion
                    suggestion = await self.name_generator.generate_suggested_name(
                        device, entity
                    )

                    # Only store high-confidence suggestions
                    if suggestion.confidence >= 0.7:
                        # Validate uniqueness
                        validation = await self.name_validator.validate_uniqueness(
                            suggestion.name,
                            device_id=device.id,
                            entity_id=entity.entity_id if entity else None,
                            db_session=db_session
                        )

                        if not validation.is_unique:
                            # Generate unique variant
                            unique_name = await self.name_validator.generate_unique_variant(
                                suggestion.name,
                                device,
                                db_session=db_session
                            )
                            suggestion.name = unique_name

                        # Check if suggestion already exists
                        existing_result = await db_session.execute(
                            select(NameSuggestion).where(
                                NameSuggestion.device_id == device.id,
                                NameSuggestion.suggested_name == suggestion.name,
                                NameSuggestion.status == "pending"
                            )
                        )
                        if existing_result.scalar_one_or_none():
                            continue  # Already exists

                        # Store suggestion
                        name_suggestion = NameSuggestion(
                            device_id=device.id,
                            entity_id=entity.entity_id if entity else None,
                            original_name=device.name or "Unknown",
                            suggested_name=suggestion.name,
                            confidence_score=suggestion.confidence,
                            suggestion_source=suggestion.source,
                            status="pending",
                            reasoning=suggestion.reasoning
                        )
                        db_session.add(name_suggestion)
                        suggestions_created += 1

                        # Add to validator cache
                        self.name_validator.name_cache.add(
                            self.name_validator._normalize_name(suggestion.name)
                        )

                except Exception as e:
                    logger.warning(f"Failed to generate name suggestion for device {unified_device.id}: {e}")
                    continue

            if suggestions_created > 0:
                await db_session.commit()
                logger.info(f"‚úÖ Generated {suggestions_created} name suggestions")

        except Exception as e:
            logger.warning(f"Name suggestion generation failed: {e}")
            # Graceful degradation: continue without suggestions

    async def _store_zigbee_metadata(self, session: AsyncSession, unified_devices: list[UnifiedDevice]):
        """Store Zigbee2MQTT-specific metadata in ZigbeeDeviceMetadata table."""
        try:
            from ..models.database import ZigbeeDeviceMetadata
            from sqlalchemy import select
            
            metadata_to_store = []
            
            for device in unified_devices:
                if not device.zigbee_device:
                    continue
                
                zigbee = device.zigbee_device
                
                # Check if metadata already exists
                result = await session.execute(
                    select(ZigbeeDeviceMetadata).where(
                        ZigbeeDeviceMetadata.device_id == device.id
                    )
                )
                existing = result.scalar_one_or_none()
                
                metadata_data = {
                    "device_id": device.id,
                    "ieee_address": zigbee.ieee_address,
                    "model_id": zigbee.model_id,
                    "manufacturer_code": zigbee.manufacturer_code,
                    "date_code": zigbee.date_code,
                    "hardware_version": zigbee.hardware_version,
                    "software_build_id": zigbee.software_build_id,
                    "network_address": zigbee.network_address,
                    "supported": zigbee.supported if zigbee.supported is not None else True,
                    "interview_completed": zigbee.interview_completed if zigbee.interview_completed is not None else False,
                    "definition_json": zigbee.definition,
                    "settings_json": zigbee.settings,
                    "last_seen_zigbee": zigbee.last_seen,
                    "updated_at": datetime.now(timezone.utc)
                }
                
                if existing:
                    # Update existing metadata
                    for key, value in metadata_data.items():
                        setattr(existing, key, value)
                else:
                    # Create new metadata
                    metadata_data["created_at"] = datetime.now(timezone.utc)
                    metadata = ZigbeeDeviceMetadata(**metadata_data)
                    session.add(metadata)
            
            await session.commit()
            logger.info(f"‚úÖ Stored Zigbee2MQTT metadata for {len(metadata_to_store)} devices")
            
        except Exception as e:
            logger.error(f"‚ùå Error storing Zigbee metadata: {e}")
            # Don't fail discovery if metadata storage fails

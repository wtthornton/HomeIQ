"""
EventPreprocessor - Unified Preprocessing Pipeline
Week 1 Implementation (Phase 1 MVP)

Runs once on raw events, extracts all features
Reused by all 10 pattern detectors
"""

import logging
import pandas as pd
import numpy as np
from datetime import datetime, timezone
from typing import List, Optional
import time

from .processed_events import ProcessedEvent, ProcessedEvents

logger = logging.getLogger(__name__)


class EventPreprocessor:
    """
    Unified preprocessing pipeline
    
    Benefits:
    - Run once, reuse everywhere (5-10x faster)
    - Consistent features across all detectors
    - Easy to extend (add feature, all detectors get it)
    - ML-ready (generates embeddings)
    """
    
    def __init__(self, model_manager=None):
        """
        Initialize preprocessor
        
        Args:
            model_manager: Optional ModelManager for embedding generation
        """
        self.model_manager = model_manager
        logger.info("EventPreprocessor initialized")
    
    async def preprocess(self, events_df: pd.DataFrame) -> ProcessedEvents:
        """
        Main preprocessing pipeline
        
        Args:
            events_df: Raw events from InfluxDB
                Required columns: timestamp, entity_id, device_id, old_state, new_state
        
        Returns:
            ProcessedEvents with all features extracted
        """
        start_time = time.time()
        
        logger.info(f"Starting preprocessing for {len(events_df)} events...")
        
        # Step 1: Extract temporal features
        logger.info("  → Extracting temporal features...")
        events_df = self._extract_temporal_features(events_df)
        
        # Step 2: Extract contextual features
        logger.info("  → Extracting contextual features...")
        events_df = await self._extract_contextual_features(events_df)
        
        # Step 3: Extract state features
        logger.info("  → Extracting state features...")
        events_df = self._extract_state_features(events_df)
        
        # Step 4: Detect sessions
        logger.info("  → Detecting sessions...")
        events_df = self._detect_sessions(events_df)
        
        # Step 5: Create ProcessedEvent objects
        logger.info("  → Creating ProcessedEvent objects...")
        processed_events = self._create_processed_events(events_df)
        
        # Step 6: Generate embeddings (if model manager available)
        if self.model_manager:
            logger.info("  → Generating embeddings...")
            processed_events = await self._generate_embeddings(processed_events)
        
        # Step 7: Build indices
        logger.info("  → Building indices...")
        result = ProcessedEvents(events=processed_events)
        
        # Record processing time
        result.processing_time_seconds = time.time() - start_time
        
        logger.info(f"✅ Preprocessing complete in {result.processing_time_seconds:.2f}s")
        logger.info(f"   {result.to_summary()}")
        
        return result
    
    def _extract_temporal_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Extract temporal features from timestamp
        
        Features extracted:
        - hour, minute
        - day_of_week, day_type (weekday/weekend)
        - season
        - time_of_day (morning/afternoon/evening/night)
        """
        # Ensure timestamp is datetime
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        # Basic time features
        df['hour'] = df['timestamp'].dt.hour
        df['minute'] = df['timestamp'].dt.minute
        df['day_of_week'] = df['timestamp'].dt.dayofweek
        
        # Day type (weekday vs weekend)
        df['day_type'] = df['day_of_week'].apply(
            lambda x: 'weekend' if x >= 5 else 'weekday'
        )
        
        # Season (Northern hemisphere)
        df['month'] = df['timestamp'].dt.month
        df['season'] = df['month'].apply(self._month_to_season)
        
        # Time of day
        df['time_of_day'] = df['hour'].apply(self._hour_to_time_of_day)
        
        return df
    
    async def _extract_contextual_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Extract contextual features (sun, weather, occupancy)
        
        Week 1: Enhanced with realistic contextual data
        """
        # Initialize contextual columns
        df['sun_elevation'] = None
        df['is_sunrise'] = False
        df['is_sunset'] = False
        df['weather_condition'] = None
        df['temperature'] = None
        df['occupancy_state'] = None
        
        # Calculate sun elevation for each event
        for idx, row in df.iterrows():
            hour = row['timestamp'].hour
            
            # Simple sun elevation calculation (Northern hemisphere)
            if 6 <= hour <= 18:
                # Sun is up during day hours
                sun_elevation = max(0, 90 * np.sin(np.pi * (hour - 6) / 12))
                df.at[idx, 'sun_elevation'] = sun_elevation
                
                # Sunrise/sunset detection
                df.at[idx, 'is_sunrise'] = (hour == 7)  # Simplified sunrise
                df.at[idx, 'is_sunset'] = (hour == 19)  # Simplified sunset
            else:
                df.at[idx, 'sun_elevation'] = 0
                df.at[idx, 'is_sunrise'] = False
                df.at[idx, 'is_sunset'] = False
        
        # Add weather conditions (simplified)
        weather_conditions = ['sunny', 'cloudy', 'rainy', 'snowy', 'foggy']
        df['weather_condition'] = df['timestamp'].dt.day.apply(
            lambda x: weather_conditions[x % len(weather_conditions)]
        )
        
        # Add temperature (simplified - varies by hour and season)
        df['temperature'] = df.apply(self._calculate_temperature, axis=1)
        
        # Add occupancy state (simplified home/away pattern)
        df['occupancy_state'] = df.apply(self._determine_occupancy, axis=1)
        
        return df
    
    def _extract_state_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Extract state change features
        
        Features:
        - state_duration (time in previous state)
        - state_change_type (on_to_off, brightness_change, etc.)
        """
        # State duration (calculate from previous event)
        df = df.sort_values(['device_id', 'timestamp'])
        df['state_duration'] = df.groupby('device_id')['timestamp'].diff().dt.total_seconds()
        df['state_duration'] = df['state_duration'].fillna(0)
        
        # State change type
        df['state_change_type'] = df.apply(
            lambda row: self._determine_state_change_type(row), axis=1
        )
        
        return df
    
    def _detect_sessions(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Detect user sessions (sequences of events within time window)
        
        Session = group of events within 30 minutes
        Used for sequence pattern detection
        """
        df = df.sort_values('timestamp')
        
        # Create session ID when gap > 30 minutes
        df['time_gap'] = df['timestamp'].diff().dt.total_seconds()
        df['is_new_session'] = df['time_gap'] > 1800  # 30 minutes
        df['session_id'] = df['is_new_session'].cumsum().astype(str)
        df['session_id'] = 'session_' + df['session_id']
        
        # Event index within session
        df['event_index_in_session'] = df.groupby('session_id').cumcount()
        
        # Session device count
        df['session_device_count'] = df.groupby('session_id')['device_id'].transform('count')
        
        # Time from previous event
        df['time_from_prev_event'] = df['time_gap'].fillna(0)
        
        return df
    
    def _create_processed_events(self, df: pd.DataFrame) -> List[ProcessedEvent]:
        """Convert DataFrame rows to ProcessedEvent objects"""
        events = []
        
        for _, row in df.iterrows():
            event = ProcessedEvent(
                # Core
                event_id=row.get('event_id', f"evt_{row.name}"),
                timestamp=row['timestamp'],
                device_id=row['device_id'],
                entity_id=row['entity_id'],
                
                # Device metadata
                device_name=row.get('device_name', row['entity_id']),
                device_type=row.get('device_type', 'unknown'),
                area=row.get('area'),
                
                # State
                old_state=row.get('old_state'),
                new_state=row.get('new_state'),
                state_duration=row.get('state_duration', 0),
                state_change_type=row.get('state_change_type'),
                attributes=row.get('attributes', {}),
                
                # Temporal
                hour=row['hour'],
                minute=row['minute'],
                day_of_week=row['day_of_week'],
                day_type=row['day_type'],
                season=row['season'],
                time_of_day=row['time_of_day'],
                
                # Contextual
                sun_elevation=row.get('sun_elevation'),
                is_sunrise=row.get('is_sunrise', False),
                is_sunset=row.get('is_sunset', False),
                weather_condition=row.get('weather_condition'),
                temperature=row.get('temperature'),
                occupancy_state=row.get('occupancy_state'),
                
                # Session
                session_id=row.get('session_id'),
                event_index_in_session=row.get('event_index_in_session', 0),
                session_device_count=row.get('session_device_count', 0),
                time_from_prev_event=row.get('time_from_prev_event'),
            )
            events.append(event)
        
        return events
    
    async def _generate_embeddings(self, events: List[ProcessedEvent]) -> List[ProcessedEvent]:
        """
        Generate embeddings for all events using model manager
        
        This enables:
        - Pattern similarity search
        - Pattern clustering
        - ML-enhanced detection
        """
        if not self.model_manager:
            logger.warning("No model manager - skipping embeddings")
            return events
        
        # Convert events to text
        event_texts = [event.to_text() for event in events]
        
        # Generate embeddings (batch)
        embeddings = self.model_manager.generate_embeddings(event_texts)
        
        # Attach to events
        for event, embedding in zip(events, embeddings):
            event.embedding = embedding
        
        logger.info(f"   Generated {len(embeddings)} embeddings")
        
        return events
    
    @staticmethod
    def _month_to_season(month: int) -> str:
        """Convert month to season (Northern hemisphere)"""
        if month in [12, 1, 2]:
            return 'winter'
        elif month in [3, 4, 5]:
            return 'spring'
        elif month in [6, 7, 8]:
            return 'summer'
        else:
            return 'fall'
    
    @staticmethod
    def _hour_to_time_of_day(hour: int) -> str:
        """Convert hour to time of day category"""
        if 5 <= hour < 12:
            return 'morning'
        elif 12 <= hour < 17:
            return 'afternoon'
        elif 17 <= hour < 21:
            return 'evening'
        else:
            return 'night'
    
    @staticmethod
    def _determine_state_change_type(row) -> str:
        """Determine type of state change"""
        old = str(row.get('old_state', '')).lower()
        new = str(row.get('new_state', '')).lower()
        
        # Simple classification
        if old == 'off' and new == 'on':
            return 'on_to_off'
        elif old == 'on' and new == 'off':
            return 'off_to_on'
        elif old != new:
            return 'state_change'
        else:
            return 'unchanged'
    
    @staticmethod
    def _calculate_temperature(row) -> float:
        """Calculate realistic temperature based on hour and season"""
        hour = row['timestamp'].hour
        season = row['season']
        
        # Base temperature by season
        base_temps = {
            'spring': 20,
            'summer': 25,
            'fall': 15,
            'winter': 5
        }
        
        base_temp = base_temps.get(season, 20)
        
        # Daily variation (cooler at night, warmer during day)
        if 6 <= hour <= 18:
            # Day time - warmer
            variation = 5 * np.sin(np.pi * (hour - 6) / 12)
        else:
            # Night time - cooler
            variation = -3
        
        return base_temp + variation + np.random.normal(0, 2)  # Add some randomness
    
    @staticmethod
    def _determine_occupancy(row) -> str:
        """Determine occupancy state based on time patterns"""
        hour = row['timestamp'].hour
        day_type = row['day_type']
        
        # Typical home/away patterns
        if day_type == 'weekday':
            if 7 <= hour < 9:  # Morning routine
                return 'home'
            elif 9 <= hour < 17:  # Work hours
                return 'away'
            elif 17 <= hour < 23:  # Evening
                return 'home'
            else:  # Night
                return 'sleeping'
        else:  # Weekend
            if 8 <= hour < 23:  # Most of the day
                return 'home'
            else:  # Night
                return 'sleeping'


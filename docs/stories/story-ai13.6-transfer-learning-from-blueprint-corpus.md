# Story AI13.6: Transfer Learning from Blueprint Corpus

**Epic:** AI-13 - ML-Based Pattern Quality & Active Learning  
**Story ID:** AI13.6  
**Type:** Feature  
**Points:** 4  
**Status:** âœ… **READY FOR REVIEW** (Core implementation complete, tests created)  
**Estimated Effort:** 8-10 hours  
**Created:** December 2025  
**Dependencies:** Story AI13.2 (Model Training), Epic AI-4 (blueprint corpus)

---

## Story Description

Implement transfer learning from blueprint corpus. This enables the model to start with knowledge from community-validated blueprints, improving cold-start performance when there's limited user feedback.

**Current State:**
- Model starts from scratch (no pre-training)
- Requires significant user feedback before performing well
- Cold-start problem: poor predictions with limited data

**Target:**
- Load blueprint corpus (1000+ examples from Epic AI-4)
- Pre-train quality model on blueprint patterns
- Fine-tune on user feedback
- Improve cold-start performance
- Compare pre-trained vs non-pre-trained models

---

## Acceptance Criteria

- [ ] Load blueprint corpus (1000+ examples from Epic AI-4)
- [ ] Pre-train quality model on blueprint patterns
- [ ] Fine-tune on user feedback
- [ ] Improve cold-start performance
- [ ] Compare pre-trained vs non-pre-trained models
- [ ] Unit tests for transfer learning (>90% coverage)

---

## Tasks

### Task 1: Create Blueprint Pattern Converter
- [x] Create function to convert blueprints to synthetic patterns
- [x] Extract features from blueprints (device types, use cases, quality scores)
- [x] Map blueprint metadata to PatternFeatures

### Task 2: Create Transfer Learner
- [x] Create `transfer_learner.py` with `BlueprintTransferLearner` class
- [x] Implement blueprint corpus loading
- [x] Implement pre-training on blueprints
- [x] Implement fine-tuning on user feedback

### Task 3: Model Comparison
- [x] Implement comparison between pre-trained and non-pre-trained models
- [x] Track cold-start performance metrics
- [ ] Generate comparison reports (optional enhancement)

### Task 4: Integration
- [ ] Integrate with PatternQualityTrainer (can be done in later story)
- [ ] Add pre-training option to training script (can be done in later story)
- [ ] Add configuration for transfer learning (can be done in later story)

### Task 5: Unit Tests
- [x] Test blueprint pattern conversion
- [x] Test pre-training
- [x] Test fine-tuning
- [x] Test model comparison
- [x] Achieve >90% coverage

---

## Technical Design

### Transfer Learning Approach

1. **Pre-training Phase:**
   - Load blueprints from automation-miner
   - Convert blueprints to synthetic patterns
   - Extract features from blueprints
   - Use blueprint quality scores as labels (high quality = 1, low quality = 0)
   - Train model on blueprint patterns

2. **Fine-tuning Phase:**
   - Load pre-trained model
   - Continue training on user feedback
   - Lower learning rate for fine-tuning

### Blueprint to Pattern Conversion

```python
def blueprint_to_pattern_features(blueprint: dict[str, Any]) -> PatternFeatures:
    """
    Convert blueprint to PatternFeatures.
    
    Args:
        blueprint: Blueprint metadata from automation-miner
    
    Returns:
        PatternFeatures extracted from blueprint
    """
    features = PatternFeatures()
    
    # Extract device types
    device_types = blueprint.get('metadata', {}).get('_blueprint_devices', [])
    features.device_count_total = len(device_types)
    features.device_count_unique = len(set(device_types))
    
    # Extract quality score (use as confidence)
    quality_score = blueprint.get('quality_score', 0.5)
    features.confidence_raw = quality_score
    features.confidence_calibrated = quality_score
    
    # Pattern type (blueprints are typically co-occurrence patterns)
    features.pattern_type_co_occurrence = 1.0
    
    # Metadata complexity
    metadata = blueprint.get('metadata', {})
    features.metadata_complexity = len(metadata)
    
    # Use blueprint quality as label (high quality = 1, low quality = 0)
    # Threshold: quality_score > 0.7 = high quality
    
    return features
```

### Transfer Learner

```python
class BlueprintTransferLearner:
    """
    Transfer learning from blueprint corpus.
    
    Pre-trains model on blueprints, then fine-tunes on user feedback.
    """
    
    def __init__(
        self,
        miner_integration: MinerIntegration,
        feature_extractor: PatternFeatureExtractor
    ):
        """
        Initialize transfer learner.
        
        Args:
            miner_integration: Integration with automation-miner
            feature_extractor: Feature extractor for patterns
        """
        pass
    
    async def load_blueprint_corpus(
        self,
        min_quality: float = 0.0,
        limit: int = 1000
    ) -> tuple[np.ndarray, np.ndarray]:
        """
        Load blueprint corpus and convert to training data.
        
        Args:
            min_quality: Minimum blueprint quality score
            limit: Maximum number of blueprints
        
        Returns:
            Tuple of (X, y) training data
        """
        pass
    
    async def pre_train(
        self,
        model: PatternQualityModel,
        min_quality: float = 0.0,
        limit: int = 1000
    ) -> dict[str, Any]:
        """
        Pre-train model on blueprint corpus.
        
        Args:
            model: Model to pre-train
            min_quality: Minimum blueprint quality score
            limit: Maximum number of blueprints
        
        Returns:
            Pre-training metrics
        """
        pass
    
    async def fine_tune(
        self,
        model: PatternQualityModel,
        X_user: np.ndarray,
        y_user: np.ndarray,
        learning_rate: float = 0.001
    ) -> dict[str, Any]:
        """
        Fine-tune pre-trained model on user feedback.
        
        Args:
            model: Pre-trained model
            X_user: User feedback features
            y_user: User feedback labels
            learning_rate: Learning rate for fine-tuning (lower than pre-training)
        
        Returns:
            Fine-tuning metrics
        """
        pass
```

---

## Files

**Created:**
- `services/ai-automation-service/src/services/pattern_quality/transfer_learner.py`
- `services/ai-automation-service/tests/services/pattern_quality/test_transfer_learning.py`

**Modified:**
- `services/ai-automation-service/src/services/pattern_quality/model_trainer.py` (add transfer learning option)
- `services/ai-automation-service/scripts/train_pattern_quality_model.py` (add pre-training option)

---

## Testing Requirements

### Unit Tests

```python
# tests/services/pattern_quality/test_transfer_learning.py

import pytest
from services.pattern_quality.transfer_learner import BlueprintTransferLearner

@pytest.mark.asyncio
async def test_load_blueprint_corpus():
    """Test loading blueprint corpus."""
    learner = BlueprintTransferLearner(...)
    X, y = await learner.load_blueprint_corpus(limit=100)
    assert len(X) > 0
    assert len(y) > 0

@pytest.mark.asyncio
async def test_pre_train():
    """Test pre-training on blueprints."""
    learner = BlueprintTransferLearner(...)
    model = PatternQualityModel()
    metrics = await learner.pre_train(model, limit=100)
    assert 'accuracy' in metrics
    assert metrics['accuracy'] > 0.5

@pytest.mark.asyncio
async def test_fine_tune():
    """Test fine-tuning on user feedback."""
    learner = BlueprintTransferLearner(...)
    model = PatternQualityModel()
    # Pre-train first
    await learner.pre_train(model, limit=100)
    # Fine-tune
    X_user = np.random.rand(50, 28)
    y_user = np.random.randint(0, 2, 50)
    metrics = await learner.fine_tune(model, X_user, y_user)
    assert 'accuracy' in metrics
```

---

## Definition of Done

- [ ] All tasks completed
- [ ] Blueprint corpus loading implemented
- [ ] Pre-training working
- [ ] Fine-tuning working
- [ ] Cold-start performance improved
- [ ] Model comparison implemented
- [ ] Unit tests >90% coverage
- [ ] All tests passing
- [ ] Code reviewed
- [ ] Documentation updated

---

## Dependencies

**Required:**
- Story AI13.2 (Model Training) - âœ… Complete
- Epic AI-4 (Blueprint Corpus) - âœ… Available via automation-miner

**Next Story:** AI13.7 - Pattern Quality Filtering in 3 AM Workflow (depends on this story)

---

**Developer:** @dev  
**Reviewer:** @qa  
**Status:** ðŸ”„ IN PROGRESS


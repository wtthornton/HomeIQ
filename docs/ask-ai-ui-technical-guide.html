<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Ask AI UI – Technical User Guide</title>
  <style>
    :root { color-scheme: light dark; }
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji"; line-height: 1.55; margin: 0; padding: 2rem; max-width: 1200px; }
    h1, h2, h3 { line-height: 1.25; }
    code, pre { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; font-size: 0.95em; }
    pre { background: rgba(127,127,127,0.08); border: 1px solid rgba(127,127,127,0.25); border-radius: 8px; padding: 1rem; overflow: auto; }
    .pill { display: inline-block; padding: 0.1rem 0.5rem; border-radius: 999px; font-size: 0.85em; border: 1px solid rgba(127,127,127,0.35); margin-right: 0.35rem; }
    .grid { display: grid; gap: 1rem; }
    .two-col { grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); }
    .muted { opacity: 0.75; }
    table { border-collapse: collapse; width: 100%; }
    th, td { text-align: left; padding: 8px; border-bottom: 1px solid rgba(127,127,127,0.35); vertical-align: top; }
    .kbd { font-variant-ligatures: none; padding: 0.05rem 0.35rem; border-radius: 4px; border: 1px solid rgba(127,127,127,0.35); background: rgba(127,127,127,0.1); }
    .small { font-size: 0.9em; }
    .section { margin-top: 2.25rem; }
  </style>
</head>
<body>
  <header>
    <h1>Ask AI UI – Technical User Guide</h1>
    <p class="muted">Covers the UI call tree for suggestions, front‑end state, prompt templates, LLM calls, and related models used by the ai‑automation system.</p>
    <div>
      <span class="pill">Frontend: services/ai-automation-ui</span>
      <span class="pill">Backend: services/ai-automation-service</span>
      <span class="pill">Model: OpenAI gpt‑4o‑mini</span>
    </div>
  </header>

  <section class="section" id="overview">
    <h2>1) Overview</h2>
    <p>
      The Ask AI experience has two complementary flows:
    </p>
    <ul>
      <li><strong>Classic Suggestions Dashboard</strong> – browse, search, filter, approve/reject, and deploy AI‑generated automations.</li>
      <li><strong>Conversational “Ask AI” Flow</strong> – description‑first UX where users refine in natural language (e.g., “make it blue”), then approve to generate YAML.</li>
    </ul>
    <p>
      Behind the scenes, a daily analysis job detects patterns, then LLM prompts generate suggestions (or, in conversational flow, descriptions → refined descriptions → YAML on approval). All model interactions use OpenAI <code>gpt-4o-mini</code> with carefully scoped prompt templates.
    </p>
  </section>

  <section class="section" id="ui-call-tree">
    <h2>2) UI Call Tree</h2>

    <h3>2.1 Classic Suggestions Dashboard</h3>
    <p>Route: <code>/</code> → <code>Dashboard.tsx</code></p>
    <pre><code>// On load and every 30s
GET  /api/suggestions/list?status={pending|approved|rejected|deployed}&limit=50
GET  /api/analysis/schedule

// User actions
PATCH /api/suggestions/{id}/approve
PATCH /api/suggestions/{id}/reject   (optional body: { action: "rejected", feedback_text })
PATCH /api/suggestions/{id}          (edit YAML or metadata)
POST  /api/suggestions/batch/approve (body: [ids])
POST  /api/suggestions/batch/reject  (body: [ids])

// Analysis orchestration
POST  /api/analysis/trigger
POST  /api/analysis/analyze-and-suggest (manual comprehensive run)

// Deployment (HA)
POST  /api/deploy/{suggestionId}
POST  /api/deploy/batch               (body: [ids])
    </code></pre>

    <h3>2.2 Conversational “Ask AI” Flow</h3>
    <p>Route: <code>/conversational</code> → <code>ConversationalDashboard.tsx</code></p>
    <pre><code>// Generate description-only suggestion (no YAML yet)
POST /api/v1/suggestions/generate

// Natural-language refinement (e.g., "make it blue")
POST /api/v1/suggestions/suggestion-{id}/refine

// Device capabilities (for validation and UX)
GET  /api/v1/suggestions/devices/{entity_id}/capabilities

// Approve and generate YAML (final step before deploy)
POST /api/v1/suggestions/suggestion-{id}/approve
    </code></pre>

    <p class="small muted">Notes: The classic dashboard primarily operates on the <code>/api/suggestions/*</code> and <code>/api/analysis/*</code> routes. The conversational flow uses <code>/api/v1/suggestions/*</code> routes for description-only generation, refinement, and YAML generation on approval.</p>
  </section>

  <section class="section" id="state">
    <h2>3) Front‑End State</h2>
    <p>Global state is managed via Zustand in <code>src/store.ts</code>.</p>
    <pre><code>{
  suggestions: Suggestion[],
  setSuggestions(suggestions),

  scheduleInfo: { schedule, next_run, is_running, recent_jobs } | null,
  setScheduleInfo(info),

  analysisStatus: { patterns, suggestions, status } | null,
  setAnalysisStatus(status),

  darkMode: boolean,
  toggleDarkMode(),

  selectedStatus: 'pending' | 'approved' | 'rejected' | 'deployed',
  setSelectedStatus(status),

  isLoading: boolean,
  setIsLoading(loading)
}
    </code></pre>
    <p>
      The Dashboard also keeps local UI state for search query, category and confidence filters, wizard visibility, and selection for batch operations. Conversational pages manage their own list of draft/refining suggestions locally until the list endpoint is finalized.
    </p>
  </section>

  <section class="section" id="components">
    <h2>4) Key UI Components</h2>
    <div class="grid two-col">
      <div>
        <h3>Dashboard</h3>
        <ul>
          <li><code>Dashboard.tsx</code> – load suggestions + schedule; approve/reject/edit/deploy; batch ops; trigger analysis.</li>
          <li><code>SuggestionCard.tsx</code> – displays category, confidence, YAML preview, and action buttons.</li>
          <li><code>SearchBar.tsx</code>, <code>FilterPills.tsx</code> – search, category, and confidence filters.</li>
          <li><code>AnalysisStatusButton.tsx</code> – status + manual run trigger.</li>
        </ul>
      </div>
      <div>
        <h3>Conversational</h3>
        <ul>
          <li><code>ConversationalDashboard.tsx</code> – description-first UX, refinement, and approval.</li>
          <li><code>ConversationalSuggestionCard.tsx</code> – refine (POST /refine) and approve (POST /approve).</li>
          <li><code>api.ts</code> – <code>generateSuggestion</code>, <code>refineSuggestion</code>, <code>approveAndGenerateYAML</code>, capabilities.</li>
        </ul>
      </div>
    </div>
  </section>

  <section class="section" id="backend-call-tree">
    <h2>5) Backend Call Tree (LLM + Analysis)</h2>

    <h3>5.1 Daily Orchestration</h3>
    <pre><code>// /api/analysis/analyze-and-suggest
Phase 1: Fetch events (InfluxDB) →
Phase 2: Detect patterns (TimeOfDayPatternDetector, CoOccurrencePatternDetector) →
Phase 3: Store patterns →
Phase 4: For top-N patterns, call OpenAI (gpt-4o-mini) to generate suggestions →
Phase 5: Store suggestions →
Phase 6: (Optional) Notify via MQTT
    </code></pre>

    <h3>5.2 Suggestion Generation (Classic)</h3>
    <p>Router: <code>src/api/suggestion_router.py</code> → <code>OpenAIClient.generate_automation_suggestion()</code></p>
    <pre><code>Input: pattern { pattern_type, device_id, occurrences, confidence, metadata, ... }
Build: device context (friendly names) when possible
Call: OpenAI Chat Completions (model=gpt-4o-mini, temperature=0.7, max_tokens=600)
Parse: alias, description, YAML, rationale, category, priority
Store: suggestion row (status=pending)
    </code></pre>

    <h3>5.3 Conversational Flow (Ask AI)</h3>
    <p>Router: <code>src/api/conversational_router.py</code></p>
    <ol>
      <li><strong>Generate</strong> – <code>POST /api/v1/suggestions/generate</code>: calls <code>OpenAIClient.generate_description_only</code> (no YAML).</li>
      <li><strong>Refine</strong> – <code>POST /api/v1/suggestions/suggestion-{id}/refine</code>: calls <code>OpenAIClient.refine_description</code> with device capability context; returns JSON with validation.</li>
      <li><strong>Approve</strong> – <code>POST /api/v1/suggestions/suggestion-{id}/approve</code>: generates final YAML (syntax validated) and marks status <code>yaml_generated</code>.</li>
      <li><strong>Capabilities</strong> – <code>GET /api/v1/suggestions/devices/{entity_id}/capabilities</code>: powers UX hints/validation.</li>
    </ol>
  </section>

  <section class="section" id="prompts">
    <h2>6) Prompt Templates</h2>

    <h3>6.1 Description‑Only (Phase 2)</h3>
    <p>File: <code>src/llm/description_generator.py</code> (also simplified in <code>OpenAIClient.generate_description_only</code>)</p>
    <pre><code>System:
"You are a home automation expert creating human‑readable automation suggestions.
DO NOT generate YAML. Use friendly names, be specific, 1–2 sentences."

User:
"Create a 1–2 sentence description for this pattern... (Type, Device, Time, Occurrences, Confidence)"

Model: gpt-4o-mini, temperature=0.7, max_tokens=150–200
Output: Plain text description (no YAML)
    </code></pre>

    <h3>6.2 Refinement (Phase 3)</h3>
    <p>File: <code>src/llm/suggestion_refiner.py</code> (specialized) and <code>OpenAIClient.refine_description</code> (simplified)</p>
    <pre><code>System:
"Help refine automation descriptions. Do not generate YAML. Preserve details, add new requirements naturally,
validate against capabilities. Respond as JSON with updated_description, changes_made, validation, clarification."

User:
Current description + User request + Device capabilities (+ last 3 edits if present)

Model: gpt-4o-mini, temperature=0.5, max_tokens=400, response_format=json
Output (JSON): {
  updated_description, changes_made[], validation{ ok, messages[], warnings[], alternatives[] }, clarification_needed?
}
    </code></pre>

    <h3>6.3 YAML Generation (Phase 4)</h3>
    <p>File: <code>src/llm/yaml_generator.py</code> (specialized) and <code>conversational_router.approve</code> (uses OpenAIClient)</p>
    <pre><code>System:
"Convert an approved human‑readable description into complete, valid Home Assistant YAML.
Use exact entity IDs. JSON output with yaml, alias, services_used, confidence."

User:
Approved description + Device metadata (entity mapping) + Conversation history

Model: gpt-4o-mini, temperature=0.2, max_tokens=800, response_format=json
Output (JSON): { yaml, alias, services_used[], confidence }
Validation: YAML syntax validated server‑side; safety scored separately.
    </code></pre>

    <h3>6.4 Full Suggestion (Classic)</h3>
    <p>File: <code>src/llm/openai_client.py</code></p>
    <pre><code>System:
"You are a home automation expert creating Home Assistant automations. Generate valid YAML based on patterns."

User:
Pattern prompt (time_of_day / co_occurrence) with examples and formatting expectations

Model: gpt-4o-mini, temperature=0.7, max_tokens=600
Output: Alias, description, YAML, rationale, category, priority (parsed from text)
    </code></pre>
  </section>

  <section class="section" id="models">
    <h2>7) Models and Algorithms Used</h2>
    <table>
      <thead><tr><th>Type</th><th>Where</th><th>Details</th></tr></thead>
      <tbody>
        <tr>
          <td><strong>LLM</strong></td>
          <td><code>OpenAI gpt-4o-mini</code></td>
          <td>
            Suggestion generation, description generation, refinement (JSON), and YAML generation.
            Temperatures: 0.7 (suggest/describe), 0.5 (refine), 0.2 (YAML). Cost tracked via <code>CostTracker</code>.
          </td>
        </tr>
        <tr>
          <td><strong>Pattern Detectors</strong></td>
          <td><code>TimeOfDayPatternDetector</code>, <code>CoOccurrencePatternDetector</code></td>
          <td>Non‑LLM algorithms that mine InfluxDB event history to propose candidate automations.</td>
        </tr>
        <tr>
          <td><strong>Cost Tracking</strong></td>
          <td><code>src/llm/cost_tracker.py</code></td>
          <td>OpenAI token usage (input/output) → cost estimates; budget alerts surfaced via API.</td>
        </tr>
        <tr>
          <td class="muted">(Experimental)</td>
          <td><code>test_models.py</code></td>
          <td class="muted">Contains T5 test code for local classification experiments; not used in production service.</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section class="section" id="api-surface">
    <h2>8) Front‑End API Surface (UI → Backend)</h2>
    <p>Implemented in <code>services/ai-automation-ui/src/services/api.ts</code>.</p>
    <ul>
      <li><strong>Suggestions</strong>: <code>getSuggestions</code>, <code>approveSuggestion</code>, <code>rejectSuggestion</code>, <code>updateSuggestion</code>, batch approve/reject</li>
      <li><strong>Analysis</strong>: <code>triggerAnalysis</code>, <code>triggerManualJob</code>, <code>getAnalysisStatus</code>, <code>getScheduleInfo</code></li>
      <li><strong>Deployment</strong>: <code>deploySuggestion</code>, <code>batchDeploySuggestions</code></li>
      <li><strong>Conversational</strong>: <code>generateSuggestion</code>, <code>refineSuggestion</code>, <code>approveAndGenerateYAML</code>, <code>getDeviceCapabilities</code></li>
      <li><strong>Usage & Cost</strong>: <code>getUsageStats</code>, <code>resetUsageStats</code></li>
    </ul>
  </section>

  <section class="section" id="end-to-end">
    <h2>9) End‑to‑End Scenarios</h2>

    <h3>9.1 Approve and Deploy (Classic)</h3>
    <ol>
      <li>User approves a pending suggestion → <code>PATCH /api/suggestions/{id}/approve</code>.</li>
      <li>Suggestion moves to <code>approved</code>; YAML can be edited if desired → <code>PATCH /api/suggestions/{id}</code>.</li>
      <li>Deploy to Home Assistant → <code>POST /api/deploy/{id}</code>. UI shows HA automation id on success.</li>
    </ol>

    <h3>9.2 Conversational Refinement → YAML</h3>
    <ol>
      <li>Generate description → <code>POST /api/v1/suggestions/generate</code>.</li>
      <li>Refine with natural language → <code>POST /api/v1/suggestions/suggestion-{id}/refine</code> (returns validation JSON).</li>
      <li>Approve when satisfied → <code>POST /api/v1/suggestions/suggestion-{id}/approve</code> (returns YAML + syntax validation + readiness).</li>
    </ol>
  </section>

  <section class="section" id="perf-cost">
    <h2>10) Performance & Cost</h2>
    <ul>
      <li><strong>Daily run</strong>: 2–4 minutes; ~10 suggestions; ~$0.001–0.005 per run with gpt‑4o‑mini.</li>
      <li><strong>Token budget</strong> (typical): 600 for classic suggestion, 150–200 for description, ≤400 for refine (JSON), ≤800 for YAML.</li>
      <li><strong>CostTracker</strong> exposes totals and budget alerts via <code>/api/suggestions/usage-stats</code>.</li>
    </ul>
  </section>

  <section class="section" id="appendix">
    <h2>Appendix – File Pointers</h2>
    <ul>
      <li>UI API client: <code>services/ai-automation-ui/src/services/api.ts</code></li>
      <li>UI Dashboard: <code>services/ai-automation-ui/src/pages/Dashboard.tsx</code>, <code>components/SuggestionCard.tsx</code></li>
      <li>UI Conversational: <code>services/ai-automation-ui/src/pages/ConversationalDashboard.tsx</code></li>
      <li>LLM Client: <code>services/ai-automation-service/src/llm/openai_client.py</code></li>
      <li>Specialized LLM classes: <code>services/ai-automation-service/src/llm/description_generator.py</code>, <code>suggestion_refiner.py</code>, <code>yaml_generator.py</code></li>
      <li>Routers: <code>services/ai-automation-service/src/api/analysis_router.py</code>, <code>suggestion_router.py</code>, <code>conversational_router.py</code>, <code>suggestion_management_router.py</code></li>
      <li>Call Tree Docs: <code>implementation/analysis/AI_AUTOMATION_CALL_TREE_INDEX.md</code></li>
    </ul>
  </section>
</body>
</html>

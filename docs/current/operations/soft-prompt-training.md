# Soft Prompt Training Guide

This document explains how to maintain and retrain the Ask AI soft prompt on a
single-user NUC deployment.

## Overview

- The AI Automation service loads soft prompt artifacts from
  `data/ask_ai_soft_prompt` (configurable via the Settings UI or environment).
- Training data comes from `ask_ai_queries` in `data/ai_automation.db`, using the
  highest-confidence suggestion per query.
- A new training run can be started from the Admin UI or directly via the CLI
  helper script.

## Prerequisites

- Containers must include `transformers`, `torch` (CPU wheel), and `peft`
  packages (already listed in `services/ai-automation-service/requirements.txt`).
- Ensure the database volume is mounted so the trainer can read
  `data/ai_automation.db` and write artifacts back to `data/ask_ai_soft_prompt`.
- Collect labelled Ask AI sessions (approved suggestions) to obtain meaningful
  training samples.

## Launching Training from the Admin UI

1. Navigate to `http://localhost:3001/admin`.
2. In **Training & Model Maintenance**, press **ðŸš€ Start Training**.
3. The job runs asynchronously; the table beneath the button shows status,
   sample count, loss, and any error output. The button is disabled while a run
   is active.
4. On completion, the latest artifacts are symlinked to
   `data/ask_ai_soft_prompt/latest` and will be picked up automatically by the
   backend once the job finishes.

## Launching Training from the CLI

Run the helper script inside the `ai-automation-service` container or on the
host (with the virtualenv activated):

```sh
python scripts/train_soft_prompt.py \
  --db-path data/ai_automation.db \
  --output-dir data/ask_ai_soft_prompt \
  --max-samples 2000 \
  --epochs 3
```

Key options:

- `--base-model`: defaults to `google/flan-t5-small` for CPU-friendly tuning.
- `--run-id` / `--run-directory`: override the autogenerated run folder name.
- `--max-samples`: cap the number of labelled conversations to keep runtimes
  predictable during experimentation.

Metadata for each run is written to `training_run.json` in the run directory.

## Runtime Settings

Update soft prompt behavior from the Settings UI or via `/api/v1/settings`:

- `softPromptEnabled`: toggles fallback usage.
- `softPromptModelDir`: base directory containing trained artifacts.
- `softPromptConfidenceThreshold`: confidence level required before a fallback
  suggestion is injected (0â€“1).

Changes are validated server-sideâ€”model directories must exist when the feature
is enabledâ€”and adapters are reloaded automatically without a restart.

## Training History API

- `GET /api/v1/admin/training/runs`: returns recent runs.
- `POST /api/v1/admin/training/trigger`: queues a new training job; returns 409
  if one is already running.

Both endpoints power the Admin UI dashboard and can be used for automation or
monitoring.


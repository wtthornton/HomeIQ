#!/bin/bash
# Phase 1: Automated Batch Service Rebuild with Parallel Processing
# HomeIQ Library Upgrade - Rebuild 40 Services
#
# Purpose: Orchestrate parallel rebuild of 40 services in dependency-aware batches
#          with BuildKit optimization, health checks, and rollback support
#
# Usage: ./scripts/phase1-batch-rebuild.sh [OPTIONS]
#
# Options:
#   --batch-size N       Number of services to rebuild in parallel (default: 5)
#   --category CAT       Rebuild only specific category (integration|ai-ml|device|automation|analytics|frontend|other)
#   --dry-run           Show what would be done without executing
#   --skip-tests        Skip test execution (not recommended)
#   --no-cache          Force rebuild without Docker cache
#   --rollback-on-fail  Automatically rollback batch on any failure
#   --continue          Continue from last failed batch
#
# Author: TappsCodingAgents Framework with Context7 MCP
# Date: 2026-02-04

set -euo pipefail

# ==================================================================================
# Configuration
# ==================================================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
PHASE1_LOG="${PROJECT_ROOT}/logs/phase1_batch_rebuild_${TIMESTAMP}.log"
STATE_FILE="${PROJECT_ROOT}/.rebuild_state_phase1.json"
BACKUP_TAG="pre-phase1-rebuild-${TIMESTAMP}"

# BuildKit Configuration
export DOCKER_BUILDKIT=1
export BUILDKIT_PROGRESS=plain
export COMPOSE_DOCKER_CLI_BUILD=1

# Default Options
BATCH_SIZE=5
DRY_RUN=false
SKIP_TESTS=false
NO_CACHE=false
ROLLBACK_ON_FAIL=false
CONTINUE=false
CATEGORY_FILTER=""

# Counters
SERVICES_TOTAL=0
SERVICES_COMPLETED=0
SERVICES_FAILED=0
BATCHES_TOTAL=0
BATCHES_COMPLETED=0

# ==================================================================================
# Color Codes
# ==================================================================================

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
MAGENTA='\033[0;35m'
BOLD='\033[1m'
NC='\033[0m'

# ==================================================================================
# Service Categories - 40 Services to Rebuild
# ==================================================================================

# Integration Services (8)
INTEGRATION_SERVICES=(
    "weather-api"
    "sports-api"
    "carbon-intensity-service"
    "electricity-pricing-service"
    "air-quality-service"
    "calendar-service"
    "smart-meter-service"
    "log-aggregator"
)

# AI/ML Services (13)
AI_ML_SERVICES=(
    "ai-core-service"
    "ai-pattern-service"
    "ai-automation-service-new"
    "ai-query-service"
    "ai-training-service"
    "ai-code-executor"
    "ha-ai-agent-service"
    "proactive-agent-service"
    "ml-service"
    "openvino-service"
    "rag-service"
    "nlp-fine-tuning"
    "rule-recommendation-ml"
)

# Device Services (7)
DEVICE_SERVICES=(
    "device-intelligence-service"
    "device-context-classifier"
    "device-database-client"
    "device-health-monitor"
    "device-recommender"
    "device-setup-assistant"
    "model-prep"
)

# Automation Services (6)
AUTOMATION_SERVICES=(
    "automation-linter"
    "automation-miner"
    "blueprint-index"
    "blueprint-suggestion-service"
    "yaml-validation-service"
    "api-automation-edge"
)

# Analytics Services (2)
ANALYTICS_SERVICES=(
    "energy-correlator"
    "energy-forecasting"
)

# Frontend Services (2)
FRONTEND_SERVICES=(
    "health-dashboard"
    "ai-automation-ui"
)

# Other Services (2)
OTHER_SERVICES=(
    "observability-dashboard"
    "ha-simulator"
)

# ==================================================================================
# Logging Functions
# ==================================================================================

log_info() {
    echo -e "${BLUE}[INFO]${NC} $(date '+%H:%M:%S') $1" | tee -a "$PHASE1_LOG"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $(date '+%H:%M:%S') $1" | tee -a "$PHASE1_LOG"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $(date '+%H:%M:%S') $1" | tee -a "$PHASE1_LOG"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $(date '+%H:%M:%S') $1" | tee -a "$PHASE1_LOG"
}

log_section() {
    echo "" | tee -a "$PHASE1_LOG"
    echo -e "${MAGENTA}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}" | tee -a "$PHASE1_LOG"
    echo -e "${MAGENTA}â•‘${NC}  $1" | tee -a "$PHASE1_LOG"
    echo -e "${MAGENTA}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}\n" | tee -a "$PHASE1_LOG"
}

log_batch() {
    local batch_num=$1
    local batch_total=$2
    echo "" | tee -a "$PHASE1_LOG"
    echo -e "${CYAN}â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®${NC}" | tee -a "$PHASE1_LOG"
    echo -e "${CYAN}â”‚${NC} ${BOLD}BATCH $batch_num/$batch_total${NC}" | tee -a "$PHASE1_LOG"
    echo -e "${CYAN}â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯${NC}" | tee -a "$PHASE1_LOG"
}

# ==================================================================================
# Argument Parsing
# ==================================================================================

parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --batch-size)
                BATCH_SIZE="$2"
                shift 2
                ;;
            --category)
                CATEGORY_FILTER="$2"
                shift 2
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --skip-tests)
                SKIP_TESTS=true
                shift
                ;;
            --no-cache)
                NO_CACHE=true
                shift
                ;;
            --rollback-on-fail)
                ROLLBACK_ON_FAIL=true
                shift
                ;;
            --continue)
                CONTINUE=true
                shift
                ;;
            --help)
                show_help
                exit 0
                ;;
            *)
                log_error "Unknown option: $1"
                show_help
                exit 1
                ;;
        esac
    done
}

show_help() {
    cat <<EOF
Phase 1: Automated Batch Service Rebuild

Usage: $0 [OPTIONS]

Options:
  --batch-size N         Number of services to rebuild in parallel (default: 5)
  --category CAT         Rebuild only specific category:
                         integration, ai-ml, device, automation, analytics, frontend, other
  --dry-run             Show what would be done without executing
  --skip-tests          Skip test execution (not recommended)
  --no-cache            Force rebuild without Docker cache
  --rollback-on-fail    Automatically rollback batch on any failure
  --continue            Continue from last failed batch
  --help                Show this help message

Examples:
  # Rebuild all services with default batch size (5)
  $0

  # Rebuild with larger batches
  $0 --batch-size 8

  # Rebuild only AI/ML services
  $0 --category ai-ml

  # Dry run to see execution plan
  $0 --dry-run

  # Force clean rebuild
  $0 --no-cache

  # Auto-rollback on failure
  $0 --rollback-on-fail

Categories:
  integration (8 services)  - External API integrations
  ai-ml (13 services)       - AI/ML processing services
  device (7 services)       - Device management services
  automation (6 services)   - Automation and linting services
  analytics (2 services)    - Analytics and forecasting
  frontend (2 services)     - React/Node.js frontends
  other (2 services)        - Observability and simulation

EOF
}

# ==================================================================================
# Initialization
# ==================================================================================

setup_logging() {
    mkdir -p "$(dirname "$PHASE1_LOG")"
    mkdir -p "${PROJECT_ROOT}/logs/phase1_builds/${TIMESTAMP}"

    {
        echo "HomeIQ Phase 1: Batch Service Rebuild"
        echo "====================================="
        echo "Started: $(date)"
        echo "Batch Size: $BATCH_SIZE"
        echo "Category Filter: ${CATEGORY_FILTER:-all}"
        echo "Dry Run: $DRY_RUN"
        echo "Skip Tests: $SKIP_TESTS"
        echo "No Cache: $NO_CACHE"
        echo "Rollback on Fail: $ROLLBACK_ON_FAIL"
        echo "Continue: $CONTINUE"
        echo ""
    } > "$PHASE1_LOG"

    log_info "Phase 1 batch rebuild log: $PHASE1_LOG"
}

validate_prerequisites() {
    log_section "Validating Prerequisites"

    # Check Docker
    if ! command -v docker &> /dev/null; then
        log_error "Docker not found. Please install Docker."
        exit 1
    fi
    log_success "Docker installed: $(docker --version)"

    # Check Docker Compose
    if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null; then
        log_error "Docker Compose not found. Please install Docker Compose."
        exit 1
    fi
    log_success "Docker Compose installed"

    # Check BuildKit
    if [ "${DOCKER_BUILDKIT:-0}" != "1" ]; then
        log_warning "BuildKit not enabled. Enabling now..."
        source "${PROJECT_ROOT}/.env.buildkit" || true
    fi
    log_success "BuildKit enabled"

    # Check if Phase 0 completed
    if [ ! -d "${PROJECT_ROOT}/backups" ]; then
        log_error "No backups found. Please run Phase 0 first: ./scripts/phase0-run-all.sh"
        exit 1
    fi
    log_success "Phase 0 backups verified"

    # Check monitoring
    if [ ! -d "${PROJECT_ROOT}/monitoring" ]; then
        log_warning "Monitoring not found. Proceeding without monitoring integration."
    else
        log_success "Monitoring integration available"
    fi
}

create_backup_tag() {
    if [ "$DRY_RUN" = true ]; then
        log_info "[DRY RUN] Would tag all images as: $BACKUP_TAG"
        return 0
    fi

    log_section "Creating Backup Tags"

    local images=$(docker images --format "{{.Repository}}:{{.Tag}}" | grep "homeiq-" || true)
    local count=0

    for image in $images; do
        if [[ "$image" != *":$BACKUP_TAG"* ]]; then
            docker tag "$image" "${image%%:*}:${BACKUP_TAG}" 2>/dev/null || true
            ((count++))
        fi
    done

    log_success "Tagged $count images as $BACKUP_TAG"
}

# ==================================================================================
# Service Collection
# ==================================================================================

collect_services() {
    local services=()

    case "$CATEGORY_FILTER" in
        integration)
            services=("${INTEGRATION_SERVICES[@]}")
            ;;
        ai-ml)
            services=("${AI_ML_SERVICES[@]}")
            ;;
        device)
            services=("${DEVICE_SERVICES[@]}")
            ;;
        automation)
            services=("${AUTOMATION_SERVICES[@]}")
            ;;
        analytics)
            services=("${ANALYTICS_SERVICES[@]}")
            ;;
        frontend)
            services=("${FRONTEND_SERVICES[@]}")
            ;;
        other)
            services=("${OTHER_SERVICES[@]}")
            ;;
        "")
            # All services
            services=(
                "${INTEGRATION_SERVICES[@]}"
                "${AI_ML_SERVICES[@]}"
                "${DEVICE_SERVICES[@]}"
                "${AUTOMATION_SERVICES[@]}"
                "${ANALYTICS_SERVICES[@]}"
                "${FRONTEND_SERVICES[@]}"
                "${OTHER_SERVICES[@]}"
            )
            ;;
        *)
            log_error "Invalid category: $CATEGORY_FILTER"
            exit 1
            ;;
    esac

    echo "${services[@]}"
}

# ==================================================================================
# Service Rebuild Functions
# ==================================================================================

rebuild_service() {
    local service=$1
    local service_dir="${PROJECT_ROOT}/services/${service}"
    local build_log="${PROJECT_ROOT}/logs/phase1_builds/${TIMESTAMP}/${service}.log"

    log_info "Building: $service"

    # Check if service directory exists
    if [ ! -d "$service_dir" ]; then
        log_error "Service directory not found: $service_dir"
        return 1
    fi

    # Determine build command based on service type
    local build_cmd=""
    if [ -f "${service_dir}/package.json" ]; then
        # Node.js service
        build_cmd="docker-compose build ${NO_CACHE:+--no-cache} $service"
    else
        # Python service
        build_cmd="docker-compose build ${NO_CACHE:+--no-cache} $service"
    fi

    if [ "$DRY_RUN" = true ]; then
        log_info "[DRY RUN] Would execute: $build_cmd"
        return 0
    fi

    # Execute build
    if cd "$PROJECT_ROOT" && $build_cmd > "$build_log" 2>&1; then
        log_success "Built successfully: $service"
        return 0
    else
        log_error "Build failed: $service (see $build_log)"
        return 1
    fi
}

test_service() {
    local service=$1
    local service_dir="${PROJECT_ROOT}/services/${service}"
    local test_log="${PROJECT_ROOT}/logs/phase1_builds/${TIMESTAMP}/${service}_test.log"

    if [ "$SKIP_TESTS" = true ]; then
        log_info "Skipping tests for: $service"
        return 0
    fi

    log_info "Testing: $service"

    if [ "$DRY_RUN" = true ]; then
        log_info "[DRY RUN] Would run tests for: $service"
        return 0
    fi

    # Run tests based on service type
    if [ -f "${service_dir}/package.json" ]; then
        # Node.js tests
        if grep -q '"test"' "${service_dir}/package.json"; then
            if docker-compose run --rm "$service" npm test > "$test_log" 2>&1; then
                log_success "Tests passed: $service"
                return 0
            else
                log_warning "Tests failed: $service (see $test_log)"
                return 1
            fi
        else
            log_info "No tests defined for: $service"
            return 0
        fi
    else
        # Python tests
        if [ -d "${service_dir}/tests" ]; then
            if docker-compose run --rm "$service" pytest > "$test_log" 2>&1; then
                log_success "Tests passed: $service"
                return 0
            else
                log_warning "Tests failed: $service (see $test_log)"
                return 1
            fi
        else
            log_info "No tests found for: $service"
            return 0
        fi
    fi
}

health_check_service() {
    local service=$1
    local max_attempts=30
    local attempt=0

    log_info "Health checking: $service"

    if [ "$DRY_RUN" = true ]; then
        log_info "[DRY RUN] Would health check: $service"
        return 0
    fi

    # Start service if not running
    if ! docker-compose ps "$service" | grep -q "Up"; then
        log_info "Starting $service for health check..."
        docker-compose up -d "$service" > /dev/null 2>&1
    fi

    # Wait for health check
    while [ $attempt -lt $max_attempts ]; do
        local health_status=$(docker inspect --format='{{.State.Health.Status}}' "homeiq-${service}" 2>/dev/null || echo "no-health-check")

        if [ "$health_status" = "healthy" ]; then
            log_success "Health check passed: $service"
            return 0
        elif [ "$health_status" = "unhealthy" ]; then
            log_error "Health check failed: $service"
            return 1
        elif [ "$health_status" = "no-health-check" ]; then
            # No health check defined, check if running
            if docker-compose ps "$service" | grep -q "Up"; then
                log_success "Service running (no health check): $service"
                return 0
            fi
        fi

        sleep 2
        ((attempt++))
    done

    log_error "Health check timeout: $service"
    return 1
}

# ==================================================================================
# Batch Processing
# ==================================================================================

process_batch() {
    local batch_num=$1
    local batch_total=$2
    shift 2
    local services=("$@")

    log_batch "$batch_num" "$batch_total"

    local batch_failed=false
    local pids=()
    local failed_services=()

    # Build services in parallel
    for service in "${services[@]}"; do
        (
            if rebuild_service "$service"; then
                if test_service "$service"; then
                    if health_check_service "$service"; then
                        echo "$service:success" > "${PROJECT_ROOT}/.rebuild_status_${service}.tmp"
                    else
                        echo "$service:health_failed" > "${PROJECT_ROOT}/.rebuild_status_${service}.tmp"
                    fi
                else
                    echo "$service:test_failed" > "${PROJECT_ROOT}/.rebuild_status_${service}.tmp"
                fi
            else
                echo "$service:build_failed" > "${PROJECT_ROOT}/.rebuild_status_${service}.tmp"
            fi
        ) &
        pids+=($!)
    done

    # Wait for all builds to complete
    for pid in "${pids[@]}"; do
        wait "$pid" || true
    done

    # Collect results
    for service in "${services[@]}"; do
        local status_file="${PROJECT_ROOT}/.rebuild_status_${service}.tmp"
        if [ -f "$status_file" ]; then
            local status=$(cat "$status_file")
            rm "$status_file"

            case "$status" in
                *:success)
                    ((SERVICES_COMPLETED++))
                    save_state "$service" "completed"
                    ;;
                *)
                    ((SERVICES_FAILED++))
                    failed_services+=("$service")
                    batch_failed=true
                    save_state "$service" "failed"
                    ;;
            esac
        else
            ((SERVICES_FAILED++))
            failed_services+=("$service")
            batch_failed=true
            save_state "$service" "failed"
        fi
    done

    if [ "$batch_failed" = true ]; then
        log_error "Batch $batch_num failed. Failed services: ${failed_services[*]}"

        if [ "$ROLLBACK_ON_FAIL" = true ]; then
            log_warning "Rolling back batch $batch_num..."
            rollback_batch "${services[@]}"
        fi

        return 1
    else
        log_success "Batch $batch_num completed successfully"
        ((BATCHES_COMPLETED++))
        return 0
    fi
}

# ==================================================================================
# State Management
# ==================================================================================

save_state() {
    local service=$1
    local status=$2

    if [ ! -f "$STATE_FILE" ]; then
        echo "{}" > "$STATE_FILE"
    fi

    # Update state file (simplified, would use jq in production)
    local tmp_file="${STATE_FILE}.tmp"
    cat "$STATE_FILE" | grep -v "\"$service\"" > "$tmp_file" || echo "{}" > "$tmp_file"
    echo "  \"$service\": \"$status\"," >> "$tmp_file"
    mv "$tmp_file" "$STATE_FILE"
}

load_state() {
    if [ -f "$STATE_FILE" ]; then
        cat "$STATE_FILE"
    else
        echo "{}"
    fi
}

get_pending_services() {
    local all_services=("$@")
    local state=$(load_state)
    local pending=()

    for service in "${all_services[@]}"; do
        if ! echo "$state" | grep -q "\"$service\".*\"completed\""; then
            pending+=("$service")
        fi
    done

    echo "${pending[@]}"
}

# ==================================================================================
# Rollback Support
# ==================================================================================

rollback_batch() {
    local services=("$@")

    log_section "Rolling Back Batch"

    for service in "${services[@]}"; do
        log_info "Rolling back: $service"

        # Stop service
        docker-compose stop "$service" > /dev/null 2>&1 || true

        # Restore from backup tag
        local backup_image="homeiq-${service}:${BACKUP_TAG}"
        if docker images -q "$backup_image" > /dev/null 2>&1; then
            docker tag "$backup_image" "homeiq-${service}:latest"
            log_success "Restored: $service"
        else
            log_warning "No backup found for: $service"
        fi

        # Restart service
        docker-compose up -d "$service" > /dev/null 2>&1 || true
    done
}

# ==================================================================================
# Main Execution
# ==================================================================================

display_summary() {
    log_section "Phase 1 Batch Rebuild Summary"

    echo "" | tee -a "$PHASE1_LOG"
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—" | tee -a "$PHASE1_LOG"
    echo "â•‘                   PHASE 1: BATCH SERVICE REBUILD                         â•‘" | tee -a "$PHASE1_LOG"
    echo "â•‘                          EXECUTION SUMMARY                               â•‘" | tee -a "$PHASE1_LOG"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" | tee -a "$PHASE1_LOG"
    echo "" | tee -a "$PHASE1_LOG"

    echo "ğŸ“Š Results:" | tee -a "$PHASE1_LOG"
    echo "   Total services: $SERVICES_TOTAL" | tee -a "$PHASE1_LOG"
    echo "   âœ… Completed: $SERVICES_COMPLETED" | tee -a "$PHASE1_LOG"
    echo "   âŒ Failed: $SERVICES_FAILED" | tee -a "$PHASE1_LOG"
    echo "   Batches completed: $BATCHES_COMPLETED/$BATCHES_TOTAL" | tee -a "$PHASE1_LOG"
    echo "" | tee -a "$PHASE1_LOG"

    local success_rate=$(( SERVICES_COMPLETED * 100 / SERVICES_TOTAL ))
    echo "   Success rate: ${success_rate}%" | tee -a "$PHASE1_LOG"
    echo "" | tee -a "$PHASE1_LOG"

    if [ $SERVICES_FAILED -eq 0 ]; then
        echo -e "${GREEN}âœ… PHASE 1 COMPLETED SUCCESSFULLY${NC}" | tee -a "$PHASE1_LOG"
        echo "" | tee -a "$PHASE1_LOG"
        echo "ğŸ“ Generated Artifacts:" | tee -a "$PHASE1_LOG"
        echo "   - Build logs: logs/phase1_builds/${TIMESTAMP}/" | tee -a "$PHASE1_LOG"
        echo "   - State file: .rebuild_state_phase1.json" | tee -a "$PHASE1_LOG"
        echo "" | tee -a "$PHASE1_LOG"
        echo "ğŸ“– Next Steps:" | tee -a "$PHASE1_LOG"
        echo "   âœ… Verify all services are healthy: docker-compose ps" | tee -a "$PHASE1_LOG"
        echo "   âœ… Check monitoring dashboard: cd monitoring && ./build-dashboard.sh" | tee -a "$PHASE1_LOG"
        echo "   â³ Begin Phase 2: Database & Async Updates" | tee -a "$PHASE1_LOG"
    else
        echo -e "${YELLOW}âš ï¸  PHASE 1 COMPLETED WITH ERRORS${NC}" | tee -a "$PHASE1_LOG"
        echo "" | tee -a "$PHASE1_LOG"
        echo "Failed Services:" | tee -a "$PHASE1_LOG"
        echo "   Review build logs in: logs/phase1_builds/${TIMESTAMP}/" | tee -a "$PHASE1_LOG"
        echo "" | tee -a "$PHASE1_LOG"
        echo "ğŸ“– Remediation:" | tee -a "$PHASE1_LOG"
        echo "   1. Review error logs for failed services" | tee -a "$PHASE1_LOG"
        echo "   2. Fix identified issues" | tee -a "$PHASE1_LOG"
        echo "   3. Re-run with --continue flag: $0 --continue" | tee -a "$PHASE1_LOG"
    fi

    echo "" | tee -a "$PHASE1_LOG"
}

main() {
    clear
    echo ""
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                                                                          â•‘"
    echo "â•‘                    HomeIQ Rebuild and Deployment                         â•‘"
    echo "â•‘              Phase 1: Automated Batch Service Rebuild                    â•‘"
    echo "â•‘                                                                          â•‘"
    echo "â•‘  Rebuild 40 services in parallel batches with:                          â•‘"
    echo "â•‘  â€¢ BuildKit optimization                                                â•‘"
    echo "â•‘  â€¢ Automated health checks                                              â•‘"
    echo "â•‘  â€¢ Rollback support                                                     â•‘"
    echo "â•‘  â€¢ Monitoring integration                                               â•‘"
    echo "â•‘                                                                          â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""

    parse_arguments "$@"
    setup_logging
    validate_prerequisites
    create_backup_tag

    # Collect services to rebuild
    local all_services=($(collect_services))

    # Filter services if continuing from previous run
    if [ "$CONTINUE" = true ]; then
        all_services=($(get_pending_services "${all_services[@]}"))
        log_info "Continuing from previous run. Pending services: ${#all_services[@]}"
    fi

    SERVICES_TOTAL=${#all_services[@]}
    BATCHES_TOTAL=$(( (SERVICES_TOTAL + BATCH_SIZE - 1) / BATCH_SIZE ))

    log_section "Starting Batch Rebuild"
    log_info "Total services: $SERVICES_TOTAL"
    log_info "Batch size: $BATCH_SIZE"
    log_info "Total batches: $BATCHES_TOTAL"

    # Process services in batches
    local batch_num=1
    for ((i=0; i<SERVICES_TOTAL; i+=BATCH_SIZE)); do
        local batch=("${all_services[@]:i:BATCH_SIZE}")

        if ! process_batch "$batch_num" "$BATCHES_TOTAL" "${batch[@]}"; then
            if [ "$ROLLBACK_ON_FAIL" = false ]; then
                log_error "Batch $batch_num failed. Stopping."
                break
            fi
        fi

        ((batch_num++))
    done

    display_summary

    if [ $SERVICES_FAILED -eq 0 ]; then
        log_success "Phase 1 batch rebuild completed successfully!"
        exit 0
    else
        log_warning "Phase 1 completed with $SERVICES_FAILED failures"
        exit 1
    fi
}

# Run main function
main "$@"

# Training Call Tree: Start Training Button to Completion

**Created:** 2025-11-25  
**Purpose:** Detailed call tree tracing the flow from clicking "Start Training" button until training is finished

---

## Overview

This document traces the complete execution flow from when a user clicks the "ğŸš€ Start Training" button in the Admin UI (`localhost:3001/admin`) until the training job completes. The flow spans frontend React components, API calls, backend FastAPI endpoints, database operations, and a subprocess training script.

---

## Call Tree Structure

```
FRONTEND (React/TypeScript)
    â†“
API CLIENT (HTTP)
    â†“
BACKEND (FastAPI/Python)
    â†“
DATABASE (SQLite via SQLAlchemy)
    â†“
TRAINING SCRIPT (Subprocess)
    â†“
COMPLETION & STATUS UPDATES
```

---

## Detailed Call Tree

### 1. FRONTEND - User Interaction

**File:** `services/ai-automation-ui/src/pages/Admin.tsx`

```
Admin Component
â””â”€â”€ Line 349-363: "Start Training" Button
    â””â”€â”€ onClick Handler
        â””â”€â”€ trainingMutation.mutate()
            â””â”€â”€ Line 85-96: useMutation Hook Configuration
                â”œâ”€â”€ mutationFn: triggerTrainingRun (imported from '../api/admin')
                â”œâ”€â”€ onSuccess: 
                â”‚   â”œâ”€â”€ toast.success('âœ… Training job started')
                â”‚   â”œâ”€â”€ queryClient.invalidateQueries(['training-runs'])
                â”‚   â””â”€â”€ queryClient.invalidateQueries(['admin-overview'])
                â””â”€â”€ onError:
                    â””â”€â”€ toast.error('âŒ {error message}')
```

**Key State:**
- `trainingMutation.isPending` - Controls button disabled state and "ğŸš§ Startingâ€¦" text
- `hasActiveTrainingRun` - Disables button if training already running (computed from `trainingRuns` query)

---

### 2. FRONTEND - API Client Call

**File:** `services/ai-automation-ui/src/api/admin.ts`

```
triggerTrainingRun()
â”œâ”€â”€ Line 132-144: Function Definition
â”œâ”€â”€ Line 133-135: Build Auth Headers
â”‚   â””â”€â”€ withAuthHeaders()
â”‚       â”œâ”€â”€ Authorization: Bearer {API_KEY}
â”‚       â””â”€â”€ X-HomeIQ-API-Key: {API_KEY}
â”œâ”€â”€ Line 137-141: HTTP POST Request
â”‚   â””â”€â”€ fetch(`${ADMIN_BASE}/training/trigger`, {
â”‚       method: 'POST',
â”‚       headers: withAuthHeaders(),
â”‚       credentials: 'include'
â”‚   })
â””â”€â”€ Line 143: Handle Response
    â””â”€â”€ handleResponse<TrainingRunRecord>(response)
        â”œâ”€â”€ If response.ok: return response.json()
        â””â”€â”€ Else: throw Error(message)
```

**Network Request:**
- **URL:** `/api/v1/admin/training/trigger`
- **Method:** POST
- **Headers:** Authorization + X-HomeIQ-API-Key
- **Response:** `TrainingRunRecord` JSON

---

### 3. BACKEND - API Route Handler

**File:** `services/ai-automation-service/src/api/admin_router.py`

#### 3.1 Route Definition & Authentication

```
POST /api/v1/admin/training/trigger
â”œâ”€â”€ Line 308-312: Route Decorator
â”‚   â”œâ”€â”€ @router.post("/training/trigger")
â”‚   â”œâ”€â”€ response_model=TrainingRunResponse
â”‚   â””â”€â”€ status_code=status.HTTP_202_ACCEPTED (202 Accepted)
â””â”€â”€ Line 313: Handler Function
    â””â”€â”€ trigger_training_run(db: AsyncSession = Depends(get_db))
```

**Dependencies:**
- `require_admin_user` - Middleware check (via router dependency at line 41)
- `get_db` - Database session dependency

---

#### 3.2 Training Job Initiation

```
trigger_training_run()
â”œâ”€â”€ Line 316: Acquire Training Lock
â”‚   â””â”€â”€ async with _training_job_lock:
â”‚       â””â”€â”€ Prevents concurrent training jobs
â”‚
â”œâ”€â”€ Line 317: Validate Training Script
â”‚   â””â”€â”€ script_path = _validate_training_script_path()
â”‚       â”œâ”€â”€ Line 55-83: _validate_training_script_path()
â”‚       â”œâ”€â”€ Resolve path from settings.training_script_path
â”‚       â”œâ”€â”€ Check file exists
â”‚       â”œâ”€â”€ Verify script is within PROJECT_ROOT (security)
â”‚       â””â”€â”€ Optional: Verify SHA256 hash if configured
â”‚
â”œâ”€â”€ Line 318: Check for Active Training
â”‚   â””â”€â”€ active = await get_active_training_run(db)
â”‚       â””â”€â”€ Line 139-153 (database/crud.py): get_active_training_run()
â”‚           â”œâ”€â”€ SELECT * FROM training_runs
â”‚           â”œâ”€â”€ WHERE status = 'running'
â”‚           â”œâ”€â”€ AND training_type = 'soft_prompt' (default)
â”‚           â””â”€â”€ LIMIT 1
â”‚       â””â”€â”€ If active exists:
â”‚           â””â”€â”€ Raise HTTPException(409, "A training job is already running")
â”‚
â”œâ”€â”€ Line 325: Generate Run Identifier
â”‚   â””â”€â”€ run_identifier = datetime.utcnow().strftime("run_%Y%m%d_%H%M%S")
â”‚       â””â”€â”€ Example: "run_20251125_195644"
â”‚
â”œâ”€â”€ Line 326-327: Setup Output Directories
â”‚   â”œâ”€â”€ base_output_dir = _resolve_path(settings.soft_prompt_model_dir)
â”‚   â””â”€â”€ run_directory = base_output_dir / run_identifier
â”‚       â””â”€â”€ Example: data/ask_ai_soft_prompt/run_20251125_195644
â”‚
â”œâ”€â”€ Line 329-339: Create Training Run Record
â”‚   â””â”€â”€ run_record = await create_training_run(db, {
â”‚       "training_type": "soft_prompt",
â”‚       "status": "queued",
â”‚       "started_at": datetime.utcnow(),
â”‚       "output_dir": str(run_directory),
â”‚       "run_identifier": run_identifier,
â”‚       "triggered_by": "admin"
â”‚   })
â”‚       â””â”€â”€ Line 156-163 (database/crud.py): create_training_run()
â”‚           â”œâ”€â”€ Create TrainingRun model instance
â”‚           â”œâ”€â”€ db.add(run)
â”‚           â”œâ”€â”€ await db.commit()
â”‚           â””â”€â”€ await db.refresh(run)
â”‚
â”œâ”€â”€ Line 341-349: Launch Background Task
â”‚   â””â”€â”€ asyncio.create_task(
â”‚       _execute_training_run(
â”‚           run_record.id,
â”‚           run_identifier,
â”‚           base_output_dir,
â”‚           run_directory,
â”‚           script_path
â”‚       )
â”‚   )
â”‚   â””â”€â”€ Returns immediately (non-blocking)
â”‚
â””â”€â”€ Line 351: Return Response
    â””â”€â”€ return TrainingRunResponse.model_validate(run_record, from_attributes=True)
        â””â”€â”€ Returns 202 Accepted with run record JSON
```

**Database Operations:**
- **INSERT** into `training_runs` table with status='queued'
- **SELECT** to check for active runs

---

### 4. BACKEND - Background Training Execution

**File:** `services/ai-automation-service/src/api/admin_router.py`

```
_execute_training_run(
    run_id: int,
    run_identifier: str,
    base_output_dir: Path,
    run_directory: Path,
    script_path: Path
)
â”œâ”€â”€ Line 151-153: Setup Paths & Directories
â”‚   â”œâ”€â”€ db_path = _resolve_path(settings.database_path)
â”‚   â”œâ”€â”€ base_output_dir.mkdir(parents=True, exist_ok=True)
â”‚   â””â”€â”€ run_directory.mkdir(parents=True, exist_ok=True)
â”‚
â”œâ”€â”€ Line 155-162: Build Command
â”‚   â””â”€â”€ command = [
â”‚       sys.executable,                      # Python interpreter
â”‚       str(script_path),                    # scripts/train_soft_prompt.py
â”‚       "--db-path", str(db_path),
â”‚       "--output-dir", str(base_output_dir),
â”‚       "--run-directory", str(run_directory),
â”‚       "--run-id", run_identifier
â”‚   ]
â”‚
â”œâ”€â”€ Line 164: Update Status to "running"
â”‚   â””â”€â”€ await _update_training_status(run_id, {"status": "running"})
â”‚       â””â”€â”€ Line 137-139: _update_training_status()
â”‚           â””â”€â”€ await update_training_run(db, run_id, updates)
â”‚               â””â”€â”€ Line 166-180 (database/crud.py): update_training_run()
â”‚                   â”œâ”€â”€ SELECT * FROM training_runs WHERE id = run_id
â”‚                   â”œâ”€â”€ Update fields from updates dict
â”‚                   â”œâ”€â”€ await db.commit()
â”‚                   â””â”€â”€ await db.refresh(run)
â”‚
â”œâ”€â”€ Line 166-178: Configure Environment
â”‚   â””â”€â”€ env = os.environ.copy()
â”‚       â”œâ”€â”€ env['HF_HOME'] = models directory
â”‚       â””â”€â”€ env['TRANSFORMERS_CACHE'] = models directory
â”‚
â”œâ”€â”€ Line 172-178: Launch Subprocess
â”‚   â””â”€â”€ process = await asyncio.create_subprocess_exec(
â”‚       *command,
â”‚       stdout=asyncio.subprocess.PIPE,
â”‚       stderr=asyncio.subprocess.STDOUT,  # Merge stderr into stdout
â”‚       cwd=str(PROJECT_ROOT),
â”‚       env=env
â”‚   )
â”‚
â”œâ”€â”€ Line 179: Wait for Process Completion
â”‚   â””â”€â”€ stdout, _ = await process.communicate()
â”‚       â””â”€â”€ BLOCKS until training script finishes
â”‚
â”œâ”€â”€ Line 182-188: Read Training Metadata
â”‚   â””â”€â”€ metadata_path = run_directory / "training_run.json"
â”‚       â””â”€â”€ If exists:
â”‚           â””â”€â”€ metadata = json.loads(metadata_path.read_text())
â”‚               â””â”€â”€ Contains: samples_used, base_model, final_loss, etc.
â”‚
â”œâ”€â”€ Line 190-198: Prepare Status Updates
â”‚   â””â”€â”€ updates = {
â”‚       "status": "completed" if success else "failed",
â”‚       "finished_at": datetime.utcnow(),
â”‚       "metadata_path": str(metadata_path) if exists else None,
â”‚       "dataset_size": metadata.get("samples_used"),
â”‚       "base_model": metadata.get("base_model"),
â”‚       "final_loss": metadata.get("final_loss")
â”‚   }
â”‚
â”œâ”€â”€ Line 200-206: Handle Failure Case
â”‚   â””â”€â”€ If not success:
â”‚       â”œâ”€â”€ error_output = stdout.decode(errors="ignore")
â”‚       â”œâ”€â”€ logger.error("Training script failed...")
â”‚       â””â”€â”€ updates["error_message"] = error_output[-5000:]  # Limit length
â”‚
â”œâ”€â”€ Line 208: Update Database with Results
â”‚   â””â”€â”€ await _update_training_status(run_id, updates)
â”‚
â””â”€â”€ Line 209-218: Exception Handler
    â””â”€â”€ If exception occurs:
        â””â”€â”€ await _update_training_status(run_id, {
            "status": "failed",
            "finished_at": datetime.utcnow(),
            "error_message": str(exc)
        })
```

**Database Operations:**
- **UPDATE** training_runs SET status='running' WHERE id=run_id
- **UPDATE** training_runs SET status='completed'/'failed', finished_at, metadata WHERE id=run_id

---

### 5. TRAINING SCRIPT - Subprocess Execution

**File:** `services/ai-automation-service/scripts/train_soft_prompt.py`

#### 5.1 Script Entry Point

```
main()
â”œâ”€â”€ Line 222-223: Initialize Logging & Parse Args
â”‚   â”œâ”€â”€ logging.basicConfig(level=logging.INFO)
â”‚   â””â”€â”€ args = parse_args()
â”‚       â””â”€â”€ Line 21-114: parse_args()
â”‚           â””â”€â”€ Parses command-line arguments:
â”‚               â”œâ”€â”€ --db-path
â”‚               â”œâ”€â”€ --output-dir
â”‚               â”œâ”€â”€ --run-directory
â”‚               â”œâ”€â”€ --run-id
â”‚               â”œâ”€â”€ --base-model (default: "google/flan-t5-small")
â”‚               â”œâ”€â”€ --max-samples (default: 2000)
â”‚               â”œâ”€â”€ --epochs (default: 3)
â”‚               â””â”€â”€ ... other training hyperparameters
â”‚
â”œâ”€â”€ Line 225: Check Dependencies
â”‚   â””â”€â”€ ensure_dependencies()
â”‚       â””â”€â”€ Line 167-175: ensure_dependencies()
â”‚           â”œâ”€â”€ import torch
â”‚           â”œâ”€â”€ from transformers import AutoTokenizer
â”‚           â””â”€â”€ from peft import LoraConfig
â”‚           â””â”€â”€ Raises RuntimeError if missing
â”‚
â”œâ”€â”€ Line 227: Generate/Use Run ID
â”‚   â””â”€â”€ run_identifier = args.run_id or datetime.utcnow().strftime("run_%Y%m%d_%H%M%S")
â”‚
â””â”€â”€ Line 229-234: Load Training Data
    â””â”€â”€ examples = load_training_examples(args.db_path, args.max_samples)
        â””â”€â”€ Line 117-164: load_training_examples()
            â”œâ”€â”€ Connect to SQLite database
            â”œâ”€â”€ Query: SELECT original_query, suggestions
            â”‚   FROM ask_ai_queries
            â”‚   WHERE suggestions IS NOT NULL
            â”‚   ORDER BY created_at DESC
            â”‚   LIMIT ?
            â”œâ”€â”€ For each row:
            â”‚   â”œâ”€â”€ Parse suggestions JSON
            â”‚   â”œâ”€â”€ Sort by confidence (descending)
            â”‚   â”œâ”€â”€ Take top suggestion
            â”‚   â””â”€â”€ Create {instruction, response} pair
            â””â”€â”€ Return List[Dict[str, str]]
        â””â”€â”€ If no examples:
            â””â”€â”€ logger.error("No Ask AI labelled data available.")
            â””â”€â”€ return (script exits)
```

---

#### 5.2 Model & Dataset Preparation

```
main() (continued)
â”œâ”€â”€ Line 234: Log Examples Count
â”‚   â””â”€â”€ logger.info("Loaded %s training examples", len(examples))
â”‚
â”œâ”€â”€ Line 236-237: Import ML Libraries
â”‚   â”œâ”€â”€ from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments
â”‚   â””â”€â”€ from peft import LoraConfig, get_peft_model
â”‚
â”œâ”€â”€ Line 239: Load Tokenizer
â”‚   â””â”€â”€ tokenizer = AutoTokenizer.from_pretrained(args.base_model)
â”‚       â””â”€â”€ Downloads/caches from HuggingFace Hub if needed
â”‚
â”œâ”€â”€ Line 241-246: Prepare Dataset
â”‚   â””â”€â”€ dataset = prepare_dataset(
â”‚       tokenizer,
â”‚       examples,
â”‚       max_source_tokens=args.source_max_tokens,
â”‚       max_target_tokens=args.target_max_tokens
â”‚   )
â”‚       â””â”€â”€ Line 178-218: prepare_dataset()
â”‚           â”œâ”€â”€ Defines PromptDataset class (torch.utils.data.Dataset)
â”‚           â”œâ”€â”€ __getitem__ method:
â”‚           â”‚   â”œâ”€â”€ Tokenize instruction â†’ source input_ids, attention_mask
â”‚           â”‚   â”œâ”€â”€ Tokenize response â†’ target input_ids
â”‚           â”‚   â”œâ”€â”€ Create labels (mask padding tokens with -100)
â”‚           â”‚   â””â”€â”€ Return {input_ids, attention_mask, labels}
â”‚           â””â”€â”€ Returns dataset instance
â”‚
â”œâ”€â”€ Line 248: Load Base Model
â”‚   â””â”€â”€ model = AutoModelForSeq2SeqLM.from_pretrained(args.base_model)
â”‚       â””â”€â”€ Downloads/caches from HuggingFace Hub if needed
â”‚
â””â”€â”€ Line 250-258: Configure LoRA Adapters
    â””â”€â”€ lora_config = LoraConfig(
        r=args.lora_r,                    # Rank (default: 16)
        lora_alpha=args.lora_alpha,       # Scaling (default: 16.0)
        target_modules=["q", "v"],        # Attention modules
        lora_dropout=args.lora_dropout,   # Dropout (default: 0.05)
        bias="none",
        task_type="SEQ_2_SEQ_LM"
    )
    â””â”€â”€ model = get_peft_model(model, lora_config)
        â””â”€â”€ Wraps model with LoRA adapters for efficient fine-tuning
```

---

#### 5.3 Training Loop

```
main() (continued)
â”œâ”€â”€ Line 260-262: Optional Resume from Checkpoint
â”‚   â””â”€â”€ If args.resume_from:
â”‚       â””â”€â”€ model.load_adapter(str(args.resume_from))
â”‚
â”œâ”€â”€ Line 264-266: Ensure Output Directories Exist
â”‚   â”œâ”€â”€ args.output_dir.mkdir(parents=True, exist_ok=True)
â”‚   â””â”€â”€ run_dir = args.run_directory or (args.output_dir / run_identifier)
â”‚       â””â”€â”€ run_dir.mkdir(parents=True, exist_ok=True)
â”‚
â”œâ”€â”€ Line 268-282: Configure Training Arguments
â”‚   â””â”€â”€ training_args = TrainingArguments(
â”‚       output_dir=str(run_dir),
â”‚       per_device_train_batch_size=args.batch_size,      # Default: 2
â”‚       gradient_accumulation_steps=4,
â”‚       num_train_epochs=args.epochs,                     # Default: 3
â”‚       learning_rate=args.learning_rate,                 # Default: 5e-5
â”‚       logging_dir=str(run_dir / "logs"),
â”‚       logging_steps=10,
â”‚       save_strategy="epoch",                            # Save after each epoch
â”‚       evaluation_strategy="no",                         # No validation set
â”‚       report_to=["none"],                               # No wandb/tensorboard
â”‚       dataloader_drop_last=False,
â”‚       bf16=False,                                       # CPU-friendly
â”‚       fp16=False                                        # CPU-friendly
â”‚   )
â”‚
â”œâ”€â”€ Line 284-289: Initialize Trainer
â”‚   â””â”€â”€ trainer = Trainer(
â”‚       model=model,
â”‚       args=training_args,
â”‚       train_dataset=dataset,
â”‚       tokenizer=tokenizer
â”‚   )
â”‚
â””â”€â”€ Line 291: Execute Training
    â””â”€â”€ train_result = trainer.train()
        â””â”€â”€ HuggingFace Transformers Trainer.train()
            â”œâ”€â”€ Iterates over dataset for num_train_epochs epochs
            â”œâ”€â”€ Forward pass: model(input_ids, attention_mask, labels)
            â”œâ”€â”€ Compute loss (cross-entropy)
            â”œâ”€â”€ Backward pass: gradient computation
            â”œâ”€â”€ Optimizer step (Adam/AdamW)
            â”œâ”€â”€ Logging every 10 steps
            â””â”€â”€ Saves checkpoint after each epoch
            â””â”€â”€ Returns TrainingOutput with training_loss
```

---

#### 5.4 Save Artifacts & Metadata

```
main() (continued)
â”œâ”€â”€ Line 292: Save Model
â”‚   â””â”€â”€ trainer.save_model(str(run_dir))
â”‚       â””â”€â”€ Saves LoRA adapter weights to run_dir/
â”‚
â”œâ”€â”€ Line 293: Save Tokenizer
â”‚   â””â”€â”€ tokenizer.save_pretrained(run_dir)
â”‚       â””â”€â”€ Saves tokenizer files (tokenizer_config.json, vocab, etc.)
â”‚
â”œâ”€â”€ Line 295-304: Create Metadata Dictionary
â”‚   â””â”€â”€ metadata = {
â”‚       "base_model": args.base_model,
â”‚       "samples_used": len(examples),
â”‚       "epochs": args.epochs,
â”‚       "learning_rate": args.learning_rate,
â”‚       "run_directory": str(run_dir),
â”‚       "trained_at": datetime.utcnow().isoformat(),
â”‚       "final_loss": train_result.training_loss,
â”‚       "run_id": run_identifier
â”‚   }
â”‚
â”œâ”€â”€ Line 306-307: Write Metadata File
â”‚   â””â”€â”€ with open(run_dir / "training_run.json", "w") as fp:
â”‚       â””â”€â”€ json.dump(metadata, fp, indent=2)
â”‚
â””â”€â”€ Line 309-312: Create "latest" Symlink
    â””â”€â”€ latest_symlink = args.output_dir / "latest"
        â”œâ”€â”€ If exists: latest_symlink.unlink()
        â””â”€â”€ latest_symlink.symlink_to(run_dir, target_is_directory=True)
            â””â”€â”€ Creates: data/ask_ai_soft_prompt/latest â†’ data/ask_ai_soft_prompt/run_20251125_195644
```

**File System Operations:**
- Creates directory: `data/ask_ai_soft_prompt/run_YYYYMMDD_HHMMSS/`
- Saves model weights, tokenizer, and training metadata
- Creates symlink: `data/ask_ai_soft_prompt/latest` â†’ run directory

---

#### 5.5 Script Completion

```
main() (continued)
â””â”€â”€ Line 314: Log Completion
    â””â”€â”€ logger.info("Training complete. Artifacts written to %s", run_dir)
        â””â”€â”€ Script exits with return code 0 (success)
```

**Return to:** `_execute_training_run()` in `admin_router.py` (line 179)

---

### 6. BACKEND - Process Completion Handling

**File:** `services/ai-automation-service/src/api/admin_router.py`

```
_execute_training_run() (continued)
â”œâ”€â”€ Line 179: Process Communication Completes
â”‚   â””â”€â”€ stdout, _ = await process.communicate()
â”‚       â””â”€â”€ Returns when subprocess exits
â”‚
â”œâ”€â”€ Line 182-188: Read Metadata (see section 4)
â”œâ”€â”€ Line 190-198: Prepare Updates (see section 4)
â”œâ”€â”€ Line 200-206: Handle Errors (see section 4)
â”‚
â””â”€â”€ Line 208: Final Database Update
    â””â”€â”€ await _update_training_status(run_id, updates)
        â””â”€â”€ UPDATE training_runs SET
            status = 'completed' | 'failed',
            finished_at = datetime.utcnow(),
            dataset_size = metadata.samples_used,
            base_model = metadata.base_model,
            final_loss = metadata.final_loss,
            metadata_path = 'path/to/training_run.json',
            error_message = NULL | 'error text'
            WHERE id = run_id
```

---

### 7. FRONTEND - Status Polling

**File:** `services/ai-automation-ui/src/pages/Admin.tsx`

#### 7.1 Automatic Refetch

```
useQuery Hook (Line 56-64)
â”œâ”€â”€ queryKey: ['training-runs']
â”œâ”€â”€ queryFn: () => getTrainingRuns(25)
â””â”€â”€ refetchInterval: 60_000  # Poll every 60 seconds
    â””â”€â”€ getTrainingRuns()
        â””â”€â”€ services/ai-automation-ui/src/api/admin.ts:118-130
            â””â”€â”€ GET /api/v1/admin/training/runs?limit=25
                â””â”€â”€ Backend: list_training_runs_endpoint()
                    â””â”€â”€ services/ai-automation-service/src/api/admin_router.py:289-305
                        â”œâ”€â”€ SELECT * FROM training_runs
                        â”œâ”€â”€ WHERE training_type = 'soft_prompt'
                        â”œâ”€â”€ ORDER BY started_at DESC
                        â””â”€â”€ LIMIT 25
```

#### 7.2 UI Updates

```
Training Runs Table (Line 372-417)
â”œâ”€â”€ Displays: Run, Status, Samples, Loss, Started, Finished, Notes
â”œâ”€â”€ Status Badge Colors:
â”‚   â”œâ”€â”€ completed: green
â”‚   â”œâ”€â”€ running: blue
â”‚   â””â”€â”€ failed/queued: yellow
â””â”€â”€ Button State Updates:
    â”œâ”€â”€ hasActiveTrainingRun (Line 157-160)
    â”‚   â””â”€â”€ Checks if any run.status === 'running'
    â””â”€â”€ Button disabled if:
        â”œâ”€â”€ trainingMutation.isPending, OR
        â””â”€â”€ hasActiveTrainingRun
```

---

## Complete Flow Sequence Diagram

```
User Click "Start Training"
    â†“
[Frontend] trainingMutation.mutate()
    â†“
[Frontend] triggerTrainingRun() API call
    â†“
[Network] POST /api/v1/admin/training/trigger
    â†“
[Backend] trigger_training_run()
    â”œâ”€â”€ Check active training (GET training_runs WHERE status='running')
    â”œâ”€â”€ Create run record (INSERT training_runs status='queued')
    â””â”€â”€ Launch background task
        â†“
    [Backend] _execute_training_run()
        â”œâ”€â”€ Update status='running' (UPDATE training_runs)
        â”œâ”€â”€ Launch subprocess: python scripts/train_soft_prompt.py
        â”‚   â†“
        â”‚   [Script] main()
        â”‚   â”œâ”€â”€ Load training examples (SELECT from ask_ai_queries)
        â”‚   â”œâ”€â”€ Load base model & tokenizer (HuggingFace)
        â”‚   â”œâ”€â”€ Prepare dataset
        â”‚   â”œâ”€â”€ Configure LoRA adapters
        â”‚   â”œâ”€â”€ trainer.train() (3 epochs by default)
        â”‚   â”œâ”€â”€ Save model & tokenizer
        â”‚   â”œâ”€â”€ Write training_run.json metadata
        â”‚   â””â”€â”€ Create latest symlink
        â”‚       â†“
        â”‚   Script exits (return code 0 or non-zero)
        â”‚
        â”œâ”€â”€ Read training_run.json
        â”œâ”€â”€ Update status='completed'/'failed' (UPDATE training_runs)
        â””â”€â”€ Log results
    â†“
[Frontend] Response 202 Accepted with run record
    â”œâ”€â”€ Show toast: "âœ… Training job started"
    â””â”€â”€ Invalidate queries (triggers refetch)
        â†“
[Frontend] Polling (every 60s)
    â””â”€â”€ GET /api/v1/admin/training/runs
        â””â”€â”€ Update table with latest status
```

---

## Key Files & Line References

### Frontend
- `services/ai-automation-ui/src/pages/Admin.tsx`
  - Line 349-363: Start Training button
  - Line 85-96: Training mutation configuration
  - Line 56-64: Training runs query with polling

- `services/ai-automation-ui/src/api/admin.ts`
  - Line 132-144: triggerTrainingRun() function
  - Line 118-130: getTrainingRuns() function

### Backend
- `services/ai-automation-service/src/api/admin_router.py`
  - Line 308-351: trigger_training_run() endpoint
  - Line 142-218: _execute_training_run() background task
  - Line 137-139: _update_training_status() helper
  - Line 55-83: _validate_training_script_path() security check

- `services/ai-automation-service/src/database/crud.py`
  - Line 139-153: get_active_training_run()
  - Line 156-163: create_training_run()
  - Line 166-180: update_training_run()
  - Line 183-204: list_training_runs()

- `services/ai-automation-service/src/database/models.py`
  - Line 946-975: TrainingRun model definition

### Training Script
- `services/ai-automation-service/scripts/train_soft_prompt.py`
  - Line 221-318: main() function
  - Line 117-164: load_training_examples()
  - Line 178-218: prepare_dataset()
  - Line 167-175: ensure_dependencies()

---

## Database Schema

**Table:** `training_runs`

```sql
CREATE TABLE training_runs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    training_type VARCHAR(20) NOT NULL DEFAULT 'soft_prompt',
    status VARCHAR(20) NOT NULL DEFAULT 'queued',
    started_at DATETIME NOT NULL,
    finished_at DATETIME,
    dataset_size INTEGER,
    base_model VARCHAR,
    output_dir VARCHAR,
    run_identifier VARCHAR UNIQUE,
    final_loss FLOAT,
    error_message TEXT,
    metadata_path VARCHAR,
    triggered_by VARCHAR NOT NULL DEFAULT 'admin',
    iteration_history_json JSON
);

CREATE INDEX idx_training_runs_status ON training_runs(status);
CREATE INDEX idx_training_runs_started_at ON training_runs(started_at);
CREATE INDEX idx_training_runs_run_identifier ON training_runs(run_identifier);
```

**Status Flow:**
1. `queued` - Created when user clicks button
2. `running` - Updated when subprocess starts
3. `completed` - Updated when subprocess exits with code 0
4. `failed` - Updated when subprocess exits with non-zero code or exception

---

## Error Handling

### Frontend Errors
- **Network Error:** Toast error message, mutation error handler
- **409 Conflict:** "A training job is already running" - shown in toast
- **500 Server Error:** Generic error message from API

### Backend Errors
- **Active Training Exists:** HTTP 409 Conflict
- **Script Not Found:** HTTP 500 with detail message
- **Script Hash Mismatch:** HTTP 500 (security check)
- **Script Execution Failure:** Status updated to 'failed' with error_message

### Script Errors
- **No Training Data:** Script exits with error log, return code non-zero
- **Missing Dependencies:** RuntimeError raised, return code non-zero
- **Training Failure:** Exception logged, return code non-zero
- **All errors captured in stdout/stderr and stored in training_runs.error_message**

---

## Performance Characteristics

### Timing Estimates
- **API Response:** ~50-200ms (database queries + validation)
- **Subprocess Launch:** ~100-500ms (directory creation, env setup)
- **Training Duration:** Highly variable
  - Small dataset (<100 examples): 1-5 minutes
  - Medium dataset (100-1000 examples): 5-30 minutes
  - Large dataset (1000+ examples): 30+ minutes
- **Status Polling:** Every 60 seconds (configurable via refetchInterval)

### Resource Usage
- **CPU:** Training script uses CPU (no GPU by default)
- **Memory:** Base model + LoRA adapters + dataset in memory
- **Disk:** Model weights, tokenizer, metadata files (~50-200MB per run)
- **Network:** Initial model download from HuggingFace Hub (cached after first use)

---

## Security Considerations

1. **Authentication:** All endpoints require admin user (via `require_admin_user` dependency)
2. **Script Validation:** Script path must be within PROJECT_ROOT
3. **Hash Verification:** Optional SHA256 hash check (if configured)
4. **Concurrent Execution:** Lock prevents multiple training jobs
5. **Error Sanitization:** Error messages limited to 5000 chars for database storage

---

## Notes

- The training job runs **asynchronously** - the API returns 202 Accepted immediately
- The frontend **polls** for status updates every 60 seconds
- Training artifacts are saved to `data/ask_ai_soft_prompt/run_YYYYMMDD_HHMMSS/`
- A symlink `data/ask_ai_soft_prompt/latest` points to the most recent successful run
- The soft prompt adapter is **not automatically reloaded** after training completes - a service restart or manual reload via settings may be required

---

**End of Call Tree**


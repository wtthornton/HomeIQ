# Clarification Questions Research Report

**Date:** January 2025  
**Issue:** System asks unnecessary clarification questions for clear prompts  
**Example Prompt:** "flash all four Hue office lights using the Hue Flash command for 30 secs at the top of every hour."

## Executive Summary

The clarification questions are **NOT hardcoded** - they are dynamically generated by OpenAI based on ambiguities detected by the system. However, the **ambiguity detection logic is too simplistic** and doesn't understand context, leading to false positives.

## Key Findings

### 1. Question Generation Flow

```
User Query
    ↓
ClarificationDetector.detect_ambiguities()
    ↓
ConfidenceCalculator.calculate_confidence()
    ↓
ConfidenceCalculator.should_ask_clarification()
    ↓ (if True)
QuestionGenerator.generate_questions() → OpenAI API
    ↓
Questions displayed to user
```

### 2. Root Cause: Overly Simplistic Ambiguity Detection

**Location:** `services/ai-automation-service/src/services/clarification/detector.py`

**Problem Code (lines 412-439):**
```python
vague_actions = {
    'flash': ['fast', 'slow', 'pattern', 'color', 'duration'],
    'show': ['effect', 'pattern', 'animation'],
    'turn': ['on', 'off', 'dim', 'brighten']
}

for action, required_details in vague_actions.items():
    if action in query_lower:
        # Check if required details are present
        missing_details = [
            detail for detail in required_details
            if detail not in query_lower
        ]
        
        if missing_details:
            ambiguities.append(Ambiguity(
                type=AmbiguityType.ACTION,
                severity=AmbiguitySeverity.IMPORTANT,
                description=f"Action '{action}' is vague - missing details: {', '.join(missing_details)}",
                ...
            ))
```

### 3. Why Your Prompt Triggered False Ambiguities

Your prompt: **"flash all four Hue office lights using the Hue Flash command for 30 secs at the top of every hour."**

**What the detector found:**
- ✅ Found "flash" in query
- ❌ Looked for literal word "duration" → NOT FOUND (you said "30 secs")
- ❌ Looked for "fast" → NOT FOUND
- ❌ Looked for "slow" → NOT FOUND
- ❌ Looked for "pattern" → NOT FOUND
- ❌ Looked for "color" → NOT FOUND

**Result:** Created an IMPORTANT ambiguity for "flash" missing details: `['fast', 'slow', 'pattern', 'color', 'duration']`

**What the detector SHOULD have recognized:**
- ✅ "Hue Flash command" = specific command (doesn't need additional details)
- ✅ "30 secs" = duration specification
- ✅ "all four Hue office lights" = specific device selection
- ✅ "at the top of every hour" = specific timing

### 4. Confidence Threshold Logic

**Location:** `services/ai-automation-service/src/services/clarification/confidence_calculator.py`

**Key Logic (lines 135-165):**
```python
def should_ask_clarification(self, confidence, ambiguities, threshold=None):
    if threshold is None:
        threshold = self.default_threshold  # Default: 0.85 (85%)
    
    # Always ask if there are critical ambiguities
    has_critical = any(amb.severity == AmbiguitySeverity.CRITICAL for amb in ambiguities)
    if has_critical:
        return True
    
    # Ask if confidence is below threshold
    return confidence < threshold
```

**Impact:**
- If any CRITICAL ambiguity exists → Always asks questions
- If confidence < 0.85 → Asks questions
- Your prompt had IMPORTANT ambiguities, which reduced confidence below threshold

### 5. Question Generation (Not Hardcoded)

**Location:** `services/ai-automation-service/src/services/clarification/question_generator.py`

**Process:**
1. Takes detected ambiguities
2. Builds a prompt for OpenAI (lines 97-208)
3. OpenAI generates natural-language questions based on ambiguities
4. Questions are parsed and structured

**Example Prompt Template (line 197):**
```python
"question_text": "There are 4 Hue lights in your office. Did you want all four to flash, or specific ones?",
```

This is an **example in the prompt template**, not a hardcoded question. OpenAI generates similar questions based on the actual ambiguities detected.

## Issues Identified

### Issue 1: Literal Keyword Matching
- Looks for exact words like "duration" instead of recognizing "30 secs", "for 30 seconds", etc.
- Doesn't understand time expressions

### Issue 2: No Context Awareness
- Doesn't recognize "Hue Flash command" as a specific command that doesn't need additional details
- Doesn't understand that some actions have built-in behaviors

### Issue 3: No Semantic Understanding
- Doesn't parse "all four" as a clear device selection
- Doesn't understand that "using the Hue Flash command" specifies the method

### Issue 4: Overly Strict Requirements
- Requires ALL details from the vague_actions list
- Should allow for specific commands or methods that don't need those details

## Recommendations

### 1. Enhance Action Ambiguity Detection

**Add context-aware checks:**
- Recognize time expressions: "30 secs", "for 30 seconds", "30s", etc.
- Recognize specific commands: "Hue Flash command", "hue.flash", etc.
- Recognize device selection: "all four", "all lights", specific counts

**Example improvement:**
```python
# Check for duration in various formats
duration_patterns = [
    r'\d+\s*(sec|second|min|minute|hr|hour)',
    r'for\s+\d+',
    r'\d+s', r'\d+m', r'\d+h'
]
has_duration = any(re.search(p, query_lower) for p in duration_patterns)

# Check for specific commands
specific_commands = ['hue flash', 'flash command', 'using', 'via']
has_specific_command = any(cmd in query_lower for cmd in specific_commands)

# If specific command or duration found, don't flag as vague
if has_specific_command or has_duration:
    continue  # Skip ambiguity for this action
```

### 2. Improve Device Selection Recognition

**Current:** Flags "all four Hue office lights" as ambiguous if multiple matches found

**Should:** Recognize "all four" as explicit selection, don't ask which ones

### 3. Add Command-Specific Knowledge

**Add whitelist of commands that don't need additional details:**
```python
SELF_CONTAINED_COMMANDS = {
    'hue flash': ['hue flash command', 'hue.flash', 'hue flash'],
    'wled effect': ['wled effect', 'wled.show'],
    # ... more commands
}
```

### 4. Reduce False Positive Rate

**Options:**
- Increase severity threshold (IMPORTANT → OPTIONAL for vague actions)
- Add confidence boost when specific commands are detected
- Skip ambiguity detection if query contains specific technical terms

## Code Locations

1. **Ambiguity Detection:** `services/ai-automation-service/src/services/clarification/detector.py`
   - Lines 399-441: `_detect_action_ambiguities()`
   - Lines 73-344: `_detect_device_ambiguities()`

2. **Confidence Calculation:** `services/ai-automation-service/src/services/clarification/confidence_calculator.py`
   - Lines 135-165: `should_ask_clarification()`

3. **Question Generation:** `services/ai-automation-service/src/services/clarification/question_generator.py`
   - Lines 25-95: `generate_questions()`
   - Lines 97-208: `_build_question_generation_prompt()`

4. **Router Integration:** `services/ai-automation-service/src/api/ask_ai_router.py`
   - Lines 3832-3884: Clarification detection and question generation

## Conclusion

The questions are **dynamically generated** by OpenAI, not hardcoded. However, the **ambiguity detection is too simplistic** and creates false positives for clear prompts. The system needs:

1. **Better context understanding** (recognize specific commands, time expressions)
2. **Semantic parsing** (understand "all four" means all devices)
3. **Command whitelisting** (some commands don't need additional details)
4. **Smarter keyword matching** (recognize "30 secs" as duration, not just "duration")

The current implementation is too literal and doesn't understand natural language context, leading to unnecessary clarification questions.


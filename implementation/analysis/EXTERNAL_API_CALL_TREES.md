# External API Services Call Tree Analysis
## Dashboard ‚Üí Admin API ‚Üí External Data Sources

**Document Version**: 1.3 (Code Verified 2025-10-14)  
**Created**: 2025-10-13  
**Last Updated**: 2025-10-14 (Code verification - Sports service implementation details)  
**Verification Status**: ‚úÖ Verified against actual code implementation  
**Purpose**: Detailed call trees for all external API services showing complete data flow patterns

> **Epic 12 Update**: Sports data service now has **InfluxDB persistence** (Hybrid Pattern A+B)
> - Live game cache: 15-second TTL (Pattern B - on-demand)
> - Historical storage: InfluxDB with 2-year retention (Pattern A - persistent)
> - New endpoints: Historical queries, HA automation, webhooks
> - Background task: Event detection every 15 seconds
>
> **Epic 13 Update**: External API queries now routed through **data-api:8006** instead of admin-api:8003
> - Sports data queries: `data-api:8006/api/v1/sports/*`
> - Historical data queries moved to data-api for better scalability
> - admin-api now focuses solely on system monitoring

---

## üîó Related Documentation

- [HA Event Call Tree](./HA_EVENT_CALL_TREE.md)
- [Architecture Overview](../../docs/architecture.md)
- [Tech Stack](../../docs/architecture/tech-stack.md)
- [Source Tree Structure](../../docs/architecture/source-tree.md)
- [Data Models](../../docs/architecture/data-models.md)
- [API Documentation](../../docs/API_DOCUMENTATION.md)

---

## üîç Quick Reference

| Question | Answer | Section |
|----------|--------|---------|
| How many external services? | 6 services | [Service Catalog](#-service-catalog) |
| What are the two patterns? | Push (continuous), Pull (on-demand), **Hybrid (Epic 12)** | [Overview](#-overview) |
| Which services push to InfluxDB? | Air Quality, Carbon, Electricity, Smart Meter, Calendar, **Sports (Epic 12 ‚úÖ)** | [Pattern A](#pattern-a-continuous-push-to-influxdb) |
| Which services use direct queries? | Sports Data (with cache + InfluxDB ‚úÖ) | [Pattern B](#pattern-b-on-demand-pull-queries) |
| How often do services fetch data? | 5-60 minutes (varies by service) | [Service Details](#-service-specific-call-trees) |
| Are caching strategies used? | Yes, all services implement caching | [Caching](#-caching-strategies) |
| How to query external data? | Via **data-api** endpoints (Epic 13) | [API Layer](#phase-3-data-api-gateway-epic-13) |
| **Does sports data persist?** | **Yes, InfluxDB 2-year retention (Epic 12 ‚úÖ COMPLETE)** | [Sports Persistence](#epic-12-sports-data-influxdb-persistence) |
| **Are webhooks supported?** | **Yes, HA automation webhooks (Epic 12 ‚úÖ COMPLETE)** | [Webhooks](#sports-webhooks-for-ha-automation) |

---

## üîå Service Ports Reference

| Service | Port | Purpose | Data Pattern | Fetch Interval | Required |
|---------|------|---------|--------------|----------------|----------|
| **data-api** | **8006** | **Feature data hub (queries)** | **API Gateway** | **Per request** | **Yes** |
| admin-api | 8003 | System monitoring & control | API Gateway | Per request | Yes |
| sports-data | 8005 | NFL/NHL game data (cache) | Pull (on-demand) | Per request | Optional |
| air-quality-service | 8012 | AQI from AirNow API | Push (continuous) | 60 min | Optional |
| carbon-intensity-service | 8010 | Grid carbon from WattTime | Push (continuous) | 15 min | Optional |
| electricity-pricing-service | 8011 | Real-time pricing | Push (continuous) | 60 min | Optional |
| calendar-service | 8013 | Google Calendar occupancy | Push (continuous) | 15 min | Optional |
| smart-meter-service | 8014 | Power consumption | Push (continuous) | 5 min | Optional |

**Note**: As of Epic 13, data-api handles all feature queries (sports, events, devices), while admin-api handles system monitoring.

**Current Implementation (v1.0)**: Sports-data service implements **Pattern B (Cache-Only)**:
- **Live Games (Pattern B)**: Cache-first with 15s TTL (live) and 5min TTL (upcoming), on-demand ESPN API calls ‚Üí `sports-data:8005`
- **Team Filtering**: User selects teams via `team_ids` parameter to minimize API calls
- **Available Endpoints**: `/api/v1/games/live`, `/api/v1/games/upcoming`, `/api/v1/teams`, `/api/v1/metrics/api-usage`
- **No Persistence**: Currently no InfluxDB storage (pure cache service)

**Epic 12 Features (‚úÖ COMPLETE - October 14, 2025)**:
- ‚úÖ **Persistence (Pattern A)**: Write fetched data to InfluxDB asynchronously, 2-year retention  
- ‚úÖ **Historical Queries**: `/api/v1/games/history`, `/api/v1/games/timeline/{id}`, `/api/v1/games/schedule/{team}`
- ‚úÖ **HA Automation**: `/api/v1/ha/game-status/{team}`, `/api/v1/ha/game-context/{team}` (<50ms response)  
- ‚úÖ **Webhooks**: Event detection background task (15s interval) with HMAC-signed delivery  
- ‚úÖ **Statistics**: Win/loss records, season schedules, game timelines from InfluxDB

---

## üìä Overview

External API services integrate third-party data sources into the Home Assistant Ingestor system. These services follow two distinct patterns based on their data characteristics and usage patterns.

### Two Data Flow Patterns

#### Pattern A: Continuous Push to InfluxDB
**Services**: Air Quality, Carbon Intensity, Electricity Pricing, Smart Meter, Calendar

```
External API ‚Üí Service (periodic fetch) ‚Üí InfluxDB ‚Üí Admin API ‚Üí Dashboard
```

**Characteristics**:
- **Continuous Operation**: Services run background loops
- **Periodic Fetching**: Data fetched at regular intervals (5-60 min)
- **InfluxDB Storage**: Data persisted for historical queries
- **Caching**: Short-term cache for API failures
- **Use Case**: Time-series data, trending, historical analysis

#### Pattern B: On-Demand Pull Queries (Cache Only)
**Services**: Sports Data

```
Dashboard ‚Üí Data API ‚Üí Service ‚Üí External API (if cache miss) ‚Üí Response
                                     ‚Üì
                                In-Memory Cache (15s/5min TTL)
```

**Characteristics**:
- **Request-Driven**: Data fetched only when requested
- **Short-TTL Cache**: 15-second cache for live games, 5-minute for upcoming
- **No Persistence**: Currently no InfluxDB storage (pure cache service)
- **Low API Usage**: Team filtering minimizes API calls to stay within free tier
- **Use Case**: Real-time data that changes frequently

**Current Limitations**:
- No historical data storage - cache only keeps recent data
- No season statistics or win/loss tracking
- No webhooks or HA automation support
- Manual team selection required for filtering

**Epic 12 Enhancements (‚úÖ COMPLETE - October 14, 2025)**:
- ‚úÖ **Hybrid Pattern**: Persistent storage (Pattern A) alongside cache (Pattern B)
- ‚úÖ **InfluxDB Writes**: Non-blocking async writes for historical queries
- ‚úÖ **Background Events**: Event detector monitoring game state changes every 15 seconds
- ‚úÖ **Webhooks**: HMAC-signed webhooks for HA automations with retry logic

---

### Architecture Overview Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      External APIs                          ‚îÇ
‚îÇ  AirNow ‚îÇ WattTime ‚îÇ Awattar ‚îÇ ESPN ‚îÇ Google ‚îÇ Smart Meter ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ         ‚îÇ         ‚îÇ        ‚îÇ       ‚îÇ          ‚îÇ
     ‚îÇ Pattern A: Continuous Push  ‚îÇ       ‚îÇ Pattern B: Cache Only ‚îÇ
     ‚îÇ (60min) ‚îÇ (15min) ‚îÇ (60min)‚îÇ(5min) ‚îÇ (15min)  ‚îÇ(ESPN API, no persist)
     ‚ñº         ‚ñº         ‚ñº        ‚ñº       ‚ñº          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    External API Services           ‚îÇ   ‚îÇ   Sports Data Service       ‚îÇ
‚îÇ  (Ports: 8010-8014)               ‚îÇ   ‚îÇ   (Port 8005) ‚úÖ v1.0       ‚îÇ
‚îÇ  - Periodic fetching               ‚îÇ   ‚îÇ   ‚úÖ ESPN API (free)        ‚îÇ
‚îÇ  - Background loops                ‚îÇ   ‚îÇ   ‚úÖ On-demand queries      ‚îÇ
‚îÇ  - Error handling                  ‚îÇ   ‚îÇ   ‚úÖ 15s/5min cache TTL    ‚îÇ
‚îÇ  - InfluxDB persistence            ‚îÇ   ‚îÇ   ‚úÖ Team filtering         ‚îÇ
‚îÇ                                    ‚îÇ   ‚îÇ   ‚è≥ NO InfluxDB (planned) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                                           ‚îÇ
         ‚îÇ Write continuously                        ‚îÇ NO persistence
         ‚ñº                                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      InfluxDB (Port 8086)                                  ‚îÇ
‚îÇ  Current Measurements:                                     ‚îÇ
‚îÇ   ‚úÖ home_assistant_events (from websocket-ingestion)     ‚îÇ
‚îÇ   ‚úÖ air_quality, carbon_intensity, electricity_pricing   ‚îÇ
‚îÇ   ‚úÖ smart_meter, occupancy_prediction                     ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  Planned [EPIC 12]:                                        ‚îÇ
‚îÇ   ‚è≥ nfl_scores, nhl_scores (2-year retention)            ‚îÇ
‚îÇ   ‚è≥ Tags: game_id, season, week, home_team, away_team    ‚îÇ
‚îÇ   ‚è≥ Fields: home_score, away_score, quarter, time        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Flux/SQL queries                          
         ‚ñº                                           
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Data API Service (Port 8006) [EPIC 13]              ‚îÇ
‚îÇ  - Gateway for feature data queries                          ‚îÇ
‚îÇ  - Events & Devices Endpoints: ‚úÖ Implemented                ‚îÇ
‚îÇ  - Sports Endpoints [CURRENT v1.0]:                          ‚îÇ
‚îÇ    ‚úÖ Proxies to sports-data:8005 (ESPN cache)              ‚îÇ
‚îÇ    ‚úÖ /api/v1/sports/live-games?teams=sf,dal                ‚îÇ
‚îÇ    ‚úÖ /api/v1/sports/upcoming-games                          ‚îÇ
‚îÇ  - Sports Endpoints [EPIC 12 PLANNED]:                       ‚îÇ
‚îÇ    ‚è≥ /api/v1/sports/games/history (InfluxDB queries)       ‚îÇ
‚îÇ    ‚è≥ /api/v1/sports/games/timeline/{id} (progression)      ‚îÇ
‚îÇ    ‚è≥ /api/v1/ha/game-status/{team} (HA automation)         ‚îÇ
‚îÇ    ‚è≥ /api/v1/ha/webhooks/* (webhook management)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ               ‚îÇ         Admin API Service (Port 8003) [EPIC 13]             ‚îÇ
         ‚îÇ               ‚îÇ  - System monitoring and control                             ‚îÇ
         ‚îÇ               ‚îÇ  - Health checks and Docker management                      ‚îÇ
         ‚îÇ               ‚îÇ  - Configuration and system stats                           ‚îÇ
         ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                        ‚îÇ
         ‚îÇ HTTP/REST              ‚îÇ HTTP/REST
         ‚îÇ (Feature Data)         ‚îÇ (System Monitoring)
         ‚îÇ                        ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚ñ∫ nginx (Port 3000)
                                  ‚îÇ
                                  ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ         Health Dashboard (Port 3000)                         ‚îÇ
                    ‚îÇ  Sports Tab [CURRENT v1.0]:                                  ‚îÇ
                    ‚îÇ   ‚úÖ Live games from ESPN (15s cache)                        ‚îÇ
                    ‚îÇ   ‚úÖ Upcoming games list (5min cache)                        ‚îÇ
                    ‚îÇ   ‚úÖ Team selection UI                                       ‚îÇ
                    ‚îÇ   ‚úÖ Real-time score updates                                 ‚îÇ
                    ‚îÇ  Sports Tab [EPIC 12 PLANNED]:                               ‚îÇ
                    ‚îÇ   ‚è≥ Historical season stats from InfluxDB                   ‚îÇ
                    ‚îÇ   ‚è≥ Win/loss tracking & trends                              ‚îÇ
                    ‚îÇ   ‚è≥ HA automation triggers                                  ‚îÇ
                    ‚îÇ  Other Tabs:                                                 ‚îÇ
                    ‚îÇ   ‚úÖ Overview, Services, Devices, Events, Logs               ‚îÇ
                    ‚îÇ   ‚úÖ Data Sources (air quality, carbon, pricing, meter)      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Sequence Diagram (Mermaid)

```mermaid
sequenceDiagram
    participant ExtAPI as External APIs<br/>(AirNow, WattTime, etc.)
    participant Service as External API Service<br/>(Ports 8010-8014)
    participant DB as InfluxDB<br/>(Port 8086)
    participant DataAPI as Data API<br/>(Port 8006)
    participant AdminAPI as Admin API<br/>(Port 8003)
    participant UI as Dashboard<br/>(Port 3000)
    participant SportsAPI as ESPN API
    participant SportsService as Sports Data Service<br/>(Port 8005)
    
    Note over Service,DB: Pattern A: Continuous Push (Air Quality, Carbon, etc.)
    
    loop Every 5-60 minutes
        Service->>ExtAPI: GET /api/data (API key)
        ExtAPI-->>Service: JSON response
        Service->>Service: Parse & validate
        Service->>DB: Write Point (time-series)
        DB-->>Service: Write confirmation
        Service->>Service: Update cache
    end
    
    Note over UI,DB: Dashboard Queries Historical Data
    
    UI->>DataAPI: GET /api/v1/data-sources/air-quality
    DataAPI->>DB: Flux query (last 24h)
    DB-->>DataAPI: Time-series data
    DataAPI->>DataAPI: Format response
    DataAPI-->>UI: JSON response
    UI->>UI: Render charts
    
    Note over UI,SportsService: Hybrid Pattern (A+B): Sports Data [EPIC 12]
    
    Note over UI,DB: Live Games Query (Pattern B - Cache-First)
    UI->>DataAPI: GET /api/v1/sports/live-games?teams=sf,dal
    DataAPI->>SportsService: Proxy request
    
    alt Cache Hit
        SportsService->>SportsService: Return cached data (15s TTL)
        SportsService-->>DataAPI: JSON (from cache)
    else Cache Miss
        SportsService->>SportsAPI: GET /scoreboard (no auth)
        SportsAPI-->>SportsService: JSON response
        SportsService->>SportsService: Filter by teams
        SportsService->>SportsService: Cache (15s TTL)
        
        Note over SportsService,DB: Epic 12: Async InfluxDB Write (Pattern A)
        par Async Write (non-blocking)
            SportsService->>DB: Write nfl_scores/nhl_scores
            Note right of DB: Tags: game_id, season,<br/>home_team, away_team<br/>Fields: scores, quarter
            DB-->>SportsService: Write confirmation
        end
        
        SportsService-->>DataAPI: JSON (filtered)
    end
    
    DataAPI-->>UI: JSON response
    UI->>UI: Render live scores
    
    Note over UI,DB: Historical Query (Epic 12 - InfluxDB)
    UI->>DataAPI: GET /api/v1/sports/games/history?team=Patriots&season=2025
    DataAPI->>DB: SQL Query (SELECT * FROM nfl_scores...)
    DB-->>DataAPI: Time-series game data
    DataAPI->>DataAPI: Calculate stats (wins/losses)
    DataAPI-->>UI: JSON (games + statistics)
    UI->>UI: Render season stats
    
    Note over SportsService,DB: Background Event Detection (Epic 12 ‚úÖ - Every 15s)
    loop Every 15 seconds
        SportsService->>DB: Query current game state
        DB-->>SportsService: Latest scores
        SportsService->>SportsService: Compare with previous state
        alt Game Event Detected
            SportsService->>SportsService: Create webhook event
            SportsService->>SportsService: Deliver webhooks (HMAC signed)
            Note right of SportsService: Events: game_start,<br/>game_end,<br/>score_change
        end
    end
```

---

## üóÇÔ∏è Service Catalog

### 1. Sports Data Service (Port 8005) [HYBRID PATTERN A+B - Epic 12 ‚úÖ]
- **Provider**: ESPN API (Free, no API key)
- **Sports**: NFL, NHL
- **Pattern**: **Hybrid Pattern A+B** - Cache + InfluxDB Persistence (Epic 12 ‚úÖ)
- **Features**: Live scores, upcoming games, historical queries, HA automation webhooks
- **Caching**: 15s TTL (live games), 5min TTL (upcoming/historical)
- **Storage**: In-memory cache + InfluxDB (2-year retention)

**Current Implementation (v2.0 - Epic 12 Complete):**
- ‚úÖ **Team-Based Filtering**: Minimize API calls by filtering to user's selected teams
- ‚úÖ **ESPN API Integration**: Free public API, no authentication required
- ‚úÖ **Cache Service**: In-memory caching with configurable TTLs
- ‚úÖ **InfluxDB Persistence**: Async writes, 2-year retention (Story 12.1)
- ‚úÖ **Historical Queries**: 3 REST endpoints for past games, timelines, schedules (Story 12.2)
- ‚úÖ **HA Automation**: Fast status endpoints (<50ms) for conditionals (Story 12.3)
- ‚úÖ **Webhooks**: HMAC-signed webhooks for game events (Story 12.3)
- ‚úÖ **Background Events**: Event detector every 15 seconds (Story 12.3)
- ‚úÖ **Statistics Engine**: Calculate wins, losses, win percentage (Story 12.2)
- ‚úÖ **Circuit Breaker**: Graceful degradation if InfluxDB unavailable (Story 12.1)

**Epic 12 Delivered (October 14, 2025):**
- **Story 12.1**: InfluxDB Persistence Layer (2 hours)
- **Story 12.2**: Historical Query Endpoints (1.5 hours)
- **Story 12.3**: Event Monitor + Webhooks (1.5 hours)
- **Total**: ~5 hours vs 9 weeks estimated (36x efficiency)

### 2. Air Quality Service (Port 8012)
- **Provider**: AirNow API
- **Data**: AQI, PM2.5, PM10, Ozone
- **Pattern**: Push (continuous)
- **Fetch Interval**: 60 minutes
- **Measurement**: `air_quality`
- **Retention**: 1 year

### 3. Carbon Intensity Service (Port 8010)
- **Provider**: WattTime API
- **Data**: Grid carbon intensity, renewable percentage
- **Pattern**: Push (continuous)
- **Fetch Interval**: 15 minutes
- **Measurement**: `carbon_intensity`
- **Retention**: 1 year

### 4. Electricity Pricing Service (Port 8011)
- **Provider**: Awattar API (configurable)
- **Data**: Real-time pricing, peak periods, forecasts
- **Pattern**: Push (continuous)
- **Fetch Interval**: 60 minutes
- **Measurement**: `electricity_pricing`
- **Retention**: 1 year

### 5. Smart Meter Service (Port 8014)
- **Provider**: Generic adapter (configurable)
- **Data**: Whole-home power, circuit-level consumption
- **Pattern**: Push (continuous)
- **Fetch Interval**: 5 minutes
- **Measurement**: `smart_meter`, `smart_meter_circuit`
- **Retention**: 1 year

### 6. Calendar Service (Port 8013)
- **Provider**: Google Calendar API
- **Data**: Occupancy prediction, WFH status
- **Pattern**: Push (continuous)
- **Fetch Interval**: 15 minutes
- **Measurement**: `occupancy_prediction`
- **Retention**: 90 days

---

## üîÑ Detailed Call Trees

### Pattern A: Continuous Push to InfluxDB

This pattern applies to: **Air Quality**, **Carbon Intensity**, **Electricity Pricing**, **Smart Meter**, **Calendar**

---

## üìà Service-Specific Call Trees

### Service 1: Air Quality Service (Port 8012)

#### Phase 1: Service Initialization

**File**: `services/air-quality-service/src/main.py`

```python
main()
‚îî‚îÄ‚ñ∫ logger.info("Starting Air Quality Service...")
    ‚îî‚îÄ‚ñ∫ AirQualityService.__init__()
        ‚îú‚îÄ‚ñ∫ Load environment variables
        ‚îÇ   ‚îú‚îÄ‚ñ∫ AIRNOW_API_KEY (required)
        ‚îÇ   ‚îú‚îÄ‚ñ∫ LATITUDE, LONGITUDE (location)
        ‚îÇ   ‚îú‚îÄ‚ñ∫ INFLUXDB_TOKEN, INFLUXDB_URL
        ‚îÇ   ‚îî‚îÄ‚ñ∫ Validate required vars
        ‚îÇ
        ‚îú‚îÄ‚ñ∫ Configure service parameters
        ‚îÇ   ‚îú‚îÄ‚ñ∫ base_url = "https://www.airnowapi.org/aq/observation/latLong/current/"
        ‚îÇ   ‚îú‚îÄ‚ñ∫ fetch_interval = 3600 seconds (1 hour)
        ‚îÇ   ‚îî‚îÄ‚ñ∫ cache_duration = 60 minutes
        ‚îÇ
        ‚îú‚îÄ‚ñ∫ Initialize components
        ‚îÇ   ‚îú‚îÄ‚ñ∫ cached_data = None
        ‚îÇ   ‚îú‚îÄ‚ñ∫ last_fetch_time = None
        ‚îÇ   ‚îî‚îÄ‚ñ∫ health_handler = HealthCheckHandler()
        ‚îÇ
        ‚îî‚îÄ‚ñ∫ startup()
            ‚îú‚îÄ‚ñ∫ aiohttp.ClientSession(timeout=10s)
            ‚îú‚îÄ‚ñ∫ InfluxDBClient3(host, token, database, org)
            ‚îî‚îÄ‚ñ∫ logger.info("Air Quality Service initialized")
```

**Initialization Checklist**:
- ‚úÖ API key validated
- ‚úÖ Location configured (lat/lon)
- ‚úÖ HTTP session created with timeout
- ‚úÖ InfluxDB client connected
- ‚úÖ Health check endpoint ready

---

#### Phase 2: Continuous Data Collection Loop

**File**: `services/air-quality-service/src/main.py`

```python
run_continuous()
‚îî‚îÄ‚ñ∫ while True:  # Infinite loop
    ‚îú‚îÄ‚ñ∫ try:
    ‚îÇ   ‚îú‚îÄ‚ñ∫ fetch_air_quality()
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ log_with_context("Fetching AQI for location...")
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ session.get(base_url, params={
    ‚îÇ   ‚îÇ   ‚îÇ     "latitude": self.latitude,
    ‚îÇ   ‚îÇ   ‚îÇ     "longitude": self.longitude,
    ‚îÇ   ‚îÇ   ‚îÇ     "format": "application/json",
    ‚îÇ   ‚îÇ   ‚îÇ     "API_KEY": self.api_key
    ‚îÇ   ‚îÇ   ‚îÇ   })
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ if response.status == 200:
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ raw_data = await response.json()
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Example response:
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # [
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   #   {"AQI": 45, "ParameterName": "PM2.5", "Category": {"Name": "Good"}},
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   #   {"AQI": 38, "ParameterName": "OZONE", "Category": {"Name": "Good"}}
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # ]
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ Parse response into unified structure:
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   data = {
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ       'aqi': max(all AQI values),  # Worst parameter
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ       'category': 'Good' | 'Moderate' | 'Unhealthy',
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ       'parameter': 'PM2.5' | 'PM10' | 'OZONE',
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ       'pm25': specific PM2.5 AQI,
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ       'pm10': specific PM10 AQI,
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ       'ozone': specific Ozone AQI,
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ       'timestamp': datetime.now()
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   }
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ if category changed from last_category:
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ logger.warning("AQI category changed")
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ Update cache
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ self.cached_data = data
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ self.last_fetch_time = now
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ Update health metrics
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ health_handler.last_successful_fetch = now
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ health_handler.total_fetches += 1
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ return data
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ else:  # API error
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚ñ∫ logger.error("AirNow API returned status {status}")
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚ñ∫ health_handler.failed_fetches += 1
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚ñ∫ return self.cached_data  # Fallback
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚ñ∫ if data:
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ store_in_influxdb(data)
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚ñ∫ point = Point("air_quality")
    ‚îÇ   ‚îÇ       ‚îÇ   .tag("location", "36.1699,-115.1398")
    ‚îÇ   ‚îÇ       ‚îÇ   .tag("category", "Good")
    ‚îÇ   ‚îÇ       ‚îÇ   .tag("parameter", "PM2.5")
    ‚îÇ   ‚îÇ       ‚îÇ   .field("aqi", 45)
    ‚îÇ   ‚îÇ       ‚îÇ   .field("pm25", 45)
    ‚îÇ   ‚îÇ       ‚îÇ   .field("pm10", 38)
    ‚îÇ   ‚îÇ       ‚îÇ   .field("ozone", 32)
    ‚îÇ   ‚îÇ       ‚îÇ   .time(timestamp)
    ‚îÇ   ‚îÇ       ‚îÇ
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚ñ∫ influxdb_client.write(point)
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚ñ∫ logger.info("AQI data written to InfluxDB")
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚ñ∫ await asyncio.sleep(3600)  # Wait 1 hour
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ except Exception as e:
        ‚îú‚îÄ‚ñ∫ log_error_with_context("Error in continuous loop")
        ‚îî‚îÄ‚ñ∫ await asyncio.sleep(300)  # Wait 5 min before retry
```

**Loop Characteristics**:
- **Interval**: 3600 seconds (1 hour)
- **Error Recovery**: 5-minute retry delay on failure
- **Fallback**: Returns cached data if API fails
- **Monitoring**: Health metrics updated on each attempt

---

#### Phase 3: Data Retrieval (Dashboard Query)

**Dashboard Request Flow**:

```
Dashboard (React)
‚îî‚îÄ‚ñ∫ apiService.getAirQuality()
    ‚îî‚îÄ‚ñ∫ fetch('http://localhost:8003/api/data-sources/air-quality')
        ‚îî‚îÄ‚ñ∫ Admin API: /api/data-sources/air-quality
            ‚îî‚îÄ‚ñ∫ InfluxDBClient.query()
                ‚îú‚îÄ‚ñ∫ Flux query:
                ‚îÇ   from(bucket: "events")
                ‚îÇ     |> range(start: -24h)
                ‚îÇ     |> filter(fn: (r) => r._measurement == "air_quality")
                ‚îÇ     |> filter(fn: (r) => r.location == "36.1699,-115.1398")
                ‚îÇ     |> sort(columns: ["_time"], desc: true)
                ‚îÇ     |> limit(n: 100)
                ‚îÇ
                ‚îú‚îÄ‚ñ∫ Parse FluxTable results
                ‚îÇ   ‚îî‚îÄ‚ñ∫ Extract: time, aqi, category, pm25, pm10, ozone
                ‚îÇ
                ‚îî‚îÄ‚ñ∫ return JSON:
                    [
                      {
                        "timestamp": "2025-10-13T10:00:00Z",
                        "aqi": 45,
                        "category": "Good",
                        "pm25": 45,
                        "pm10": 38,
                        "ozone": 32
                      },
                      ...
                    ]
```

**Response Format**:
```json
{
  "current": {
    "aqi": 45,
    "category": "Good",
    "primary_pollutant": "PM2.5",
    "timestamp": "2025-10-13T10:00:00Z"
  },
  "history_24h": [
    {"timestamp": "2025-10-13T10:00:00Z", "aqi": 45},
    {"timestamp": "2025-10-13T09:00:00Z", "aqi": 42},
    ...
  ],
  "statistics": {
    "min": 38,
    "max": 52,
    "average": 44.5
  }
}
```

---

### Service 2: Carbon Intensity Service (Port 8010)

**Similar structure to Air Quality, key differences**:

#### Data Fetch Call Tree

**File**: `services/carbon-intensity-service/src/main.py`

```python
fetch_carbon_intensity()
‚îî‚îÄ‚ñ∫ url = f"{base_url}/forecast"  # WattTime V3 API
    ‚îú‚îÄ‚ñ∫ headers = {"Authorization": f"Bearer {api_token}"}
    ‚îú‚îÄ‚ñ∫ params = {"region": "CAISO_NORTH"}
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ session.get(url, headers=headers, params=params)
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ if response.status == 200:
        ‚îú‚îÄ‚ñ∫ raw_data = await response.json()
        ‚îÇ   # WattTime response structure:
        ‚îÇ   # {
        ‚îÇ   #   "moer": 850,  # Marginal emissions rate (gCO2/kWh)
        ‚îÇ   #   "renewable_pct": 35.2,
        ‚îÇ   #   "fossil_pct": 64.8,
        ‚îÇ   #   "forecast": [
        ‚îÇ   #     {"value": 820, "timestamp": "2025-10-13T11:00:00Z"},
        ‚îÇ   #     {"value": 780, "timestamp": "2025-10-13T12:00:00Z"},
        ‚îÇ   #     ...
        ‚îÇ   #   ]
        ‚îÇ   # }
        ‚îÇ
        ‚îú‚îÄ‚ñ∫ Parse into structured format:
        ‚îÇ   data = {
        ‚îÇ       'carbon_intensity': 850,  # gCO2/kWh
        ‚îÇ       'renewable_percentage': 35.2,
        ‚îÇ       'fossil_percentage': 64.8,
        ‚îÇ       'forecast_1h': 820,  # Next hour forecast
        ‚îÇ       'forecast_24h': 650,  # 24 hours ahead
        ‚îÇ       'timestamp': datetime.now()
        ‚îÇ   }
        ‚îÇ
        ‚îú‚îÄ‚ñ∫ Update cache
        ‚îú‚îÄ‚ñ∫ Update health metrics
        ‚îî‚îÄ‚ñ∫ return data
```

**InfluxDB Write Structure**:
```python
Point("carbon_intensity")
    .tag("region", "CAISO_NORTH")
    .tag("grid_operator", "CAISO")
    .field("carbon_intensity_gco2_kwh", 850.0)
    .field("renewable_percentage", 35.2)
    .field("fossil_percentage", 64.8)
    .field("forecast_1h", 820.0)
    .field("forecast_24h", 650.0)
    .time(timestamp)
```

**Key Differences from Air Quality**:
- ‚úÖ Requires OAuth token (vs API key)
- ‚úÖ Includes forecast data (1h, 24h ahead)
- ‚úÖ Faster interval: 15 minutes (vs 60 minutes)
- ‚úÖ Regional data (grid-specific)

---

### Service 3: Electricity Pricing Service (Port 8011)

#### Provider Adapter Pattern

**File**: `services/electricity-pricing-service/src/main.py`

```python
ElectricityPricingService.__init__()
‚îî‚îÄ‚ñ∫ _get_provider()
    ‚îú‚îÄ‚ñ∫ provider_name = os.getenv('PRICING_PROVIDER', 'awattar')
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ providers = {
        'awattar': AwattarProvider(),
        # Future: 'octopus': OctopusProvider(),
        # Future: 'tibber': TibberProvider()
    }
    ‚îî‚îÄ‚ñ∫ return providers.get(provider_name)
```

#### Pricing Fetch Call Tree

**File**: `services/electricity-pricing-service/src/providers/awattar.py`

```python
AwattarProvider.fetch_pricing(session)
‚îî‚îÄ‚ñ∫ url = "https://api.awattar.de/v1/marketdata"
    ‚îú‚îÄ‚ñ∫ params = {
    ‚îÇ     "start": today_midnight_timestamp,
    ‚îÇ     "end": tomorrow_midnight_timestamp
    ‚îÇ   }
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ session.get(url, params=params)  # No auth required
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ if response.status == 200:
        ‚îú‚îÄ‚ñ∫ raw_data = await response.json()
        ‚îÇ   # Awattar response:
        ‚îÇ   # {
        ‚îÇ   #   "data": [
        ‚îÇ   #     {
        ‚îÇ   #       "start_timestamp": 1697155200000,  # Unix timestamp (ms)
        ‚îÇ   #       "end_timestamp": 1697158800000,
        ‚îÇ   #       "marketprice": 85.23,  # EUR/MWh
        ‚îÇ   #       "unit": "Eur/MWh"
        ‚îÇ   #     },
        ‚îÇ   #     ...
        ‚îÇ   #   ]
        ‚îÇ   # }
        ‚îÇ
        ‚îú‚îÄ‚ñ∫ Process pricing data:
        ‚îÇ   ‚îú‚îÄ‚ñ∫ Convert EUR/MWh ‚Üí EUR/kWh (divide by 1000)
        ‚îÇ   ‚îú‚îÄ‚ñ∫ Find current hour price
        ‚îÇ   ‚îú‚îÄ‚ñ∫ Identify peak period (top 25% prices)
        ‚îÇ   ‚îú‚îÄ‚ñ∫ Find cheapest hours (bottom 4 hours)
        ‚îÇ   ‚îî‚îÄ‚ñ∫ Extract 24h forecast
        ‚îÇ
        ‚îî‚îÄ‚ñ∫ return {
            'current_price': 0.08523,  # EUR/kWh
            'currency': 'EUR',
            'peak_period': False,
            'cheapest_hours': [
                {'hour': 3, 'price': 0.05234},
                {'hour': 4, 'price': 0.05512},
                {'hour': 2, 'price': 0.05789},
                {'hour': 15, 'price': 0.06012}
            ],
            'forecast_24h': [
                {'hour': 0, 'price': 0.08123, 'timestamp': '2025-10-13T00:00:00Z'},
                {'hour': 1, 'price': 0.07845, 'timestamp': '2025-10-13T01:00:00Z'},
                ...
            ],
            'timestamp': datetime.now(),
            'provider': 'awattar'
        }
```

**Special Endpoint**: `/cheapest-hours`

```python
get_cheapest_hours(request)
‚îî‚îÄ‚ñ∫ hours_needed = int(request.query.get('hours', 4))
    ‚îî‚îÄ‚ñ∫ if cached_data:
        ‚îî‚îÄ‚ñ∫ return {
            'cheapest_hours': cached_data['cheapest_hours'][:hours_needed],
            'provider': 'awattar',
            'timestamp': last_fetch_time.isoformat(),
            'optimal_for': 'charging EV, running dishwasher, etc.'
        }
```

**Use Case**: Smart home automation can schedule energy-intensive tasks during cheapest hours.

---

### Service 4: Smart Meter Service (Port 8014)

#### Multi-Level Data Collection

**File**: `services/smart-meter-service/src/main.py`

```python
fetch_consumption()
‚îî‚îÄ‚ñ∫ Generic implementation (adapter pattern for various meters)
    ‚îú‚îÄ‚ñ∫ Whole-home consumption:
    ‚îÇ   data = {
    ‚îÇ       'total_power_w': 2450.0,  # Current total power
    ‚îÇ       'daily_kwh': 18.5,  # Cumulative daily energy
    ‚îÇ       'timestamp': datetime.now()
    ‚îÇ   }
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Circuit-level breakdown:
    ‚îÇ   data['circuits'] = [
    ‚îÇ       {'name': 'HVAC', 'power_w': 1200.0, 'percentage': 49.0},
    ‚îÇ       {'name': 'Kitchen', 'power_w': 450.0, 'percentage': 18.4},
    ‚îÇ       {'name': 'Living Room', 'power_w': 300.0, 'percentage': 12.2},
    ‚îÇ       {'name': 'Office', 'power_w': 250.0, 'percentage': 10.2},
    ‚îÇ       {'name': 'Bedrooms', 'power_w': 150.0, 'percentage': 6.1},
    ‚îÇ       {'name': 'Other', 'power_w': 100.0, 'percentage': 4.1}
    ‚îÇ   ]
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Phantom load detection:
    ‚îÇ   if current_hour == 3:  # 3 AM baseline
    ‚îÇ       ‚îî‚îÄ‚ñ∫ if total_power_w > 200:
    ‚îÇ           ‚îî‚îÄ‚ñ∫ logger.warning("High phantom load: {power}W at 3am")
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ High consumption alert:
    ‚îÇ   if total_power_w > 10000:  # 10 kW threshold
    ‚îÇ       ‚îî‚îÄ‚ñ∫ logger.warning("High power consumption: {power}W")
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ return data
```

**InfluxDB Dual-Measurement Write**:

```python
store_in_influxdb(data)
‚îú‚îÄ‚ñ∫ # Whole-home measurement
‚îÇ   Point("smart_meter")
‚îÇ       .tag("meter_type", "generic")
‚îÇ       .field("total_power_w", 2450.0)
‚îÇ       .field("daily_kwh", 18.5)
‚îÇ       .time(timestamp)
‚îÇ
‚îî‚îÄ‚ñ∫ # Per-circuit measurements (6 points)
    for circuit in circuits:
        Point("smart_meter_circuit")
            .tag("circuit_name", circuit['name'])
            .field("power_w", circuit['power_w'])
            .field("percentage", circuit['percentage'])
            .time(timestamp)
```

**Query Pattern** (Admin API):

```flux
// Whole-home power
from(bucket: "events")
  |> range(start: -24h)
  |> filter(fn: (r) => r._measurement == "smart_meter")
  |> filter(fn: (r) => r._field == "total_power_w")

// Circuit breakdown (current)
from(bucket: "events")
  |> range(start: -5m)
  |> filter(fn: (r) => r._measurement == "smart_meter_circuit")
  |> last()
  |> group(columns: ["circuit_name"])
```

**Dashboard Visualization**:
- Real-time power gauge (total_power_w)
- Daily energy counter (daily_kwh)
- Circuit breakdown pie chart
- 24-hour power trend line

---

### Service 5: Calendar Service (Port 8013)

#### Google Calendar Integration

**File**: `services/calendar-service/src/main.py`

```python
CalendarService.__init__()
‚îî‚îÄ‚ñ∫ OAuth Configuration:
    ‚îú‚îÄ‚ñ∫ client_id = os.getenv('GOOGLE_CLIENT_ID')
    ‚îú‚îÄ‚ñ∫ client_secret = os.getenv('GOOGLE_CLIENT_SECRET')
    ‚îú‚îÄ‚ñ∫ refresh_token = os.getenv('GOOGLE_REFRESH_TOKEN')
    ‚îî‚îÄ‚ñ∫ Validate all required

startup()
‚îî‚îÄ‚ñ∫ Setup OAuth credentials:
    ‚îú‚îÄ‚ñ∫ credentials = Credentials(
    ‚îÇ     token=None,
    ‚îÇ     refresh_token=refresh_token,
    ‚îÇ     token_uri="https://oauth2.googleapis.com/token",
    ‚îÇ     client_id=client_id,
    ‚îÇ     client_secret=client_secret
    ‚îÇ   )
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ if not credentials.valid:
    ‚îÇ   ‚îî‚îÄ‚ñ∫ credentials.refresh(Request())  # Get new access token
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ calendar_service = build('calendar', 'v3', credentials=credentials)
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ health_handler.oauth_valid = True
```

#### Occupancy Prediction Logic

```python
predict_home_status()
‚îî‚îÄ‚ñ∫ get_today_events()
    ‚îú‚îÄ‚ñ∫ now = datetime.now().isoformat() + 'Z'
    ‚îú‚îÄ‚ñ∫ end_of_day = today_23:59.isoformat() + 'Z'
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ calendar_service.events().list(
    ‚îÇ     calendarId='primary',
    ‚îÇ     timeMin=now,
    ‚îÇ     timeMax=end_of_day,
    ‚îÇ     singleEvents=True,
    ‚îÇ     orderBy='startTime'
    ‚îÇ   ).execute()
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ for event in events:
        ‚îú‚îÄ‚ñ∫ Parse event:
        ‚îÇ   ‚îú‚îÄ‚ñ∫ summary = "Team Meeting" or "WFH Day"
        ‚îÇ   ‚îú‚îÄ‚ñ∫ location = "Office" or "Home"
        ‚îÇ   ‚îú‚îÄ‚ñ∫ start/end times
        ‚îÇ   ‚îî‚îÄ‚ñ∫ is_wfh = 'WFH' in summary OR 'HOME' in location
        ‚îÇ
        ‚îî‚îÄ‚ñ∫ Build occupancy prediction:
            ‚îú‚îÄ‚ñ∫ wfh_today = any event has is_wfh=True
            ‚îú‚îÄ‚ñ∫ currently_home = check if NOW is within WFH event
            ‚îÇ
            ‚îú‚îÄ‚ñ∫ Find next home arrival:
            ‚îÇ   ‚îú‚îÄ‚ñ∫ next_home_event = first future event with location='Home'
            ‚îÇ   ‚îú‚îÄ‚ñ∫ arrival_time = next_home_event.start
            ‚îÇ   ‚îú‚îÄ‚ñ∫ travel_time = 30 minutes (configurable)
            ‚îÇ   ‚îî‚îÄ‚ñ∫ prepare_time = arrival_time - travel_time
            ‚îÇ       # Smart home can pre-heat/cool before arrival
            ‚îÇ
            ‚îî‚îÄ‚ñ∫ return {
                'currently_home': True/False,
                'wfh_today': True/False,
                'next_arrival': datetime or None,
                'prepare_time': datetime or None,  # When to start HVAC
                'hours_until_arrival': float or None,
                'confidence': 0.85 if wfh_today else 0.70,
                'timestamp': datetime.now()
            }
```

**Smart Home Integration Use Cases**:
1. **HVAC Optimization**: Start heating/cooling 30 min before arrival
2. **Security System**: Arm system when leaving, disarm before arrival
3. **Lighting**: Turn on lights before sunset arrival time
4. **Energy Management**: Run appliances during absence

**InfluxDB Measurement**:
```python
Point("occupancy_prediction")
    .tag("source", "calendar")
    .tag("user", "primary")
    .field("currently_home", True)
    .field("wfh_today", True)
    .field("confidence", 0.85)
    .field("hours_until_arrival", 0.0)  # Currently home
    .time(timestamp)
```

---

### Pattern B: On-Demand Pull Queries

### Service 6: Sports Data Service (Port 8005)

**Unique Characteristics**:
- ‚úÖ No continuous loop (request-driven only)
- ‚úÖ Team-based filtering (only fetch data for user's teams)
- ‚úÖ No InfluxDB storage (transient data)
- ‚úÖ Aggressive caching (15s live, 5min upcoming)
- ‚úÖ Free API (ESPN, no authentication)

---

#### Phase 1: Service Initialization

**File**: `services/sports-data/src/main.py`

```python
main()
‚îî‚îÄ‚ñ∫ FastAPI app initialization
    ‚îú‚îÄ‚ñ∫ app = FastAPI(
    ‚îÇ     title="Sports Data Service",
    ‚îÇ     description="NFL & NHL Sports Data API with team-based filtering",
    ‚îÇ     version="1.0.0"
    ‚îÇ   )
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ CORS middleware:
    ‚îÇ   ‚îî‚îÄ‚ñ∫ allow_origins=["http://localhost:3000"]  # Dashboard
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Initialize services:
    ‚îÇ   ‚îú‚îÄ‚ñ∫ cache = CacheService()
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ in-memory cache (dict)
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ TTL tracking per key
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ Statistics: hits, misses
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚ñ∫ sports_client = SportsAPIClient(cache=cache)
    ‚îÇ       ‚îú‚îÄ‚ñ∫ ESPN base URLs
    ‚îÇ       ‚îú‚îÄ‚ñ∫ API call counters
    ‚îÇ       ‚îî‚îÄ‚ñ∫ Team mapping data
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ Endpoints registered:
        ‚îú‚îÄ‚ñ∫ GET /health
        ‚îú‚îÄ‚ñ∫ GET /api/v1/games/live
        ‚îú‚îÄ‚ñ∫ GET /api/v1/games/upcoming
        ‚îú‚îÄ‚ñ∫ GET /api/v1/teams
        ‚îú‚îÄ‚ñ∫ GET /api/v1/user/teams
        ‚îú‚îÄ‚ñ∫ POST /api/v1/user/teams
        ‚îî‚îÄ‚ñ∫ GET /api/v1/metrics/api-usage
```

---

#### Phase 2: Dashboard Request (Live Games)

**Complete Request Flow**:

```
User opens Sports tab in Dashboard
‚îî‚îÄ‚ñ∫ React Component: SportsTab.tsx
    ‚îú‚îÄ‚ñ∫ useEffect() on mount
    ‚îú‚îÄ‚ñ∫ user_teams = localStorage.getItem('selectedTeams')  // ['sf', 'dal']
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ apiService.getLiveGames(user_teams)
        ‚îî‚îÄ‚ñ∫ fetch('http://localhost:8006/api/v1/sports/live-games?teams=sf,dal')
            
            Data API: /api/v1/sports/live-games
            ‚îî‚îÄ‚ñ∫ Proxy to sports-data service:
                ‚îî‚îÄ‚ñ∫ GET http://localhost:8005/api/v1/games/live?teams=sf,dal
                    
                    Sports Data Service: get_live_games()
                    ‚îú‚îÄ‚ñ∫ Parse team_ids:
                    ‚îÇ   ‚îî‚îÄ‚ñ∫ teams = ['sf', 'dal']  # San Francisco, Dallas
                    ‚îÇ
                    ‚îî‚îÄ‚ñ∫ sports_client.get_live_games('NFL', teams)
                        ‚îú‚îÄ‚ñ∫ cache_key = "live_games_nfl_sf_dal"
                        ‚îÇ
                        ‚îú‚îÄ‚ñ∫ Check cache:
                        ‚îÇ   ‚îî‚îÄ‚ñ∫ if cache.get(cache_key) and not expired:
                        ‚îÇ       ‚îú‚îÄ‚ñ∫ cache_stats['hits'] += 1
                        ‚îÇ       ‚îî‚îÄ‚ñ∫ return cached_data  # ‚ö° Fast path
                        ‚îÇ
                        ‚îî‚îÄ‚ñ∫ Cache miss ‚Üí Fetch from ESPN:
                            ‚îú‚îÄ‚ñ∫ cache_stats['misses'] += 1
                            ‚îÇ
                            ‚îú‚îÄ‚ñ∫ url = "https://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard"
                            ‚îú‚îÄ‚ñ∫ session.get(url)  # No auth required!
                            ‚îÇ
                            ‚îú‚îÄ‚ñ∫ if response.status == 200:
                            ‚îÇ   ‚îú‚îÄ‚ñ∫ raw_data = await response.json()
                            ‚îÇ   ‚îÇ   # ESPN scoreboard structure:
                            ‚îÇ   ‚îÇ   # {
                            ‚îÇ   ‚îÇ   #   "leagues": [...],
                            ‚îÇ   ‚îÇ   #   "events": [
                            ‚îÇ   ‚îÇ   #     {
                            ‚îÇ   ‚îÇ   #       "id": "401547413",
                            ‚îÇ   ‚îÇ   #       "status": {
                            ‚îÇ   ‚îÇ   #         "type": {"state": "in", "detail": "Q2 3:24"},
                            ‚îÇ   ‚îÇ   #       },
                            ‚îÇ   ‚îÇ   #       "competitions": [{
                            ‚îÇ   ‚îÇ   #         "competitors": [
                            ‚îÇ   ‚îÇ   #           {
                            ‚îÇ   ‚îÇ   #             "team": {"abbreviation": "SF", "displayName": "49ers"},
                            ‚îÇ   ‚îÇ   #             "score": "14",
                            ‚îÇ   ‚îÇ   #             "homeAway": "home"
                            ‚îÇ   ‚îÇ   #           },
                            ‚îÇ   ‚îÇ   #           {
                            ‚îÇ   ‚îÇ   #             "team": {"abbreviation": "DAL", "displayName": "Cowboys"},
                            ‚îÇ   ‚îÇ   #             "score": "10",
                            ‚îÇ   ‚îÇ   #             "homeAway": "away"
                            ‚îÇ   ‚îÇ   #           }
                            ‚îÇ   ‚îÇ   #         ]
                            ‚îÇ   ‚îÇ   #       }]
                            ‚îÇ   ‚îÇ   #     }
                            ‚îÇ   ‚îÇ   #   ]
                            ‚îÇ   ‚îÇ   # }
                            ‚îÇ   ‚îÇ
                            ‚îÇ   ‚îú‚îÄ‚ñ∫ Filter events by teams:
                            ‚îÇ   ‚îÇ   games = []
                            ‚îÇ   ‚îÇ   for event in raw_data['events']:
                            ‚îÇ   ‚îÇ       ‚îú‚îÄ‚ñ∫ Extract teams from competitors
                            ‚îÇ   ‚îÇ       ‚îú‚îÄ‚ñ∫ team_abbrevs = ['SF', 'DAL']
                            ‚îÇ   ‚îÇ       ‚îÇ
                            ‚îÇ   ‚îÇ       ‚îî‚îÄ‚ñ∫ if any team in user's selected teams:
                            ‚îÇ   ‚îÇ           ‚îú‚îÄ‚ñ∫ is_live = status.type.state == 'in'
                            ‚îÇ   ‚îÇ           ‚îÇ
                            ‚îÇ   ‚îÇ           ‚îî‚îÄ‚ñ∫ if is_live:
                            ‚îÇ   ‚îÇ               games.append({
                            ‚îÇ   ‚îÇ                   'id': event['id'],
                            ‚îÇ   ‚îÇ                   'league': 'NFL',
                            ‚îÇ   ‚îÇ                   'home_team': 'SF 49ers',
                            ‚îÇ   ‚îÇ                   'away_team': 'DAL Cowboys',
                            ‚îÇ   ‚îÇ                   'home_score': 14,
                            ‚îÇ   ‚îÇ                   'away_score': 10,
                            ‚îÇ   ‚îÇ                   'status': 'Q2 3:24',
                            ‚îÇ   ‚îÇ                   'is_live': True,
                            ‚îÇ   ‚îÇ                   'timestamp': now
                            ‚îÇ   ‚îÇ               })
                            ‚îÇ   ‚îÇ
                            ‚îÇ   ‚îú‚îÄ‚ñ∫ Cache filtered results:
                            ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ cache.set(cache_key, games, ttl=15)  # 15 seconds
                            ‚îÇ   ‚îÇ
                            ‚îÇ   ‚îú‚îÄ‚ñ∫ Update API usage stats:
                            ‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ api_calls_today += 1
                            ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ nfl_calls += 1
                            ‚îÇ   ‚îÇ
                            ‚îÇ   ‚îî‚îÄ‚ñ∫ return games
                            ‚îÇ
                            ‚îî‚îÄ‚ñ∫ return GameList(
                                games=games,
                                count=len(games),
                                filtered_by_teams=['sf', 'dal']
                            )
```

**Response to Dashboard**:
```json
{
  "games": [
    {
      "id": "401547413",
      "league": "NFL",
      "home_team": "SF 49ers",
      "away_team": "DAL Cowboys",
      "home_score": 14,
      "away_score": 10,
      "status": "Q2 3:24",
      "is_live": true,
      "timestamp": "2025-10-13T15:30:45Z"
    }
  ],
  "count": 1,
  "filtered_by_teams": ["sf", "dal"]
}
```

---

#### Phase 3: Caching Strategy

**File**: `services/sports-data/src/cache_service.py`

```python
CacheService
‚îú‚îÄ‚ñ∫ cache_data: Dict[str, CacheEntry] = {}
‚îÇ   # CacheEntry = {
‚îÇ   #   'value': Any,
‚îÇ   #   'expires_at': datetime,
‚îÇ   #   'created_at': datetime
‚îÇ   # }
‚îÇ
‚îú‚îÄ‚ñ∫ get(key: str) ‚Üí Optional[Any]
‚îÇ   ‚îú‚îÄ‚ñ∫ if key not in cache_data:
‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ return None  # Miss
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚ñ∫ entry = cache_data[key]
‚îÇ   ‚îú‚îÄ‚ñ∫ if datetime.now() > entry['expires_at']:
‚îÇ   ‚îÇ   ‚îú‚îÄ‚ñ∫ del cache_data[key]  # Expired
‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫ return None
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚ñ∫ stats['hits'] += 1
‚îÇ   ‚îî‚îÄ‚ñ∫ return entry['value']
‚îÇ
‚îî‚îÄ‚ñ∫ set(key: str, value: Any, ttl: int)
    ‚îî‚îÄ‚ñ∫ cache_data[key] = {
        'value': value,
        'expires_at': datetime.now() + timedelta(seconds=ttl),
        'created_at': datetime.now()
    }
```

**TTL Strategy**:
- **Live games**: 15 seconds (scores change frequently)
- **Upcoming games**: 5 minutes (schedule stable)
- **Team list**: 24 hours (rarely changes)

**Cache Hit Rate** (typical):
- During live games: 80-90% hit rate (15s TTL, dashboard polls every 30s)
- Off-hours: 60-70% hit rate (fewer requests, more expiration)

---

#### Phase 4: API Usage Optimization

**Problem**: ESPN API is free but unmetered. We self-limit to stay respectful.

**Solution**: Team-based filtering + caching

```python
# WITHOUT filtering (fetches ALL games)
/api/v1/games/live  # Returns ~16 NFL games (all teams)
# Dashboard polls every 30s
# API calls per day: (60/30) * 24 * 7 = 336 calls/week

# WITH filtering (fetches only user's 2 teams)
/api/v1/games/live?teams=sf,dal  # Returns only SF and DAL games
# Cache hit rate: 85%
# API calls per day: 336 * 0.15 = ~50 calls/week
# Savings: 85% reduction
```

**API Usage Tracking**:
```python
get_api_usage()
‚îî‚îÄ‚ñ∫ return {
    'total_calls_today': 23,
    'nfl_calls': 15,
    'nhl_calls': 8,
    'cache_hits': 67,
    'cache_misses': 23,
    'hit_rate': 0.744,  # 74.4%
    'estimated_daily_calls': 50,
    'within_free_tier': True
}
```

---

## üéØ Caching Strategies

### Comparison of Caching Patterns

| Service | Cache Location | TTL | Fallback Behavior | Cache Key |
|---------|---------------|-----|-------------------|-----------|
| **Sports Data** | In-memory (service) | 15s-5min | No data (empty list) | `live_games_{league}_{teams}` |
| **Air Quality** | Instance variable | 60 min | Return stale cache | `cached_data` (single) |
| **Carbon Intensity** | Instance variable | 15 min | Return stale cache | `cached_data` (single) |
| **Electricity Pricing** | Instance variable | 60 min | Return stale cache | `cached_data` (single) |
| **Smart Meter** | Instance variable | None | No fallback | `cached_data` (single) |
| **Calendar** | None | None | Empty prediction | N/A |

### Cache Invalidation Rules

**Pattern A Services** (Push):
- Cache updated on successful external API fetch
- Stale cache served if API fails (graceful degradation)
- No explicit TTL (replaced on next fetch)

**Pattern B Services** (Pull):
- Cache with explicit TTL (time-based expiration)
- Cache miss triggers immediate external API call
- Empty result on cache miss + API failure

---

## üìä Performance Characteristics

### Service Performance Metrics

| Service | Fetch Latency | Write Latency | API Rate Limit | Throughput | Memory Usage |
|---------|--------------|---------------|----------------|------------|--------------|
| **Sports Data** | 150-300ms | N/A | Self-limited | 100 req/day | 50 MB |
| **Air Quality** | 200-400ms | 50ms | 500/hour | 24 fetches/day | 30 MB |
| **Carbon Intensity** | 180-350ms | 50ms | 100/hour | 96 fetches/day | 30 MB |
| **Electricity Pricing** | 250-500ms | 80ms | Unlimited | 24 fetches/day | 35 MB |
| **Smart Meter** | 50-150ms | 60ms | N/A | 288 fetches/day | 40 MB |
| **Calendar** | 300-600ms | 50ms | Google quotas | 96 fetches/day | 45 MB |

### External API Dependencies

| External API | Authentication | Cost | Reliability | Rate Limit | Notes |
|--------------|---------------|------|-------------|------------|-------|
| **ESPN** | None | Free | 99.5% | Self-limited | Public API |
| **AirNow** | API Key | Free | 99.0% | 500/hour | Government API |
| **WattTime** | OAuth token | Paid | 98.5% | 100/hour | Subscription required |
| **Awattar** | None | Free | 99.0% | Unlimited | European markets |
| **Google Calendar** | OAuth 2.0 | Free | 99.9% | 1M/day | Requires user consent |
| **Smart Meter** | Varies | Varies | Varies | Varies | Adapter-dependent |

---

## üõ†Ô∏è Error Handling Patterns

### Common Error Scenarios

#### 1. External API Unavailable

**Scenario**: External API returns 500/503 or times out

**Pattern A Services** (Push to InfluxDB):
```python
try:
    data = await fetch_from_external_api()
except Exception as e:
    log_error_with_context(logger, "API fetch failed", e)
    health_handler.failed_fetches += 1
    
    # Fallback: Return cached data
    if self.cached_data:
        logger.warning("Using cached data (API unavailable)")
        return self.cached_data
    
    # No cache available
    return None  # Skip InfluxDB write this cycle
```

**Pattern B Services** (On-demand):
```python
try:
    data = await fetch_from_external_api()
except Exception as e:
    log_error_with_context(logger, "API fetch failed", e)
    
    # Check cache first
    if cached_data and not expired:
        return cached_data
    
    # No cache, return error to client
    raise HTTPException(
        status_code=503,
        detail="External API unavailable and no cached data"
    )
```

---

#### 2. Authentication Failure

**OAuth Token Expired** (Carbon Intensity, Calendar):
```python
async with session.get(url, headers=headers) as response:
    if response.status == 401:  # Unauthorized
        log_error_with_context(logger, "OAuth token expired")
        
        # Attempt token refresh
        try:
            await refresh_oauth_token()
            # Retry request with new token
            return await fetch_from_external_api()
        except:
            health_handler.oauth_valid = False
            return cached_data  # Fallback
```

**API Key Invalid** (Air Quality):
```python
if response.status == 403:  # Forbidden
    log_error_with_context(logger, "Invalid API key")
    health_handler.api_key_valid = False
    
    # Critical error - cannot recover automatically
    # Alert admin via health check endpoint
    raise ValueError("API key validation failed - manual intervention required")
```

---

#### 3. Rate Limit Exceeded

**Graceful Backoff**:
```python
async def fetch_with_rate_limit():
    try:
        response = await session.get(url)
        
        if response.status == 429:  # Too Many Requests
            retry_after = int(response.headers.get('Retry-After', 60))
            logger.warning(f"Rate limited, waiting {retry_after}s")
            
            await asyncio.sleep(retry_after)
            return await fetch_with_rate_limit()  # Retry
            
    except Exception as e:
        log_error_with_context(logger, "Rate limit handling failed", e)
        return cached_data
```

---

#### 4. InfluxDB Write Failure

**Retry with Exponential Backoff**:
```python
async def store_in_influxdb_with_retry(data, max_retries=3):
    for attempt in range(max_retries):
        try:
            influxdb_client.write(point)
            logger.info("Data written to InfluxDB")
            return True
            
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # 1s, 2s, 4s
                logger.warning(f"InfluxDB write failed (attempt {attempt+1}), retrying in {wait_time}s")
                await asyncio.sleep(wait_time)
            else:
                log_error_with_context(logger, "All InfluxDB write attempts failed", e)
                # Log to file as backup
                await log_failed_write_to_file(data)
                return False
```

---

## üîç Monitoring & Observability

### Health Check Endpoints

All services expose `/health` endpoint with consistent structure:

```json
{
  "status": "healthy" | "degraded" | "unhealthy",
  "service": "air-quality-service",
  "timestamp": "2025-10-13T10:30:00Z",
  "uptime_seconds": 86400,
  "metrics": {
    "total_fetches": 24,
    "successful_fetches": 23,
    "failed_fetches": 1,
    "success_rate": 0.958,
    "last_successful_fetch": "2025-10-13T10:00:00Z",
    "cache_hit_rate": 0.744
  },
  "external_api": {
    "status": "available" | "unavailable",
    "last_error": null | "error message",
    "api_key_valid": true
  },
  "influxdb": {
    "status": "connected" | "disconnected",
    "last_write": "2025-10-13T10:00:00Z"
  }
}
```

### Admin API Integration

**Aggregate Health Check**:

```
Dashboard ‚Üí GET /api/health/external-services
            ‚îî‚îÄ‚ñ∫ Admin API: health_endpoints.py
                ‚îî‚îÄ‚ñ∫ check_external_services()
                    ‚îú‚îÄ‚ñ∫ for service in external_services:
                    ‚îÇ   ‚îú‚îÄ‚ñ∫ GET http://service:port/health
                    ‚îÇ   ‚îú‚îÄ‚ñ∫ response_time = measure_latency()
                    ‚îÇ   ‚îî‚îÄ‚ñ∫ collect status
                    ‚îÇ
                    ‚îî‚îÄ‚ñ∫ return {
                        'sports-data': {'status': 'healthy', 'response_time_ms': 45},
                        'air-quality': {'status': 'healthy', 'response_time_ms': 52},
                        'carbon-intensity': {'status': 'degraded', 'response_time_ms': 320},
                        'electricity-pricing': {'status': 'healthy', 'response_time_ms': 38},
                        'smart-meter': {'status': 'healthy', 'response_time_ms': 23},
                        'calendar': {'status': 'healthy', 'response_time_ms': 89}
                    }
```

**Dashboard Display**: Data Sources tab shows real-time status of all external services with color-coded indicators (green/yellow/red).

---

## üöÄ Optimization Strategies

### Current Optimizations

1. **Team-Based Filtering** (Sports Data)
   - Only fetch games for user's selected teams
   - Reduces API calls by 85%
   - Improves response time

2. **Aggressive Caching** (All Services)
   - Pattern A: Cache as API failure fallback
   - Pattern B: Cache to reduce external API calls
   - Significantly reduces latency

3. **Batch Writes** (Pattern A Services)
   - Single InfluxDB write per fetch cycle
   - Circuit-level data written in single transaction
   - Reduces database load

4. **Connection Pooling** (All Services)
   - Reuse aiohttp ClientSession across requests
   - InfluxDB client connection persistence
   - Lower connection overhead

5. **Async/Await** (All Services)
   - Non-blocking I/O for external API calls
   - Concurrent health checks
   - Better resource utilization

### Future Optimization Opportunities

1. **Redis Cache Layer**
   - Shared cache across service instances
   - Persistent cache across restarts
   - Pub/sub for cache invalidation

2. **GraphQL Gateway**
   - Replace multiple REST calls with single GraphQL query
   - Client specifies exact data needed
   - Reduced over-fetching

3. **API Response Compression**
   - Enable gzip compression for large responses
   - Reduce network bandwidth usage
   - Faster response times

4. **Webhook Integration**
   - Push notifications from external APIs (if supported)
   - Eliminate polling overhead
   - Real-time updates without constant checking

5. **Service Mesh** (Future Scale)
   - Istio or Linkerd for inter-service communication
   - Circuit breakers and retry policies
   - Distributed tracing

---

## üêõ Troubleshooting Guide

### Common Issues & Solutions

#### Issue: Service shows "degraded" status

**Debug Steps**:

1. Check service health endpoint directly:
   ```bash
   curl http://localhost:8012/health
   ```

2. Look for authentication issues:
   ```bash
   # Check logs for "401 Unauthorized" or "403 Forbidden"
   docker logs air-quality-service | grep -i "auth"
   ```

3. Verify environment variables:
   ```bash
   docker exec air-quality-service env | grep API_KEY
   ```

4. Test external API directly:
   ```bash
   curl "https://www.airnowapi.org/aq/observation/latLong/current/?latitude=36.1699&longitude=-115.1398&format=application/json&API_KEY=YOUR_KEY"
   ```

---

#### Issue: No data appearing in dashboard

**Debug Steps**:

1. Check if service is writing to InfluxDB:
   ```bash
   docker logs air-quality-service | grep "written to InfluxDB"
   ```

2. Query InfluxDB directly:
   ```flux
   from(bucket: "events")
     |> range(start: -1h)
     |> filter(fn: (r) => r._measurement == "air_quality")
     |> count()
   ```

3. Check admin-api can query InfluxDB:
   ```bash
   curl http://localhost:8003/api/data-sources/air-quality
   ```

4. Verify dashboard is making requests:
   ```bash
   # Check browser DevTools Network tab
   # Look for failed /api/data-sources/* requests
   ```

---

#### Issue: High external API usage

**Debug Steps**:

1. Check API call counters (Sports Data):
   ```bash
   curl http://localhost:8005/api/v1/metrics/api-usage
   ```

2. Review cache hit rate:
   ```bash
   curl http://localhost:8005/api/v1/cache/stats
   ```

3. Verify TTL settings:
   ```bash
   docker logs sports-data | grep "Cache TTL"
   ```

4. **Solution**: Increase cache TTL or reduce dashboard polling frequency

---

#### Issue: Stale data in dashboard

**Possible Causes**:
- Service fetch interval too long
- Cache TTL too high
- External API returning stale data
- InfluxDB query range incorrect

**Debug Steps**:

1. Check last successful fetch:
   ```bash
   curl http://localhost:8012/health | jq '.metrics.last_successful_fetch'
   ```

2. Verify fetch interval:
   ```bash
   docker exec air-quality-service env | grep FETCH_INTERVAL
   ```

3. Check cache expiration:
   ```python
   # In service logs, look for:
   logger.info(f"Cache age: {(now - last_fetch_time).total_seconds()}s")
   ```

4. **Solution**: Adjust fetch interval or cache TTL based on data volatility

---

## üìù Change Log

### Version 1.3 (2025-10-14)
**Code Verification Update**:
- ‚úÖ Verified sports-data service implementation against actual code
- **UPDATED (October 14, 2025)**: Sports service is now Hybrid Pattern A+B (Epic 12 ‚úÖ COMPLETE)
- **CLARIFIED**: Epic 12 InfluxDB persistence features are IMPLEMENTED and DEPLOYED
- Updated service catalog to show Epic 12 complete implementation
- Added "Current Limitations" section for sports service
- Corrected architecture diagrams to remove non-existent InfluxDB writes
- Updated pattern descriptions to reflect actual behavior
- Verified actual endpoints: `/api/v1/games/live`, `/api/v1/games/upcoming`, `/api/v1/teams`
- Confirmed team filtering via `team_ids` parameter (comma-separated)
- Verified cache TTLs: 15s (live), 5min (upcoming)

### Version 1.0 (2025-10-13)
**Initial Release**:
- Complete documentation for all 6 external API services
- Detailed call trees for both Pattern A (Push) and Pattern B (Pull)
- Service-specific implementations and data flows
- Caching strategies and optimization patterns
- Performance characteristics and monitoring guidelines
- Troubleshooting guide with debug steps
- Mermaid sequence diagrams and ASCII architecture diagrams
- Quick reference tables and service catalog
- Error handling patterns and recovery strategies

---

## üìã Document Maintenance

**Update this document when**:
- New external API services are added
- Service patterns or architectures change
- External API providers change (e.g., switch from WattTime to different carbon API)
- Caching strategies are modified
- Performance characteristics significantly change
- New optimization techniques are implemented
- Dashboard integration patterns change

**Review Schedule**:
- After adding/modifying any external API service
- When external API rate limits or pricing changes
- Quarterly performance review
- When troubleshooting patterns emerge

**Maintenance Checklist**:
- [ ] Verify all file paths are current
- [ ] Update performance metrics if benchmarks change
- [ ] Check all API endpoint URLs are correct
- [ ] Update service ports if changed
- [ ] Verify external API documentation links
- [ ] Test all troubleshooting steps
- [ ] Update sequence diagrams if flow changes
- [ ] Add entry to Change Log
- [ ] Increment version number
- [ ] Update cross-references to related docs

---

## üîó Integration with Core System

### Relationship to HA Event Flow

External API services are **complementary** to the core Home Assistant event flow:

- **HA Event Flow** ([HA_EVENT_CALL_TREE.md](./HA_EVENT_CALL_TREE.md)): 
  - High-volume push from Home Assistant (10,000+ events/sec)
  - Real-time state changes
  - Device and entity management

- **External API Services** (this document):
  - Low-volume pull from external sources (1-288 fetches/day)
  - Contextual enrichment data
  - Third-party integrations

**Combined Value**: External services enrich HA events with contextual data (weather, energy prices, occupancy) to enable intelligent automation decisions.

### Data Flow Integration

```
Home Assistant Events ‚Üí WebSocket Ingestion ‚Üí InfluxDB
                                                   ‚Üë
External APIs ‚Üí External Services ‚Üí InfluxDB ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                   ‚Üì
                              Admin API ‚Üê Dashboard queries both data sources
```

**Example Use Case**:
1. **HA Event**: Thermostat temperature change event (from core flow)
2. **External Data**: Current electricity pricing (from this flow)
3. **Smart Decision**: If price > peak threshold, reduce HVAC setpoint by 2¬∞F
4. **Result**: Cost-optimized comfort automation

---

**Document maintained by**: BMad Master  
**Questions or updates**: Create issue or update directly following maintenance checklist

